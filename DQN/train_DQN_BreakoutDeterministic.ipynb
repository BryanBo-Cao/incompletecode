{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gA8FHJqiMgOo"
   },
   "source": [
    "## **OpenAI Gym, PyBullet and PyBulletGym Installation**\n",
    "[Click here to see Gym documentaion](https://gym.openai.com/docs/)\n",
    "\n",
    "[Click here to see PyBullet documentaion](https://docs.google.com/document/d/10sXEhzFRSnvFcl3XxNGhnD4N2SedqwdAvK3dsihxVUA)\n",
    "\n",
    "[Click here to see PyBulletGym page](https://github.com/benelot/pybullet-gym)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C1LashLPkqYx"
   },
   "source": [
    "Note that this assignment was done in a remote server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nipCFbQpMu8h"
   },
   "source": [
    "**Before we start, first update the apt-get tool in the given machine.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (default, Aug 13 2019, 20:35:49) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "zViYHb_7C2fi",
    "outputId": "66c01425-b9aa-4981-be6c-787d632d7024"
   },
   "outputs": [],
   "source": [
    "# !apt-get update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6x2LqNwbMFww"
   },
   "source": [
    "Most of the requirements of python packages are already fulfilled on Colab. To run Gym, you have to install prerequisites like xvbf,opengl & other python-dev packages using the following codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "EY1Z1npZC5fo",
    "outputId": "026f6bb0-04e3-4651-8c48-5095b4046b33"
   },
   "outputs": [],
   "source": [
    "# !pip install gym\n",
    "# !apt-get install python-opengl -y\n",
    "# !apt install xvfb -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fH-G48ZaSlFO"
   },
   "source": [
    "For rendering environment, you can use pyvirtualdisplay. So fulfill that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "RD8I53YpC92T",
    "outputId": "50692931-75b4-4969-9b32-77c92d46cb61"
   },
   "outputs": [],
   "source": [
    "# !pip install pyvirtualdisplay\n",
    "# !pip install piglet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5-z6FT2NYzXE",
    "outputId": "bc8cd11d-00dd-42ac-e40f-67156fa99cdb"
   },
   "outputs": [],
   "source": [
    "# !pip install pybullet==2.5.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HHwqCuAVDrn9"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/benelot/pybullet-gym.git # should already be there in my Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oXc2n4nNaeU6"
   },
   "source": [
    "## **Update the source code**\n",
    "In pybulletgym/envs/mujoco/envs/pendulum/inverted_pendulum_env.py, line 32, change\n",
    "\n",
    "done = not np.isfinite(state).all() or np.abs(state[1]) > .2\n",
    "\n",
    "to\n",
    "\n",
    "done = abs(state[0][0]) > 2.4 or abs(state[0][1]) > 0.27\n",
    "\n",
    "**Restart runtime and run the following cells.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_GVojhyza7Nz"
   },
   "outputs": [],
   "source": [
    "# cd /content/pybullet-gym/ # use the address below instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7uSrlp8xatq_",
    "outputId": "864bb347-69b1-4dac-da0b-275f5fbefe54"
   },
   "outputs": [],
   "source": [
    "# cd './pybullet-gym'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "-gEJuj5LDxL0",
    "outputId": "66e73ccd-bc5f-4d57-cd55-0c8f28709a59"
   },
   "outputs": [],
   "source": [
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow version: 1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==1.13.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZVlna0dTh3N"
   },
   "source": [
    "Import everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zuMjm4mjC_9T"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/bryanbc/Apps/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/bryanbc/Apps/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/bryanbc/Apps/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/bryanbc/Apps/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/bryanbc/Apps/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/bryanbc/Apps/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bryanbc/Apps/anaconda3/lib/python3.7/site-packages/tensorflow/python/compat/compat.py:175: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "config:  gpu_options {\n",
      "  allow_growth: true\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import gym\n",
    "from gym import logger as gymlogger\n",
    "from gym.wrappers import Monitor\n",
    "gymlogger.set_level(40) # error only\n",
    "\n",
    "import pybulletgym  # register PyBullet enviroments with open ai gym\n",
    "import pybullet\n",
    "import pybullet_data\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "import os\n",
    "from os import path\n",
    "import copy\n",
    "import hickle as hkl\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "# Colab comes with PyTorch\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.autograd import Variable\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import gym\n",
    "import psutil\n",
    "import gc\n",
    "import statistics\n",
    "import cv2\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Dropout, Input, BatchNormalization, \\\n",
    "                            Reshape, Flatten, Activation, ZeroPadding2D, \\\n",
    "                            Lambda, Convolution2D\n",
    "from keras.layers.merge import Add, Multiply\n",
    "from keras.optimizers import Adam\n",
    "# import keras.backend as K\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.engine.topology import Layer\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from collections import deque\n",
    "\n",
    "# use plaidml as backend\n",
    "# install plaidml:\n",
    "# pip install plaidml-keras\n",
    "# plaidml-setup\n",
    "# ======================================================\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "# ======================================================\n",
    "from keras import backend as K\n",
    "# from tensorflow.keras import backend as K\n",
    "from tensorflow.python.keras import backend as k\n",
    "# use tensorflow as backend\n",
    "# ======================================================\n",
    "# import tensorflow as tf\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "# config = tf.compat.v1.ConfigProto() # for Tensorflow 2.1\n",
    "config = tf.ConfigProto() # for Tensorflow 1.13.1\n",
    "config.gpu_options.allow_growth = True\n",
    "print(\"config: \", config)\n",
    "\n",
    "# tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config)) # for Tensorflow 2.1\n",
    "K.set_session(tf.Session(config=config)) # for Tensorflow 1.13.1\n",
    "# ======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------\n",
    "# All parameters\n",
    "# ---------------\n",
    "class Params:\n",
    "    def __init__(self):\n",
    "        # Paramaters for this experiment\n",
    "        self.exp_id = 'DQN_bk_smer_4' # bk: Breakout, smer: save max episode reward\n",
    "        self.env_id = 'BreakoutDeterministic-v4'# 'BreakoutNoFrameskip-v4'\n",
    "        self.server_path = '/home/bryanbc/Repos/rl/'\n",
    "        self.hw = 'hw03'\n",
    "        self.video_path = self.server_path + self.hw + '/' + self.exp_id + '/video/'\n",
    "        self.mp4list_path = self.video_path + '*.mp4'\n",
    "        \n",
    "        # Parameters for enviroment\n",
    "        self.seed_num = 123\n",
    "        self.n_actions = 4\n",
    "        self.s_len = 4\n",
    "        self.input_shape = (None, 93, 80, self.s_len)\n",
    "        self.init_epsilon = 1.\n",
    "        self.final_epsilon = 0.01\n",
    "        self.epsilon = copy.deepcopy(self.init_epsilon)\n",
    "        self.max_episodes = 10000000\n",
    "        self.max_steps = 1000\n",
    "        self.exploration_steps = 500000\n",
    "        self.cnt_frames = 0\n",
    "        self.max_episode_reward = 0\n",
    "        \n",
    "        # Parameters for models\n",
    "        self.init_learning_rate = 1e-4\n",
    "        self.final_learning_rate = 5e-6\n",
    "        self.learning_rate = copy.deepcopy(self.init_learning_rate)\n",
    "        self.learning_rate_decay_step = 0\n",
    "        self.batch_size = 32\n",
    "        self.gamma = 0.99\n",
    "        self.tau   =  0.001\n",
    "        self.buffer_size = 500000\n",
    "        \n",
    "        self.train_frame_interval = 4\n",
    "        self.update_target_network_episode_interval = 40\n",
    "        self.save_model_episode_interval = 500\n",
    "        self.episode_i = 0\n",
    "        \n",
    "        # saved models paths\n",
    "        self.saved_models_path = '/ssd/bryanbc/saved_models/' + self.hw + '/' + self.exp_id\n",
    "        self.saved_train_network_filepath = '%s/train_network_episode_%d.h5' % \\\n",
    "            (self.saved_models_path, self.episode_i)\n",
    "        self.saved_target_network_filepath = '%s/target_network_episode_%d.h5' % \\\n",
    "            (self.saved_models_path, self.episode_i)\n",
    "        self.saved_PARAMS_filepath = '%s/PARAMS_episode_%d.hkl' % \\\n",
    "            (self.saved_models_path, self.episode_i)\n",
    "        \n",
    "        # saved log path\n",
    "        self.log_path = '/ssd/bryanbc/data/logs/hw/' + self.hw + '/'\n",
    "        os.makedirs((self.log_path), exist_ok=True)\n",
    "        self.log_filepath = self.log_path + self.exp_id + '_episode_reward.log'\n",
    "        # Open the log file\n",
    "        self.log_file = open((self.log_filepath), 'a')\n",
    "        \n",
    "        # saved replay buffer path\n",
    "        # self.replay_buffer_path = self.saved_models_path + '/'\n",
    "        # os.makedirs((self.replay_buffer_path), exist_ok=True)\n",
    "        # self.saved_replay_buffer_filepath = self.replay_buffer_path + self.exp_id + '_replay_buffer_gzip.hkl'\n",
    "        \n",
    "    def load(self, load_PARAMS):\n",
    "        self.epsilon, self.learning_rate, \\\n",
    "            self.learning_rate_decay_step, self.cnt_frames, \\\n",
    "            self.episode_i, self.max_episode_reward = load_PARAMS\n",
    "        \n",
    "PARAMS = Params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eGXHAGHRTJjd"
   },
   "source": [
    "To activate virtual display, we need to run a script once for training an agent, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "50In5ybcFUMm",
    "outputId": "55ac7443-2389-471c-fc14-9d9d8187d888"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':6119'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':6119'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KzcbS-GyTUKG"
   },
   "source": [
    "The following code creates a virtual display to draw game images on. If you are running locally, just ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hwrBwc_TSfA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "310x8KjeDF1n"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility functions to enable video recording of gym environment and displaying it\n",
    "To enable video, just do \"env = wrap_env(env)\"\"\n",
    "\"\"\"\n",
    "# mp4list_path_colab = '/content/gdrive/My Drive/video/*.mp4'\n",
    "def show_video():\n",
    "    mp4list = glob.glob(PARAMS.mp4list_path) # glob.glob('/content/video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "                </video>'''.format(encoded.decode('ascii'))))\n",
    "    else: \n",
    "        print(\"Could not find video\")\n",
    "    \n",
    "# video_path_colab = '/content/gdrive/My Drive/video/'\n",
    "def wrap_env(env):\n",
    "    env = Monitor(env, PARAMS.video_path, force=True) # Monitor(env, '/content/video', force=True)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_one_hot(data, depth=10):\n",
    "    return (np.arange(depth) == np.array(data)[:, None]).astype(np.bool)\n",
    "\n",
    "\n",
    "def rgb2gray(im):\n",
    "    return (cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)).astype(np.uint8)\n",
    "\n",
    "\n",
    "def down_sample(gray):\n",
    "    return gray[25::2, ::2]\n",
    "\n",
    "\n",
    "class LayerNormalization(Layer):\n",
    "\n",
    "    def __init__(self, eps=1e-5, activation=None, **kwargs):\n",
    "        self.eps = eps\n",
    "        self.channels = None\n",
    "        self.activation = activation\n",
    "        super(LayerNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.channels = input_shape[-1]\n",
    "        shape = [1] * (len(input_shape) - 1)\n",
    "        shape.append(self.channels)\n",
    "        self.add_weight('gamma', shape, dtype='float32', initializer='ones')\n",
    "        self.add_weight('beta', shape, dtype='float32', initializer='zeros')\n",
    "\n",
    "        super(LayerNormalization, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        dim = len(K.int_shape(inputs)) - 1\n",
    "        mean = K.mean(inputs, axis=dim, keepdims=True)\n",
    "        var = K.mean(K.square(inputs - mean), axis=dim, keepdims=True)\n",
    "        outputs = (inputs - mean) / K.sqrt(var + self.eps)\n",
    "        outputs = outputs * self.trainable_weights[0] + self.trainable_weights[1]\n",
    "        if self.activation is None:\n",
    "            return outputs\n",
    "        else:\n",
    "            return self.activation(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxGb76TexllA"
   },
   "source": [
    "# **RL Algorithms**\n",
    "Code based: https://github.com/IntoxicatedDING/DQN-Beat-Atari."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.replay_buffer = deque()\n",
    "        self.q_out, self.train_network = Agent.build_train_network()\n",
    "        self.target_network = Agent.build_target_network()\n",
    "\n",
    "        # self.opt = optimizers.rmsprop(lr=self.learning_rate, rho=0.95)\n",
    "        self.opt = optimizers.adam(lr=PARAMS.learning_rate)\n",
    "        # self.opt = optimizers.RMSprop(lr=self.learning_rate, rho=0.95, epsilon=0.01)\n",
    "        self.train_network.compile(optimizer=self.opt, loss=[Agent.huber_loss])\n",
    "\n",
    "    # Append a transition (s, a, s_, r, done) into replay buffer\n",
    "    def remember(self, transition):\n",
    "        if len(self.replay_buffer) >= PARAMS.buffer_size:\n",
    "            self.replay_buffer.popleft()\n",
    "        self.replay_buffer.append(transition)\n",
    "        return self.replay_buffer\n",
    "\n",
    "    def sample_batch(self):\n",
    "        # Sample a batch of transitions from replay buffer\n",
    "        batch_q, batch_state, batch_mask, states_next, rewards, done =\\\n",
    "            map(lambda x: np.array(list(x)), zip(*random.sample(self.replay_buffer, PARAMS.batch_size)))\n",
    "        \n",
    "        batch_state = np.transpose(batch_state, axes=[0, 2, 3, 1])\n",
    "        states_next = np.transpose(states_next, axes=[0, 2, 3, 1])\n",
    "        batch_mask = dense_to_one_hot(batch_mask, PARAMS.n_actions)\n",
    "        q_next = self.target_network.predict(states_next)\n",
    "        batch_q[batch_mask] = np.array(rewards) + PARAMS.gamma * np.array(done) * np.max(q_next, axis=1)\n",
    "        return batch_q, batch_state, batch_mask\n",
    "\n",
    "    def build_train_network():\n",
    "        X = Input(shape=PARAMS.input_shape[1:], dtype='float32')\n",
    "        mask = Input(shape=(PARAMS.n_actions,), dtype='float32')\n",
    "        q_out, model = Agent.build_network(X)\n",
    "        q_ = Lambda(lambda x: K.reshape(K.sum(x * mask, axis=1), (-1, 1)), output_shape=(1,))(q_out)\n",
    "        return K.function([X], [q_out]), Model(inputs=[X, mask], outputs=q_)\n",
    "\n",
    "    def huber_loss(x, y):\n",
    "        error = K.abs(x - y)\n",
    "        quadratic_part = K.clip(error, 0.0, 1.0)\n",
    "        linear_part = error - quadratic_part\n",
    "        loss = K.mean(0.5 * K.square(quadratic_part) + linear_part, axis=-1)\n",
    "        return loss\n",
    "\n",
    "    def build_target_network():\n",
    "        X = Input(shape=PARAMS.input_shape[1:], dtype='float32')\n",
    "        Q, model = Agent.build_network(X, trainable=False, init=initializers.zeros())\n",
    "        return model\n",
    "\n",
    "    def build_network(X, trainable=True, init=initializers.truncated_normal(stddev=0.01)):\n",
    "        init_w = init\n",
    "        init_b = initializers.constant(0.)\n",
    "        normed = Lambda(lambda x: x / 255., output_shape=K.int_shape(X)[1:])(X)\n",
    "        h_conv1 = Convolution2D(32, (8, 8), strides=(4, 4),\n",
    "                                kernel_initializer=init_w, use_bias=False, padding='same')(normed)\n",
    "        h_ln1 = LayerNormalization(activation=K.relu)(h_conv1)\n",
    "        h_conv2 = Convolution2D(64, (4, 4), strides=(2, 2),\n",
    "                                kernel_initializer=init_w, use_bias=False, padding='same')(h_ln1)\n",
    "        h_ln2 = LayerNormalization(activation=K.relu)(h_conv2)\n",
    "        h_conv3 = Convolution2D(64, (3, 3), strides=(1, 1),\n",
    "                                kernel_initializer=init_w, use_bias=False, padding='same')(h_ln2)\n",
    "        h_ln3 = LayerNormalization(activation=K.relu)(h_conv3)\n",
    "        h_flat = Flatten()(h_ln3)\n",
    "        fc1 = Dense(512, use_bias=False, kernel_initializer=init_w)(h_flat)\n",
    "        h_ln_fc1 = LayerNormalization(activation=K.relu)(fc1)\n",
    "        q = Dense(PARAMS.n_actions, kernel_initializer=init_w, use_bias=False, bias_initializer=init_b)(h_ln_fc1)\n",
    "        # q = LayerNormalization()(fc2)\n",
    "        model = Model(inputs=X, outputs=q)\n",
    "        model.trainable = trainable\n",
    "        return q, model\n",
    "\n",
    "    def train(self):\n",
    "        batch_q, batch_state, batch_mask = self.sample_batch()\n",
    "        self.train_network.fit([batch_state, batch_mask], np.sum(batch_mask * batch_q, axis=1), verbose=0)\n",
    "\n",
    "    def update_epsilon(self):\n",
    "        PARAMS.epsilon = np.maximum(PARAMS.final_epsilon,\n",
    "                                  PARAMS.epsilon - (PARAMS.init_epsilon - PARAMS.final_epsilon) / PARAMS.exploration_steps)\n",
    "\n",
    "    def predict(self, state):\n",
    "        q = self.q_out([state])\n",
    "        q = np.array(q).flatten()\n",
    "        # print(np.argmax(q))\n",
    "        # print(q)\n",
    "        return q, np.argmax(q)\n",
    "\n",
    "    def update_learning_rate(self):\n",
    "        PARAMS.learning_rate = PARAMS.learning_rate * (0.99 ** (PARAMS.learning_rate_decay_step / 100))\n",
    "        K.set_value(self.train_network.optimizer.lr, PARAMS.learning_rate)\n",
    "        PARAMS.learning_rate_decay_step += 1\n",
    "\n",
    "    def update_target_network(self):\n",
    "        self.target_network.set_weights(self.train_network.get_weights())\n",
    "\n",
    "    # Save model weights and PARAMS\n",
    "    def save(self, best=False):\n",
    "        os.makedirs((PARAMS.saved_models_path), exist_ok=True)\n",
    "        \n",
    "        # Update file paths\n",
    "        if best:\n",
    "            PARAMS.saved_train_network_filepath = '%s/train_network_episode_%d_max_r_%d_best.h5' % \\\n",
    "                (PARAMS.saved_models_path, PARAMS.episode_i, PARAMS.max_episode_reward)\n",
    "            PARAMS.saved_target_network_filepath = '%s/target_network_episode_%d_max_r_%d_best.h5' % \\\n",
    "                (PARAMS.saved_models_path, PARAMS.episode_i, PARAMS.max_episode_reward)\n",
    "            PARAMS.saved_PARAMS_filepath = '%s/PARAMS_episode_%d_max_r_%d_best.hkl' % \\\n",
    "                (PARAMS.saved_models_path, PARAMS.episode_i, PARAMS.max_episode_reward)\n",
    "            # PARAMS.saved_replay_buffer_filepath = '%s/replay_buffer_episode_%d_max_r_%d_best.hkl' % \\\n",
    "            #     (PARAMS.saved_models_path, PARAMS.episode_i, PARAMS.max_episode_reward)\n",
    "        else:\n",
    "            PARAMS.saved_train_network_filepath = '%s/train_network_episode_%d.h5' % \\\n",
    "                (PARAMS.saved_models_path, PARAMS.episode_i)\n",
    "            PARAMS.saved_target_network_filepath = '%s/target_network_episode_%d.h5' % \\\n",
    "                (PARAMS.saved_models_path, PARAMS.episode_i)\n",
    "            # PARAMS.saved_PARAMS_filepath = '%s/PARAMS_episode_%d.hkl' % \\\n",
    "            #     (PARAMS.saved_models_path, PARAMS.episode_i)\n",
    "            # PARAMS.saved_replay_buffer_filepath = '%s/replay_buffer_episode_%d.hkl' % \\\n",
    "            #     (PARAMS.saved_models_path, PARAMS.episode_i)\n",
    "        \n",
    "        self.train_network.save_weights(PARAMS.saved_train_network_filepath)\n",
    "        self.target_network.save_weights(PARAMS.saved_target_network_filepath)\n",
    "        \n",
    "        # Parameters to save\n",
    "        save_PARAMS = (PARAMS.epsilon,\n",
    "                       PARAMS.learning_rate,\n",
    "                       PARAMS.learning_rate_decay_step,\n",
    "                       PARAMS.cnt_frames,\n",
    "                       PARAMS.episode_i,\n",
    "                       PARAMS.max_episode_reward)\n",
    "        hkl.dump(save_PARAMS, PARAMS.saved_PARAMS_filepath, mode='w')\n",
    "        \n",
    "        # Save replay buffer\n",
    "        # hkl.dump(self.replay_buffer, PARAMS.saved_replay_buffer_filepath, mode='w', compression='gzip')\n",
    "    \n",
    "    # Load model weights and PARAMS\n",
    "    def restore(self, episode_i, best, max_episode_reward):\n",
    "        if best:\n",
    "            saved_train_network_filepath = '%s/train_network_episode_%d_max_r_%d_best.h5' % \\\n",
    "                (PARAMS.saved_models_path, episode_i, max_episode_reward)\n",
    "            saved_target_network_filepath = '%s/target_network_episode_%d_max_r_%d_best.h5' % \\\n",
    "                (PARAMS.saved_models_path, episode_i, max_episode_reward)\n",
    "            saved_PARAMS_filepath = '%s/PARAMS_episode_%d_max_r_%d_best.hkl' % \\\n",
    "                (PARAMS.saved_models_path, episode_i, max_episode_reward)\n",
    "            # saved_replay_buffer_filepath = '%s/replay_buffer_episode_%d_max_r_%d_best.hkl' % \\\n",
    "            #     (PARAMS.saved_models_path, episode_i, max_episode_reward)\n",
    "        else:\n",
    "            saved_train_network_filepath = '%s/train_network_episode_%d.h5' % \\\n",
    "                (PARAMS.saved_models_path, episode_i)\n",
    "            saved_target_network_filepath = '%s/target_network_episode_%d.h5' % \\\n",
    "                (PARAMS.saved_models_path, episode_i)\n",
    "            saved_PARAMS_filepath = '%s/PARAMS_episode_%d.hkl' % \\\n",
    "                (PARAMS.saved_models_path, episode_i)\n",
    "            # saved_replay_buffer_filepath = '%s/replay_buffer_episode_%d.hkl' % \\\n",
    "            #     (PARAMS.saved_models_path, episode_i)\n",
    "            \n",
    "        if path.exists(saved_train_network_filepath) and \\\n",
    "            path.exists(saved_target_network_filepath) and \\\n",
    "            path.exists(saved_PARAMS_filepath):\n",
    "            # path.exists(saved_replay_buffer_filepath):\n",
    "            \n",
    "            self.train_network.load_weights(saved_train_network_filepath)\n",
    "            self.target_network.load_weights(saved_target_network_filepath)\n",
    "            \n",
    "            PARAMS.load(hkl.load(saved_PARAMS_filepath))\n",
    "            \n",
    "            print()\n",
    "            print(\"====== Models and Parameters Loaded! ======\")\n",
    "            print(\"%s, %s, and %s loaded!\" % (saved_train_network_filepath,\n",
    "                                             saved_target_network_filepath,\n",
    "                                             saved_PARAMS_filepath))\n",
    "            print(\"Current PARAMS.epsilon: \", PARAMS.epsilon,\n",
    "                    \" PARAMS.learning_rate: \", PARAMS.learning_rate,\n",
    "                    \" PARAMS.learning_rate_decay_step: \", PARAMS.learning_rate_decay_step,\n",
    "                    \" PARAMS.cnt_frames: \", PARAMS.cnt_frames,\n",
    "                    \" PARAMS.episode_i: \", PARAMS.episode_i,\n",
    "                    \" PARAMS.max_episode_reward: \", PARAMS.max_episode_reward)\n",
    "            \n",
    "            # Load replay buffer\n",
    "            # self.replay_buffer = hkl.load(saved_replay_buffer_filepath)\n",
    "            # print(\"%s loaded!\" % saved_replay_buffer_filepath)\n",
    "            \n",
    "        else:\n",
    "            print(\"====== Saved files not exist. Start from episode 0. ======\")\n",
    "            PARAMS.episode_i = 0        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bryanbc/Apps/anaconda3/lib/python3.7/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_dim: 210  PARAMS.env.observation_space.shape:  (210, 160, 3)\n",
      "PARAMS.n_actions:  4  PARAMS.env.action_space:  Discrete(4)\n",
      "PARAMS.env.unwrapped.get_action_meanings():  ['NOOP', 'FIRE', 'RIGHT', 'LEFT']\n",
      "PARAMS.env.unwrapped.ale.lives():  5\n"
     ]
    }
   ],
   "source": [
    "# Create Environment\n",
    "PARAMS.env = gym.make(PARAMS.env_id)\n",
    "PARAMS.env = wrap_env(PARAMS.env)\n",
    "PARAMS.env.seed(PARAMS.seed_num)\n",
    "\n",
    "s_dim = PARAMS.env.observation_space.shape[0]\n",
    "PARAMS.n_actions = PARAMS.env.action_space.n\n",
    "\n",
    "print(\"s_dim:\", s_dim, \" PARAMS.env.observation_space.shape: \", PARAMS.env.observation_space.shape)\n",
    "print(\"PARAMS.n_actions: \", PARAMS.n_actions, \" PARAMS.env.action_space: \", PARAMS.env.action_space)\n",
    "# print(\"PARAMS.env.observation_space.high: \", PARAMS.env.observation_space.high)\n",
    "# print(\"PARAMS.env.observation_space.low: \", PARAMS.env.observation_space.low)\n",
    "# print(\"PARAMS.env.action_space.high: \", PARAMS.env.action_space.high)\n",
    "# print(\"PARAMS.env.action_space.low: \", PARAMS.env.action_space.low)\n",
    "print(\"PARAMS.env.unwrapped.get_action_meanings(): \", PARAMS.env.unwrapped.get_action_meanings())\n",
    "print(\"PARAMS.env.unwrapped.ale.lives(): \", PARAMS.env.unwrapped.ale.lives())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "colab_type": "code",
    "id": "3l_Q9c24GQ1M",
    "outputId": "301c1269-e4b3-4739-8e49-3b5e3fc4559e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bryanbc/Apps/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "====== Start Interacting with Env ======\n",
      "WARNING:tensorflow:From /home/bryanbc/Apps/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "PARAMS.episode_i:  0 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.9999287200000015  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  1.0  agent.save() Done!\n",
      "PARAMS.episode_i:  1 episode reward:  2.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.999815860000004  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  2.0  agent.save() Done!\n",
      "PARAMS.episode_i:  2 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.9997327000000058  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3 episode reward:  2.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.9996396400000078  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9995743000000092  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.9994713400000115  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  6 episode reward:  0.0  Episode finished after 150 timesteps\n",
      "    PARAMS.epsilon:  0.9993961000000131  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  7 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.9992951200000153  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  8 episode reward:  3.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.9991743400000179  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  3.0  agent.save() Done!\n",
      "PARAMS.episode_i:  9 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9991090000000193  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  10 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.9990199000000213  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  11 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9989525800000227  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  12 episode reward:  4.0  Episode finished after 309 timesteps\n",
      "    PARAMS.epsilon:  0.998800120000026  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  4.0  agent.save() Done!\n",
      "PARAMS.episode_i:  13 episode reward:  1.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.9987169600000279  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  14 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.9986476600000294  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  15 episode reward:  3.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.9985308400000319  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  16 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.9984278800000341  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  17 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9983605600000356  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  18 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.9982892800000371  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  19 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.9981902800000393  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  20 episode reward:  2.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.9980813800000417  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  21 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.9980140600000431  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  22 episode reward:  3.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.9978913000000458  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  23 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9978259600000472  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  24 episode reward:  0.0  Episode finished after 148 timesteps\n",
      "    PARAMS.epsilon:  0.9977527000000488  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  25 episode reward:  0.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.9976774600000504  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  26 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.9976101400000519  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  27 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.9975071800000541  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  28 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.997420060000056  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  29 episode reward:  0.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.9973448200000576  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  30 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.9972616600000594  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  31 episode reward:  2.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.9971468200000619  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  32 episode reward:  3.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.9970399000000643  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  33 episode reward:  2.0  Episode finished after 199 timesteps\n",
      "    PARAMS.epsilon:  0.9969409000000664  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  34 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.9968716000000679  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  35 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.9968023000000694  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  36 episode reward:  2.0  Episode finished after 230 timesteps\n",
      "    PARAMS.epsilon:  0.9966874600000719  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  37 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.9966023200000738  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  38 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.9965350000000752  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  39 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9964676800000767  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  40 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.9963845200000785  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  41 episode reward:  5.0  Episode finished after 371 timesteps\n",
      "    PARAMS.epsilon:  0.9962003800000825  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  5.0  agent.save() Done!\n",
      "PARAMS.episode_i:  42 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.9960815800000851  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  43 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.9960182200000864  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  44 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9959528800000879  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  45 episode reward:  2.0  Episode finished after 194 timesteps\n",
      "    PARAMS.epsilon:  0.99585586000009  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  46 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.9957707200000918  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  47 episode reward:  2.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.9956776600000938  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  48 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9956123200000953  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  49 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.9955390600000968  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  50 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9954757000000982  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  51 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.9953826400001002  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  52 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9953153200001017  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  53 episode reward:  2.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.9952202800001038  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  54 episode reward:  3.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.9950915800001066  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  55 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.9950044600001084  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  56 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.9949015000001107  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  57 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.994840120000112  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  58 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.9947391400001142  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  59 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.9946381600001164  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  60 episode reward:  2.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.9945253000001189  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  61 episode reward:  0.0  Episode finished after 149 timesteps\n",
      "    PARAMS.epsilon:  0.9944520400001204  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  62 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.9943589800001225  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  63 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.9942679000001244  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  64 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.9941827600001263  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  65 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.994103560000128  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  66 episode reward:  2.0  Episode finished after 221 timesteps\n",
      "    PARAMS.epsilon:  0.9939946600001304  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  67 episode reward:  0.0  Episode finished after 147 timesteps\n",
      "    PARAMS.epsilon:  0.993921400000132  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  68 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.9938303200001339  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  69 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9937649800001354  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  70 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.9936600400001376  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  71 episode reward:  0.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.9935828200001393  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  72 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.9934917400001413  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  73 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.993414520000143  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  74 episode reward:  0.0  Episode finished after 148 timesteps\n",
      "    PARAMS.epsilon:  0.9933412600001446  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  75 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.993275920000146  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  76 episode reward:  5.0  Episode finished after 360 timesteps\n",
      "    PARAMS.epsilon:  0.9930977200001498  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  77 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.9930205000001515  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  78 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.9929215000001537  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  79 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.9928284400001557  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  80 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9927631000001571  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  81 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.9926977600001585  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  82 episode reward:  4.0  Episode finished after 244 timesteps\n",
      "    PARAMS.epsilon:  0.9925769800001611  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  83 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.9924740200001634  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  84 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.9923849200001653  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  85 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.9923156200001668  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  86 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9922483000001683  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  87 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.9921374200001707  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  88 episode reward:  4.0  Episode finished after 317 timesteps\n",
      "    PARAMS.epsilon:  0.9919790200001741  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  89 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.9918978400001759  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  90 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.9918087400001778  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  91 episode reward:  2.0  Episode finished after 235 timesteps\n",
      "    PARAMS.epsilon:  0.9916919200001804  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  92 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.9915988600001824  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  93 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.9915117400001843  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  94 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9914444200001857  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  95 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9913751200001872  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  96 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.9912880000001891  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  97 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.9911870200001913  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  98 episode reward:  3.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.991064260000194  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  99 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.9909632800001962  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  100 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9908979400001976  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  101 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.9908088400001995  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  102 episode reward:  0.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.9907336000002012  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  103 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.9906603400002028  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  104 episode reward:  0.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.9905851000002044  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  105 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9905197600002058  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  106 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.9904425400002075  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  107 episode reward:  0.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.9903673000002091  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  108 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.990280180000211  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  109 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9902168200002124  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  110 episode reward:  0.0  Episode finished after 148 timesteps\n",
      "    PARAMS.epsilon:  0.990143560000214  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  111 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.9900425800002162  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  112 episode reward:  0.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.9899633800002179  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  113 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.98986834000022  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  114 episode reward:  0.0  Episode finished after 149 timesteps\n",
      "    PARAMS.epsilon:  0.9897950800002215  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  115 episode reward:  0.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.9897198400002232  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  116 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.9896188600002254  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  117 episode reward:  3.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.9894901600002282  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  118 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.9894208600002297  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  119 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.9892981000002323  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  120 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9892307800002338  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  121 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.9891674200002352  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  122 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.9890803000002371  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  123 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.988993180000239  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  124 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.9889060600002408  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  125 episode reward:  4.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.9887833000002435  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  126 episode reward:  0.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.9887080600002451  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  127 episode reward:  1.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.9886150000002472  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  128 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.9885100600002494  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  129 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.9884407600002509  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  130 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.9883536400002528  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  131 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.9882902800002542  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  132 episode reward:  1.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.9881912800002564  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  133 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9881279200002577  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  134 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9880586200002592  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  135 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9879932800002607  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  136 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.9879041800002626  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  137 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.9878150800002645  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  138 episode reward:  2.0  Episode finished after 193 timesteps\n",
      "    PARAMS.epsilon:  0.9877200400002666  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  139 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.9876329200002685  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  140 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.9875497600002703  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  141 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.987468580000272  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  142 episode reward:  1.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.9873755200002741  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  143 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9873062200002756  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  144 episode reward:  2.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.987193360000278  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  145 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.98710228000028  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  146 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.9870013000002822  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  147 episode reward:  5.0  Episode finished after 371 timesteps\n",
      "    PARAMS.epsilon:  0.9868171600002862  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  148 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.9867557800002875  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  149 episode reward:  3.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.9866468800002899  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  150 episode reward:  0.0  Episode finished after 147 timesteps\n",
      "    PARAMS.epsilon:  0.9865736200002915  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  151 episode reward:  0.0  Episode finished after 149 timesteps\n",
      "    PARAMS.epsilon:  0.9865003600002931  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  152 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9864350200002945  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  153 episode reward:  3.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.9863221600002969  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  154 episode reward:  2.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.986229100000299  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  155 episode reward:  2.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.9861142600003014  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  156 episode reward:  2.0  Episode finished after 196 timesteps\n",
      "    PARAMS.epsilon:  0.9860172400003036  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  157 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.985951900000305  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  158 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.9858806200003065  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  159 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.9857954800003084  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  160 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.9856806400003109  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  161 episode reward:  0.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.9856034200003125  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  162 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.9855123400003145  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  163 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.9854489800003159  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  164 episode reward:  0.0  Episode finished after 151 timesteps\n",
      "    PARAMS.epsilon:  0.9853737400003175  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  165 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.9852727600003197  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  166 episode reward:  0.0  Episode finished after 147 timesteps\n",
      "    PARAMS.epsilon:  0.9851995000003213  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  167 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.9851123800003232  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  168 episode reward:  2.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.9850193200003252  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  169 episode reward:  2.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.9849282400003272  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  170 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9848629000003286  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  171 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.9847955800003301  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  172 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.9847243000003316  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  173 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.984660940000333  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  174 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.9845975800003344  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  175 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9845322400003358  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  176 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.9844688800003372  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  177 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.9844075000003385  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  178 episode reward:  4.0  Episode finished after 336 timesteps\n",
      "    PARAMS.epsilon:  0.9842411800003421  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  179 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.9841342600003444  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  180 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.9840550600003461  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  181 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9839917000003475  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  182 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9839263600003489  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  183 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.9838372600003509  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  184 episode reward:  2.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.9837224200003534  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  185 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.9836353000003553  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  186 episode reward:  2.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.9835303600003575  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  187 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.983461060000359  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  188 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.9833818600003608  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  189 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.9833006800003625  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  190 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.9832016800003647  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  191 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.983140300000366  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  192 episode reward:  2.0  Episode finished after 199 timesteps\n",
      "    PARAMS.epsilon:  0.9830413000003682  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  193 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.9829601200003699  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  194 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.9828848800003716  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  195 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.9828155800003731  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  196 episode reward:  0.0  Episode finished after 146 timesteps\n",
      "    PARAMS.epsilon:  0.9827423200003746  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  197 episode reward:  1.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.9826492600003767  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  198 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.9825581800003786  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  199 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.9824750200003805  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  200 episode reward:  0.0  Episode finished after 146 timesteps\n",
      "    PARAMS.epsilon:  0.982401760000382  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  201 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.9823403800003834  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  202 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9822730600003848  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  203 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.9822057400003863  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  204 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.9821126800003883  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  205 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9820453600003898  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  206 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.9819820000003912  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  207 episode reward:  2.0  Episode finished after 197 timesteps\n",
      "    PARAMS.epsilon:  0.9818849800003933  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  208 episode reward:  2.0  Episode finished after 239 timesteps\n",
      "    PARAMS.epsilon:  0.9817661800003958  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  209 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.9817028200003972  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  210 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.9816394600003986  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  211 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.9815602600004003  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  212 episode reward:  2.0  Episode finished after 230 timesteps\n",
      "    PARAMS.epsilon:  0.9814474000004028  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  213 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.9813602800004047  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  214 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.9812573200004069  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  215 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.9811662400004089  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  216 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.9810989200004103  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  217 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.9810058600004123  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  218 episode reward:  2.0  Episode finished after 221 timesteps\n",
      "    PARAMS.epsilon:  0.9808969600004147  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  219 episode reward:  1.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.9808039000004167  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  220 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9807365800004182  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  221 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.9806494600004201  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  222 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.9805484800004223  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  223 episode reward:  2.0  Episode finished after 222 timesteps\n",
      "    PARAMS.epsilon:  0.9804376000004247  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  224 episode reward:  0.0  Episode finished after 149 timesteps\n",
      "    PARAMS.epsilon:  0.9803643400004263  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  225 episode reward:  1.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.9802653400004284  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  226 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.9801782200004303  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  227 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9801128800004317  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  228 episode reward:  3.0  Episode finished after 271 timesteps\n",
      "    PARAMS.epsilon:  0.9799782400004347  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  229 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.9798673600004371  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  230 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.9797822200004389  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  231 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9797168800004403  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  232 episode reward:  3.0  Episode finished after 254 timesteps\n",
      "    PARAMS.epsilon:  0.9795901600004431  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  233 episode reward:  0.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.9795149200004447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  234 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.9794139400004469  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  235 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.9793347400004486  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  236 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9792674200004501  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  237 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9792020800004515  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  238 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.9791030800004537  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  239 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9790377400004551  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  240 episode reward:  2.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.9789229000004576  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  241 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.9788437000004593  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  242 episode reward:  0.0  Episode finished after 148 timesteps\n",
      "    PARAMS.epsilon:  0.9787704400004609  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  243 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.978671440000463  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  244 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.9785863000004649  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  245 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.9784754200004673  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  246 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.9784120600004687  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  247 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.9782952400004712  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  248 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9782299000004726  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  249 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.9781408000004745  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  250 episode reward:  1.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.9780477400004766  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  251 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.9779843800004779  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  252 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.9778972600004798  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  253 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9778339000004812  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  254 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.977750740000483  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  255 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.9776656000004849  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  256 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.9775606600004871  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  257 episode reward:  3.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.9774478000004896  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  258 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.9773686000004913  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  259 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9773032600004927  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  260 episode reward:  0.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.9772280200004944  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  261 episode reward:  7.0  Episode finished after 378 timesteps\n",
      "    PARAMS.epsilon:  0.9770399200004984  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  7.0  agent.save() Done!\n",
      "PARAMS.episode_i:  262 episode reward:  0.0  Episode finished after 149 timesteps\n",
      "    PARAMS.epsilon:  0.9769666600005  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  263 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.9768953800005016  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  264 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.9768062800005035  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  265 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.976738960000505  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  266 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.9766696600005065  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  267 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9766023400005079  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  268 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.9765211600005097  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  269 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9764538400005112  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  270 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.9763489000005134  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  271 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.9762419800005158  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  272 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.9761627800005175  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  273 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9760974400005189  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  274 episode reward:  3.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.9759885400005213  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  275 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.9759271600005226  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  276 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.9758459800005244  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  277 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.9757747000005259  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  278 episode reward:  3.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.9756440200005287  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  279 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.9755608600005305  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  280 episode reward:  2.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.975449980000533  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  281 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9753826600005344  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  282 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.9752975200005363  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  283 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.9752104000005382  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  284 episode reward:  2.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.9751034800005405  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  285 episode reward:  1.0  Episode finished after 196 timesteps\n",
      "    PARAMS.epsilon:  0.9750064600005426  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  286 episode reward:  4.0  Episode finished after 294 timesteps\n",
      "    PARAMS.epsilon:  0.9748599400005458  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  287 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.9747748000005476  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  288 episode reward:  2.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.97466392000055  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  289 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.9745787800005519  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  290 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.9745114600005533  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  291 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.9744421600005548  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  292 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.9743392000005571  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  293 episode reward:  3.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.9742263400005595  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  294 episode reward:  2.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.9741214000005618  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  295 episode reward:  3.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.9739907200005646  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  296 episode reward:  0.0  Episode finished after 148 timesteps\n",
      "    PARAMS.epsilon:  0.9739174600005662  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  297 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.973836280000568  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  298 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.9737551000005698  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  299 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.9736561000005719  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  300 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9735868000005734  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  301 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.9735076000005751  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  302 episode reward:  0.0  Episode finished after 147 timesteps\n",
      "    PARAMS.epsilon:  0.9734363200005767  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  303 episode reward:  3.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.9733056400005795  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  304 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.973238320000581  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  305 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.9731531800005828  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  306 episode reward:  1.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.9730700200005846  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  307 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.9729987400005862  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  308 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.9729116200005881  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  309 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.9728007400005905  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  310 episode reward:  3.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.9726621400005935  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  311 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9725968000005949  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  312 episode reward:  2.0  Episode finished after 193 timesteps\n",
      "    PARAMS.epsilon:  0.972501760000597  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  313 episode reward:  5.0  Episode finished after 339 timesteps\n",
      "    PARAMS.epsilon:  0.9723334600006006  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  314 episode reward:  0.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.9722562400006023  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  315 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9721889200006038  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  316 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.9721196200006053  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  317 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.9720325000006071  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  318 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.9719711200006085  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  319 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.9719038000006099  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  320 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9718404400006113  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  321 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.9717493600006133  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  322 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.9716464000006155  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  323 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.971581060000617  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  324 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.9715097800006185  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  325 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9714464200006199  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  326 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.9713454400006221  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  327 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.971256340000624  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  328 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.9711751600006258  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  329 episode reward:  2.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.9710801200006278  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  330 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.9710187400006292  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  331 episode reward:  2.0  Episode finished after 194 timesteps\n",
      "    PARAMS.epsilon:  0.9709237000006312  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  332 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9708563800006327  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  333 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.9707870800006342  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  334 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.9707177800006357  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  335 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.9706326400006375  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  336 episode reward:  3.0  Episode finished after 274 timesteps\n",
      "    PARAMS.epsilon:  0.9704980000006405  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  337 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.9704346400006418  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  338 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.9703633600006434  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  339 episode reward:  1.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.9702722800006454  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  340 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.9701534800006479  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  341 episode reward:  0.0  Episode finished after 147 timesteps\n",
      "    PARAMS.epsilon:  0.9700802200006495  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  342 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.9700168600006509  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  343 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.9699277600006528  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  344 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.9698248000006551  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  345 episode reward:  2.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.9697119400006575  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  346 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.969642640000659  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  347 episode reward:  7.0  Episode finished after 266 timesteps\n",
      "    PARAMS.epsilon:  0.9695119600006619  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  348 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.9694268200006637  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  349 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9693614800006651  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  350 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.9692803000006669  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  351 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.9692169400006683  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  352 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.9691476400006698  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  353 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.9690664600006715  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  354 episode reward:  0.0  Episode finished after 147 timesteps\n",
      "    PARAMS.epsilon:  0.9689932000006731  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  355 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.9689140000006748  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  356 episode reward:  3.0  Episode finished after 244 timesteps\n",
      "    PARAMS.epsilon:  0.9687932200006775  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  357 episode reward:  1.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.9686981800006795  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  358 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.9686170000006813  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  359 episode reward:  1.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.9685140400006835  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  360 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.9684229600006855  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  361 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9683576200006869  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  362 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.9682526800006892  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  363 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.9681477400006915  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  364 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.9680843800006929  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  365 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.9680131000006944  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  366 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.9679220200006964  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  367 episode reward:  4.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.9677834200006994  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  368 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.9677161000007009  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  369 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.9676369000007026  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  370 episode reward:  1.0  Episode finished after 197 timesteps\n",
      "    PARAMS.epsilon:  0.9675379000007047  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  371 episode reward:  3.0  Episode finished after 267 timesteps\n",
      "    PARAMS.epsilon:  0.9674072200007076  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  372 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.967341880000709  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  373 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9672745600007104  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  374 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9672092200007119  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  375 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.9671399200007134  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  376 episode reward:  2.0  Episode finished after 246 timesteps\n",
      "    PARAMS.epsilon:  0.967017160000716  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  377 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.9669142000007183  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  378 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9668488600007197  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  379 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.9667617400007216  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  380 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.9666904600007231  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  381 episode reward:  2.0  Episode finished after 196 timesteps\n",
      "    PARAMS.epsilon:  0.9665934400007252  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  382 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.9665281000007266  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  383 episode reward:  1.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.9664330600007287  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  384 episode reward:  3.0  Episode finished after 277 timesteps\n",
      "    PARAMS.epsilon:  0.9662964400007317  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  385 episode reward:  0.0  Episode finished after 146 timesteps\n",
      "    PARAMS.epsilon:  0.9662251600007332  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  386 episode reward:  3.0  Episode finished after 264 timesteps\n",
      "    PARAMS.epsilon:  0.9660944800007361  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  387 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.9660093400007379  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  388 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.9659459800007393  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  389 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9658806400007407  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  390 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.9658113400007422  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  391 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.9657321400007439  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  392 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.9656390800007459  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  393 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.9655618600007476  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  394 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.9654707800007496  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  395 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.9653896000007514  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  396 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.9653222800007528  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  397 episode reward:  4.0  Episode finished after 267 timesteps\n",
      "    PARAMS.epsilon:  0.9651916000007557  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  398 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9651223000007572  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  399 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.9650431000007589  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  400 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.9649817200007602  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  401 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9649163800007616  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  402 episode reward:  2.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.9648253000007636  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  403 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.964761940000765  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  404 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9646946200007664  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  405 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9646292800007679  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  406 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.9645520600007695  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  407 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.9644807800007711  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  408 episode reward:  3.0  Episode finished after 273 timesteps\n",
      "    PARAMS.epsilon:  0.964346140000774  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  409 episode reward:  2.0  Episode finished after 220 timesteps\n",
      "    PARAMS.epsilon:  0.9642372400007764  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  410 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.9641501200007783  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  411 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.9640471600007805  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  412 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.9639481600007827  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  413 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.9638788600007842  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  414 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.9637897600007861  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  415 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9637244200007875  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  416 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.9636630400007888  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  417 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.9635719600007908  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  418 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.9634947400007925  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  419 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.9634115800007943  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  420 episode reward:  0.0  Episode finished after 151 timesteps\n",
      "    PARAMS.epsilon:  0.9633363400007959  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  421 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.9632749600007973  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  422 episode reward:  0.0  Episode finished after 148 timesteps\n",
      "    PARAMS.epsilon:  0.9632017000007989  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  423 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9631363600008003  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  424 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.9630433000008023  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  425 episode reward:  3.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.9629066800008053  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  426 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9628393600008067  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  427 episode reward:  0.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.9627641200008084  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  428 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.9626829400008101  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  429 episode reward:  2.0  Episode finished after 222 timesteps\n",
      "    PARAMS.epsilon:  0.9625740400008125  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  430 episode reward:  3.0  Episode finished after 237 timesteps\n",
      "    PARAMS.epsilon:  0.9624552400008151  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  431 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9623879200008165  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  432 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.9623126800008182  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  433 episode reward:  2.0  Episode finished after 239 timesteps\n",
      "    PARAMS.epsilon:  0.9621938800008207  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  434 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9621285400008222  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  435 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.9620394400008241  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  436 episode reward:  3.0  Episode finished after 268 timesteps\n",
      "    PARAMS.epsilon:  0.961906780000827  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  437 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9618414400008284  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  438 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.9617266000008309  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  439 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9616592800008323  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  440 episode reward:  3.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.9615206800008353  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  441 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.9614177200008376  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  442 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.9613365400008393  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  443 episode reward:  2.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.9612276400008417  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  444 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.9611642800008431  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  445 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.9610712200008451  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  446 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.960984100000847  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  447 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.9608950000008489  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  448 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9608296600008503  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  449 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.960752440000852  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  450 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.9606851200008535  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  451 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.9606059200008552  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  452 episode reward:  2.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.9604910800008577  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  453 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9604237600008592  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  454 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.9603445600008609  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  455 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9602772400008623  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  456 episode reward:  0.0  Episode finished after 147 timesteps\n",
      "    PARAMS.epsilon:  0.9602039800008639  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  457 episode reward:  3.0  Episode finished after 261 timesteps\n",
      "    PARAMS.epsilon:  0.9600752800008667  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  458 episode reward:  2.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.959968360000869  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  459 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9599010400008705  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  460 episode reward:  0.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.9598218400008722  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  461 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.9597327400008742  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  462 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.9596515600008759  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  463 episode reward:  0.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.9595743400008776  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  464 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.9594911800008794  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  465 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.9593862400008817  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  466 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9593189200008831  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  467 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.9592159600008854  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  468 episode reward:  3.0  Episode finished after 264 timesteps\n",
      "    PARAMS.epsilon:  0.9590852800008882  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  469 episode reward:  3.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.9589724200008907  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  470 episode reward:  3.0  Episode finished after 266 timesteps\n",
      "    PARAMS.epsilon:  0.9588417400008935  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  471 episode reward:  2.0  Episode finished after 194 timesteps\n",
      "    PARAMS.epsilon:  0.9587447200008956  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  472 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.9586635400008974  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  473 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.9585843400008991  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  474 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.9585071200009008  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  475 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.958406140000903  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  476 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.9583368400009045  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  477 episode reward:  3.0  Episode finished after 262 timesteps\n",
      "    PARAMS.epsilon:  0.9582081400009073  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  478 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.9581447800009086  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  479 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.9580457800009108  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  480 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.9579685600009125  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  481 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.957899260000914  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  482 episode reward:  2.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.9577943200009162  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  483 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.9576992800009183  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  484 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9576339400009197  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  485 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.9575468200009216  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  486 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.9574755400009232  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  487 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.9573725800009254  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  488 episode reward:  4.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.9572339800009284  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  489 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.9571310200009306  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  490 episode reward:  4.0  Episode finished after 316 timesteps\n",
      "    PARAMS.epsilon:  0.956974600000934  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  491 episode reward:  0.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.9568973800009357  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  492 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.9568063000009377  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  493 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9567389800009392  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  494 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.956653840000941  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  495 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.9565726600009428  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  496 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9565073200009442  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  497 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9564419800009456  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  498 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.9563746600009471  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  499 episode reward:  4.0  Episode finished after 297 timesteps\n",
      "    PARAMS.epsilon:  0.9562281400009502  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  500 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.9561390400009522  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  501 episode reward:  0.0  Episode finished after 150 timesteps\n",
      "    PARAMS.epsilon:  0.9560638000009538  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  502 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.9560004400009552  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  503 episode reward:  2.0  Episode finished after 230 timesteps\n",
      "    PARAMS.epsilon:  0.9558875800009576  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  504 episode reward:  2.0  Episode finished after 221 timesteps\n",
      "    PARAMS.epsilon:  0.95577670000096  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  505 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.9556777000009622  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  506 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.9555727600009645  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  507 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.9554935600009662  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  508 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.9553925800009684  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  509 episode reward:  3.0  Episode finished after 241 timesteps\n",
      "    PARAMS.epsilon:  0.955271800000971  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  510 episode reward:  2.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.9551609200009734  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  511 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.9550817200009751  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  512 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.9550223200009764  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  513 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.9549589600009778  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  514 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.9548698600009797  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  515 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.9548025400009812  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  516 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9547372000009826  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  517 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9546679000009841  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  518 episode reward:  3.0  Episode finished after 276 timesteps\n",
      "    PARAMS.epsilon:  0.9545312800009871  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  519 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.9544560400009887  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  520 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.9543867400009902  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  521 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.9543095200009919  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  522 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.9542204200009938  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  523 episode reward:  3.0  Episode finished after 220 timesteps\n",
      "    PARAMS.epsilon:  0.9541115200009962  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  524 episode reward:  2.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.9539986600009986  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  525 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.953935300001  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  526 episode reward:  2.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.9538224400010025  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  527 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.9537293800010045  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  528 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9536640400010059  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  529 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.9535650400010081  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  530 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.9534878200010097  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  531 episode reward:  2.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.9533769400010121  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  532 episode reward:  0.0  Episode finished after 148 timesteps\n",
      "    PARAMS.epsilon:  0.9533036800010137  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  533 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.9532145800010157  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  534 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.9531334000010174  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  535 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.9530542000010191  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  536 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.9529730200010209  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  537 episode reward:  0.0  Episode finished after 149 timesteps\n",
      "    PARAMS.epsilon:  0.9528977800010225  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  538 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.952830460001024  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  539 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.9527255200010263  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  540 episode reward:  1.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.9526324600010283  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  541 episode reward:  3.0  Episode finished after 245 timesteps\n",
      "    PARAMS.epsilon:  0.9525116800010309  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  542 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.9524225800010329  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  543 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9523552600010343  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  544 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9522919000010357  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  545 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.9521929000010378  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  546 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9521255800010393  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  547 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.9520404400010412  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  548 episode reward:  1.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.9519473800010432  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  549 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.9518563000010452  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  550 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.9517889800010466  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  551 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.951725620001048  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  552 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.9516444400010498  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  553 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.9515731600010513  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  554 episode reward:  2.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.9514563400010538  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  555 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.9513632800010559  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  556 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.9512722000010578  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  557 episode reward:  2.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.9511652800010602  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  558 episode reward:  2.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.9510464800010627  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  559 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9509791600010642  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  560 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.9508999600010659  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  561 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.9508227400010676  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  562 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.9507197800010698  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  563 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9506504800010713  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  564 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9505871200010727  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  565 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9505178200010742  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  566 episode reward:  2.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.9504109000010765  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  567 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.9503237800010784  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  568 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9502564600010799  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  569 episode reward:  3.0  Episode finished after 261 timesteps\n",
      "    PARAMS.epsilon:  0.9501277600010827  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  570 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.9500406400010846  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  571 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.949975300001086  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  572 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.9498961000010877  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  573 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9498268000010892  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  574 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9497594800010907  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  575 episode reward:  3.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.9496466200010931  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  576 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.9495634600010949  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  577 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.9494921800010965  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  578 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.9493892200010987  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  579 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9493238800011001  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  580 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.9492229000011023  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  581 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9491575600011037  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  582 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9490922200011052  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  583 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.949005100001107  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  584 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.9489001600011093  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  585 episode reward:  2.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.9487932400011116  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  586 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9487279000011131  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  587 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9486625600011145  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  588 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.948593260001116  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  589 episode reward:  1.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.948500200001118  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  590 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.9484111000011199  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  591 episode reward:  1.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.9483279400011217  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  592 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9482606200011232  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  593 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.9481695400011252  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  594 episode reward:  2.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.9480626200011275  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  595 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.9480012400011288  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  596 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9479339200011303  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  597 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.9478408600011323  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  598 episode reward:  2.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.9477478000011343  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  599 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.9476606800011362  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  600 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.9475597000011384  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  601 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.94748842000114  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  602 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.9474013000011419  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  603 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.9473320000011434  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  604 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9472646800011448  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  605 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.9471835000011466  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  606 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.947118160001148  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  607 episode reward:  0.0  Episode finished after 151 timesteps\n",
      "    PARAMS.epsilon:  0.9470449000011496  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  608 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.9469657000011513  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  609 episode reward:  1.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.946890460001153  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  610 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.9468112600011547  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  611 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9467439400011561  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  612 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.9466726600011577  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  613 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9466073200011591  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  614 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.946522180001161  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  615 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.9464014000011636  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  616 episode reward:  1.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.9463083400011656  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  617 episode reward:  0.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.9462271600011674  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  618 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.9461360800011693  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  619 episode reward:  0.0  Episode finished after 150 timesteps\n",
      "    PARAMS.epsilon:  0.9460628200011709  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  620 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9459974800011723  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  621 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9459321400011738  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  622 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.945829180001176  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  623 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.9457499800011777  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  624 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.9456292000011803  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  625 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9455599000011818  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  626 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9454925800011833  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  627 episode reward:  2.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.9453995200011853  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  628 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.9453143800011872  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  629 episode reward:  1.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.9452153800011893  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  630 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.9451262800011913  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  631 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.9450371800011932  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  632 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.9449124400011959  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  633 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.9448490800011973  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  634 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9447817600011987  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  635 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.9446887000012008  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  636 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.9446095000012025  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  637 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.944538220001204  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  638 episode reward:  2.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.9444313000012063  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  639 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.9443620000012078  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  640 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.9442511200012103  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  641 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9441857800012117  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  642 episode reward:  2.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.9440709400012142  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  643 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9440016400012157  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  644 episode reward:  1.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.9439085800012177  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  645 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.94380166000122  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  646 episode reward:  4.0  Episode finished after 302 timesteps\n",
      "    PARAMS.epsilon:  0.9436511800012233  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  647 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.943573960001225  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  648 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.9434868400012268  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  649 episode reward:  3.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.9433640800012295  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  650 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9432987400012309  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  651 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.9432334000012323  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  652 episode reward:  2.0  Episode finished after 199 timesteps\n",
      "    PARAMS.epsilon:  0.9431344000012345  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  653 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.9430433200012365  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  654 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.942974020001238  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  655 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9429106600012394  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  656 episode reward:  5.0  Episode finished after 375 timesteps\n",
      "    PARAMS.epsilon:  0.9427245400012434  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  657 episode reward:  0.0  Episode finished after 150 timesteps\n",
      "    PARAMS.epsilon:  0.942649300001245  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  658 episode reward:  1.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.942556240001247  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  659 episode reward:  3.0  Episode finished after 265 timesteps\n",
      "    PARAMS.epsilon:  0.9424255600012499  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  660 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.9423186400012522  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  661 episode reward:  3.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.9421859800012551  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  662 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9421206400012565  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  663 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.9420315400012584  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  664 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.9419404600012604  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  665 episode reward:  3.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.9418335400012627  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  666 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.9417682000012642  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  667 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.9417028600012656  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  668 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.9416256400012673  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  669 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9415583200012687  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  670 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.9414771400012705  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  671 episode reward:  2.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.9413662600012729  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  672 episode reward:  0.0  Episode finished after 149 timesteps\n",
      "    PARAMS.epsilon:  0.9412930000012745  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  673 episode reward:  1.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.9411979600012765  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  674 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.9410752000012792  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  675 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.9410118400012806  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  676 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.9409267000012824  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  677 episode reward:  3.0  Episode finished after 235 timesteps\n",
      "    PARAMS.epsilon:  0.940809880001285  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  678 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.9407207800012869  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  679 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.9406574200012883  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  680 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.9405524800012905  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  681 episode reward:  3.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.9404277400012933  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  682 episode reward:  4.0  Episode finished after 292 timesteps\n",
      "    PARAMS.epsilon:  0.9402832000012964  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  683 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.9402139000012979  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  684 episode reward:  2.0  Episode finished after 230 timesteps\n",
      "    PARAMS.epsilon:  0.9400990600013004  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  685 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.9400198600013021  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  686 episode reward:  2.0  Episode finished after 198 timesteps\n",
      "    PARAMS.epsilon:  0.9399228400013042  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  687 episode reward:  2.0  Episode finished after 193 timesteps\n",
      "    PARAMS.epsilon:  0.9398278000013063  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  688 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9397585000013078  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  689 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.9396713800013097  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  690 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.939608020001311  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  691 episode reward:  4.0  Episode finished after 276 timesteps\n",
      "    PARAMS.epsilon:  0.939471400001314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  692 episode reward:  1.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.9393763600013161  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  693 episode reward:  2.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.9392714200013184  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  694 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.9391783600013204  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  695 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.9390793600013225  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  696 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.939010060001324  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  697 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.9389427400013255  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  698 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.9388635400013272  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  699 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.9387744400013291  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  700 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9387110800013305  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  701 episode reward:  6.0  Episode finished after 342 timesteps\n",
      "    PARAMS.epsilon:  0.9385408000013342  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  702 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.9384695200013358  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  703 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.9383923000013374  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  704 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.9383071600013393  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  705 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.9382358800013408  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  706 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.938134900001343  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  707 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.9380477800013449  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  708 episode reward:  4.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.937907200001348  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  709 episode reward:  2.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.9377963200013504  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  710 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.9377111800013522  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  711 episode reward:  2.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.9376220800013542  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  712 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9375547600013556  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  713 episode reward:  4.0  Episode finished after 265 timesteps\n",
      "    PARAMS.epsilon:  0.9374221000013585  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  714 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.93735478000136  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  715 episode reward:  2.0  Episode finished after 196 timesteps\n",
      "    PARAMS.epsilon:  0.9372577600013621  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  716 episode reward:  2.0  Episode finished after 199 timesteps\n",
      "    PARAMS.epsilon:  0.9371587600013642  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  717 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.9370597600013664  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  718 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9369904600013679  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  719 episode reward:  0.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.9369132400013696  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  720 episode reward:  4.0  Episode finished after 274 timesteps\n",
      "    PARAMS.epsilon:  0.9367766200013725  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  721 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.936709300001374  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  722 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9366439600013754  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  723 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.9365746600013769  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  724 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.9365053600013784  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  725 episode reward:  2.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.9363984400013807  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  726 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.9363311200013822  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  727 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.9362281600013844  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  728 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.9361489600013861  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  729 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.9360499600013883  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  730 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.9359846200013897  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  731 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.9359034400013915  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  732 episode reward:  0.0  Episode finished after 150 timesteps\n",
      "    PARAMS.epsilon:  0.9358282000013931  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  733 episode reward:  2.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.9357094000013957  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  734 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.9356242600013975  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  735 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.935558920001399  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  736 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.9354955600014003  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  737 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.9354084400014022  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  738 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.9353233000014041  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  739 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.9352480600014057  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  740 episode reward:  3.0  Episode finished after 275 timesteps\n",
      "    PARAMS.epsilon:  0.9351114400014087  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  741 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.9350203600014106  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  742 episode reward:  3.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.934913440001413  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  743 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9348461200014144  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  744 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.9347827600014158  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  745 episode reward:  2.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.9346758400014181  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  746 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9346105000014195  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  747 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.934545160001421  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  748 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.9344402200014232  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  749 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.9343352800014255  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  750 episode reward:  7.0  Episode finished after 403 timesteps\n",
      "    PARAMS.epsilon:  0.9341372800014298  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  751 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.9340679800014313  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  752 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.9339769000014333  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  753 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.9338858200014353  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  754 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.9338224600014366  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  755 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9337571200014381  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  756 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.9336917800014395  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  757 episode reward:  3.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.9335789200014419  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  758 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.9334997200014437  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  759 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.9334106200014456  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  760 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.9333096400014478  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  761 episode reward:  2.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.9331967800014502  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  762 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.9330938200014525  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  763 episode reward:  6.0  Episode finished after 381 timesteps\n",
      "    PARAMS.epsilon:  0.9329057200014566  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  764 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.9328225600014584  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  765 episode reward:  2.0  Episode finished after 221 timesteps\n",
      "    PARAMS.epsilon:  0.9327116800014608  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  766 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.932610700001463  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  767 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.9324938800014655  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  768 episode reward:  1.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.9323988400014676  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  769 episode reward:  3.0  Episode finished after 289 timesteps\n",
      "    PARAMS.epsilon:  0.9322562800014706  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  770 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.9321533200014729  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  771 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.9320523400014751  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  772 episode reward:  3.0  Episode finished after 273 timesteps\n",
      "    PARAMS.epsilon:  0.931917700001478  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  773 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.9318147400014802  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  774 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.9317078200014826  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  775 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.931642480001484  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  776 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.9315652600014857  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  777 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.9314722000014877  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  778 episode reward:  0.0  Episode finished after 151 timesteps\n",
      "    PARAMS.epsilon:  0.9313969600014893  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  779 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.9313157800014911  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  780 episode reward:  4.0  Episode finished after 318 timesteps\n",
      "    PARAMS.epsilon:  0.9311573800014945  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  781 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.9310504600014968  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  782 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9309851200014982  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  783 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9309178000014997  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  784 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.9308346400015015  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  785 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.9307554400015032  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  786 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.9306782200015049  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  787 episode reward:  2.0  Episode finished after 220 timesteps\n",
      "    PARAMS.epsilon:  0.9305693200015073  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  788 episode reward:  5.0  Episode finished after 325 timesteps\n",
      "    PARAMS.epsilon:  0.9304089400015108  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  789 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.9303455800015121  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  790 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.930258460001514  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  791 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.9301713400015159  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  792 episode reward:  0.0  Episode finished after 124 timesteps\n",
      "    PARAMS.epsilon:  0.9301099600015172  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  793 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.930030760001519  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  794 episode reward:  4.0  Episode finished after 321 timesteps\n",
      "    PARAMS.epsilon:  0.9298703800015224  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  795 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.9297911800015242  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  796 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.9297238600015256  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  797 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.9296090200015281  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  798 episode reward:  4.0  Episode finished after 284 timesteps\n",
      "    PARAMS.epsilon:  0.9294684400015312  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  799 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.9294050800015325  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  800 episode reward:  1.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.9293140000015345  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  801 episode reward:  2.0  Episode finished after 195 timesteps\n",
      "    PARAMS.epsilon:  0.9292169800015366  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  802 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9291496600015381  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  803 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.9290882800015394  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  804 episode reward:  5.0  Episode finished after 339 timesteps\n",
      "    PARAMS.epsilon:  0.9289199800015431  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  805 episode reward:  0.0  Episode finished after 147 timesteps\n",
      "    PARAMS.epsilon:  0.9288467200015447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  806 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.9287437600015469  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  807 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.9286665400015486  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  808 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.9285754600015506  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  809 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.9284863600015525  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  810 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9284210200015539  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  811 episode reward:  0.0  Episode finished after 148 timesteps\n",
      "    PARAMS.epsilon:  0.9283477600015555  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  812 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.9282586600015574  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  813 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.9281794600015592  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  814 episode reward:  1.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.928096300001561  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  815 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.9280171000015627  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  816 episode reward:  2.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.927912160001565  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  817 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.9278309800015667  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  818 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9277636600015682  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  819 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9276963400015696  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  820 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.9275973400015718  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  821 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.9275082400015737  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  822 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.9274072600015759  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  823 episode reward:  4.0  Episode finished after 277 timesteps\n",
      "    PARAMS.epsilon:  0.9272706400015789  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  824 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.9271835200015808  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  825 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.9270924400015828  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  826 episode reward:  4.0  Episode finished after 315 timesteps\n",
      "    PARAMS.epsilon:  0.9269360200015861  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  827 episode reward:  2.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.9268251400015886  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  828 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.9267419800015904  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  829 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.9266627800015921  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  830 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.9265776400015939  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  831 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.9265083400015954  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  832 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9264430000015969  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  833 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.9263578600015987  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  834 episode reward:  8.0  Episode finished after 470 timesteps\n",
      "    PARAMS.epsilon:  0.9261242200016038  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  8.0  agent.save() Done!\n",
      "PARAMS.episode_i:  835 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9260588800016052  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  836 episode reward:  2.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.9259658200016072  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  837 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.9258767200016091  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  838 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.9258054400016107  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  839 episode reward:  2.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.9256846600016133  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  840 episode reward:  3.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.9255520000016162  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  841 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.925470820001618  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  842 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.9253837000016198  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  843 episode reward:  0.0  Episode finished after 124 timesteps\n",
      "    PARAMS.epsilon:  0.9253223200016212  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  844 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.9252451000016229  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  845 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9251777800016243  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  846 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9251104600016258  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  847 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.9250233400016277  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  848 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.9249005800016303  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  849 episode reward:  1.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.9248055400016324  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  850 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.9247223800016342  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  851 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.9246590200016356  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  852 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.9245699200016375  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  853 episode reward:  2.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.9244748800016396  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  854 episode reward:  3.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.9243481600016423  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  855 episode reward:  2.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.9242412400016446  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  856 episode reward:  0.0  Episode finished after 146 timesteps\n",
      "    PARAMS.epsilon:  0.9241679800016462  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  857 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.9240808600016481  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  858 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.9240056200016498  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  859 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.9239204800016516  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  860 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.9238333600016535  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  861 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.9237719800016548  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  862 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9237066400016563  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  863 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.9236393200016577  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  864 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.9235561600016595  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  865 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.9234650800016615  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  866 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.9233641000016637  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  867 episode reward:  2.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.9232472800016662  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  868 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9231819400016676  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  869 episode reward:  1.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.9230987800016695  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  870 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.9230077000016714  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  871 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.9229146400016734  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  872 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9228493000016749  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  873 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.9227602000016768  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  874 episode reward:  3.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.9226414000016794  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  875 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9225740800016808  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  876 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.9224968600016825  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  877 episode reward:  5.0  Episode finished after 361 timesteps\n",
      "    PARAMS.epsilon:  0.9223166800016864  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  878 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.9222157000016886  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  879 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.9221127400016909  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  880 episode reward:  3.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.9219741400016939  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  881 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.9218949400016956  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  882 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.921827620001697  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  883 episode reward:  1.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.9217444600016989  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  884 episode reward:  2.0  Episode finished after 222 timesteps\n",
      "    PARAMS.epsilon:  0.9216335800017013  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  885 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.9215484400017031  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  886 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.9214850800017045  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  887 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.9214058800017062  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  888 episode reward:  2.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.9212930200017087  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  889 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.9211920400017108  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  890 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.921093040001713  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  891 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.9210138400017147  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  892 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.9209445400017162  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  893 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.9208732600017178  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  894 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9208059400017192  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  895 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.9207366400017207  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  896 episode reward:  1.0  Episode finished after 197 timesteps\n",
      "    PARAMS.epsilon:  0.9206396200017228  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  897 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.9205544800017247  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  898 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.9204733000017264  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  899 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9204079600017279  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  900 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.9203366800017294  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  901 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9202693600017309  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  902 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.9201426400017336  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  903 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.9200396800017359  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  904 episode reward:  2.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.9199268200017383  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  905 episode reward:  4.0  Episode finished after 289 timesteps\n",
      "    PARAMS.epsilon:  0.9197842600017414  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  906 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.9197209000017428  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  907 episode reward:  3.0  Episode finished after 237 timesteps\n",
      "    PARAMS.epsilon:  0.9196040800017453  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  908 episode reward:  3.0  Episode finished after 290 timesteps\n",
      "    PARAMS.epsilon:  0.9194595400017485  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  909 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.9193585600017506  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  910 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.9192694600017526  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  911 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.9191843200017544  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  912 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.919113040001756  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  913 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.919021960001758  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  914 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9189546400017594  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  915 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.9188635600017614  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  916 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.9187843600017631  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  917 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.9187130800017647  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  918 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.9186200200017667  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  919 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.9185368600017685  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  920 episode reward:  2.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.9184418200017705  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  921 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.918372520001772  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  922 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.9183111400017734  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  923 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.9182200600017754  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  924 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.9181388800017771  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  925 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.9180755200017785  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  926 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.9179864200017804  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  927 episode reward:  2.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.9178953400017824  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  928 episode reward:  0.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.917820100001784  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  929 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.917729020001786  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  930 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9176597200017875  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  931 episode reward:  2.0  Episode finished after 222 timesteps\n",
      "    PARAMS.epsilon:  0.9175508200017899  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  932 episode reward:  8.0  Episode finished after 306 timesteps\n",
      "    PARAMS.epsilon:  0.9173983600017932  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  933 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9173330200017946  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  934 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.917267680001796  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  935 episode reward:  4.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.9171271000017991  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  936 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.9170360200018011  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  937 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.9169310800018033  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  938 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.9168459400018052  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  939 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.9167449600018074  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  940 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.9166519000018094  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  941 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.9165509200018116  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  942 episode reward:  1.0  Episode finished after 198 timesteps\n",
      "    PARAMS.epsilon:  0.9164539000018137  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  943 episode reward:  3.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.9163331200018163  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  944 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.9162380800018184  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  945 episode reward:  3.0  Episode finished after 245 timesteps\n",
      "    PARAMS.epsilon:  0.916117300001821  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  946 episode reward:  3.0  Episode finished after 244 timesteps\n",
      "    PARAMS.epsilon:  0.9159965200018236  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  947 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.9158698000018264  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  948 episode reward:  0.0  Episode finished after 149 timesteps\n",
      "    PARAMS.epsilon:  0.915796540001828  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  949 episode reward:  1.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.91570348000183  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  950 episode reward:  0.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.9156242800018317  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  951 episode reward:  1.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.9155411200018335  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  952 episode reward:  3.0  Episode finished after 221 timesteps\n",
      "    PARAMS.epsilon:  0.9154322200018359  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  953 episode reward:  2.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.915337180001838  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  954 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.9152500600018398  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  955 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.9151708600018416  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  956 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.9150857200018434  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  957 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.9149827600018456  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  958 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.9148976200018475  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  959 episode reward:  2.0  Episode finished after 230 timesteps\n",
      "    PARAMS.epsilon:  0.91478278000185  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  960 episode reward:  4.0  Episode finished after 300 timesteps\n",
      "    PARAMS.epsilon:  0.9146342800018532  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  961 episode reward:  0.0  Episode finished after 149 timesteps\n",
      "    PARAMS.epsilon:  0.9145610200018548  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  962 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.9144739000018567  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  963 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.9143887600018585  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  964 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.9142897600018607  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  965 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.9142085800018624  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  966 episode reward:  1.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.9141076000018646  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  967 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.9140303800018663  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  968 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.9139432600018682  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  969 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.9138660400018699  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  970 episode reward:  2.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.9137512000018724  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  971 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9136858600018738  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  972 episode reward:  4.0  Episode finished after 287 timesteps\n",
      "    PARAMS.epsilon:  0.9135452800018768  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  973 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.9134561800018788  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  974 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.9133314400018815  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  975 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.913264120001883  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  976 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.9131631400018851  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  977 episode reward:  1.0  Episode finished after 151 timesteps\n",
      "    PARAMS.epsilon:  0.9130879000018868  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  978 episode reward:  2.0  Episode finished after 195 timesteps\n",
      "    PARAMS.epsilon:  0.9129908800018889  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  979 episode reward:  2.0  Episode finished after 245 timesteps\n",
      "    PARAMS.epsilon:  0.9128701000018915  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  980 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.9127829800018934  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  981 episode reward:  0.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.9127018000018952  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  982 episode reward:  1.0  Episode finished after 150 timesteps\n",
      "    PARAMS.epsilon:  0.9126285400018967  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  983 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9125612200018982  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  984 episode reward:  3.0  Episode finished after 241 timesteps\n",
      "    PARAMS.epsilon:  0.9124424200019008  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  985 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.9123572800019026  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  986 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.9122899600019041  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  987 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.9121988800019061  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  988 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.9121276000019076  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  989 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9120602800019091  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  990 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9119949400019105  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  991 episode reward:  2.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.911882080001913  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  992 episode reward:  1.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.9117811000019151  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  993 episode reward:  2.0  Episode finished after 230 timesteps\n",
      "    PARAMS.epsilon:  0.9116682400019176  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  994 episode reward:  2.0  Episode finished after 220 timesteps\n",
      "    PARAMS.epsilon:  0.91155934000192  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  995 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.9114544000019222  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  996 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9113910400019236  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  997 episode reward:  2.0  Episode finished after 237 timesteps\n",
      "    PARAMS.epsilon:  0.9112722400019262  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  998 episode reward:  1.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.9111791800019282  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  999 episode reward:  3.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.9110465200019311  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1000 episode reward:  2.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.9109396000019334  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1001 episode reward:  3.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.9108069400019363  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1002 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.9107000200019386  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1003 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.9106287400019402  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1004 episode reward:  1.0  Episode finished after 198 timesteps\n",
      "    PARAMS.epsilon:  0.9105317200019423  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1005 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9104644000019437  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1006 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.9103792600019456  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1007 episode reward:  3.0  Episode finished after 244 timesteps\n",
      "    PARAMS.epsilon:  0.9102584800019482  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1008 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.9101535400019505  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1009 episode reward:  4.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.9100050400019537  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1010 episode reward:  5.0  Episode finished after 374 timesteps\n",
      "    PARAMS.epsilon:  0.9098189200019577  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1011 episode reward:  4.0  Episode finished after 289 timesteps\n",
      "    PARAMS.epsilon:  0.9096763600019608  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1012 episode reward:  1.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.9095813200019629  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1013 episode reward:  3.0  Episode finished after 246 timesteps\n",
      "    PARAMS.epsilon:  0.9094605400019655  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1014 episode reward:  1.0  Episode finished after 195 timesteps\n",
      "    PARAMS.epsilon:  0.9093635200019676  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1015 episode reward:  1.0  Episode finished after 196 timesteps\n",
      "    PARAMS.epsilon:  0.9092665000019697  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1016 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.9091912600019714  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1017 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9091239400019728  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1018 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.9090328600019748  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1019 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.9089615800019764  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1020 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.9088982200019777  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1021 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9088289200019792  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1022 episode reward:  3.0  Episode finished after 252 timesteps\n",
      "    PARAMS.epsilon:  0.9087041800019819  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1023 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.9086289400019836  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1024 episode reward:  3.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.9085002400019864  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1025 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.9084111400019883  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1026 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9083438200019898  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1027 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9082765000019912  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1028 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.9082052200019928  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1029 episode reward:  0.0  Episode finished after 148 timesteps\n",
      "    PARAMS.epsilon:  0.9081319600019944  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1030 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9080646400019958  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1031 episode reward:  2.0  Episode finished after 237 timesteps\n",
      "    PARAMS.epsilon:  0.9079458400019984  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1032 episode reward:  2.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.9078349600020008  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1033 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.907733980002003  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1034 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9076666600020045  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1035 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.907595380002006  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1036 episode reward:  0.0  Episode finished after 147 timesteps\n",
      "    PARAMS.epsilon:  0.9075221200020076  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1037 episode reward:  0.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.9074468800020092  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1038 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.9073597600020111  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1039 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.9072924400020126  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1040 episode reward:  1.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.9072013600020146  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1041 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.9071122600020165  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1042 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.9070489000020179  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1043 episode reward:  0.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.9069736600020195  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1044 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.9069122800020208  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1045 episode reward:  1.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.9068172400020229  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1046 episode reward:  2.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.9067043800020254  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1047 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.9066350800020269  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1048 episode reward:  2.0  Episode finished after 220 timesteps\n",
      "    PARAMS.epsilon:  0.9065261800020292  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1049 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.9064568800020307  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1050 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.9063955000020321  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1051 episode reward:  0.0  Episode finished after 147 timesteps\n",
      "    PARAMS.epsilon:  0.9063222400020337  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1052 episode reward:  3.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.9061836400020367  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1053 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9061143400020382  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1054 episode reward:  3.0  Episode finished after 261 timesteps\n",
      "    PARAMS.epsilon:  0.905985640002041  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1055 episode reward:  0.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.9059084200020426  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1056 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.9058213000020445  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1057 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.905755960002046  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1058 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.9056846800020475  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1059 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.905617360002049  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1060 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.9055381600020507  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1061 episode reward:  2.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.9054094600020535  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1062 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.905340160002055  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1063 episode reward:  0.0  Episode finished after 146 timesteps\n",
      "    PARAMS.epsilon:  0.9052669000020566  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1064 episode reward:  3.0  Episode finished after 230 timesteps\n",
      "    PARAMS.epsilon:  0.905154040002059  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1065 episode reward:  1.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.9050708800020608  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1066 episode reward:  4.0  Episode finished after 275 timesteps\n",
      "    PARAMS.epsilon:  0.9049342600020638  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1067 episode reward:  5.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.9047699200020674  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1068 episode reward:  4.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.9046412200020701  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1069 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.9045739000020716  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1070 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.9044689600020739  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1071 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.9043976800020754  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1072 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9043303600020769  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1073 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9042670000020783  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1074 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.9041838400020801  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1075 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.9041185000020815  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1076 episode reward:  2.0  Episode finished after 198 timesteps\n",
      "    PARAMS.epsilon:  0.9040214800020836  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1077 episode reward:  2.0  Episode finished after 235 timesteps\n",
      "    PARAMS.epsilon:  0.9039046600020861  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1078 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.9038373400020876  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1079 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.903773980002089  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1080 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.9036710200020912  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1081 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.9036076600020926  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1082 episode reward:  3.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.9034928200020951  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1083 episode reward:  2.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.9033799600020975  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1084 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.903312640002099  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1085 episode reward:  2.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.9031898800021017  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1086 episode reward:  4.0  Episode finished after 261 timesteps\n",
      "    PARAMS.epsilon:  0.9030611800021044  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1087 episode reward:  3.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.9029384200021071  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1088 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.902849320002109  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1089 episode reward:  4.0  Episode finished after 277 timesteps\n",
      "    PARAMS.epsilon:  0.902712700002112  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1090 episode reward:  1.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.9026117200021142  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1091 episode reward:  3.0  Episode finished after 226 timesteps\n",
      "    PARAMS.epsilon:  0.9025008400021166  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1092 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.9023998600021188  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1093 episode reward:  3.0  Episode finished after 245 timesteps\n",
      "    PARAMS.epsilon:  0.9022790800021214  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1094 episode reward:  8.0  Episode finished after 418 timesteps\n",
      "    PARAMS.epsilon:  0.9020711800021259  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1095 episode reward:  4.0  Episode finished after 294 timesteps\n",
      "    PARAMS.epsilon:  0.9019266400021291  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1096 episode reward:  1.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.901835560002131  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1097 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.9017543800021328  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1098 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.9016771600021345  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1099 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.9016118200021359  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1100 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.9015247000021378  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1101 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.9014395600021397  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1102 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.9013524400021415  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1103 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.9012811600021431  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1104 episode reward:  1.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.9011861200021452  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1105 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9011207800021466  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1106 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.9010138600021489  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1107 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.9009227800021509  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1108 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.9008574400021523  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1109 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.9007663600021543  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1110 episode reward:  4.0  Episode finished after 290 timesteps\n",
      "    PARAMS.epsilon:  0.9006218200021574  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1111 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.9005347000021593  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1112 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.900409960002162  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1113 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.9003367000021636  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1114 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.9002674000021651  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1115 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.9001426600021678  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1116 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.9000753400021693  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1117 episode reward:  0.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.9000001000021709  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1118 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.8999149600021727  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1119 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.8998258600021747  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1120 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.8997446800021764  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1121 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.8996793400021779  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1122 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.8996041000021795  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1123 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.8995150000021814  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1124 episode reward:  3.0  Episode finished after 268 timesteps\n",
      "    PARAMS.epsilon:  0.8993823400021843  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1125 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.8992892800021863  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1126 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8992259200021877  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1127 episode reward:  2.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.8991328600021897  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1128 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.8990398000021917  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1129 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.8989526800021936  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1130 episode reward:  3.0  Episode finished after 246 timesteps\n",
      "    PARAMS.epsilon:  0.8988299200021963  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1131 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.8987645800021977  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1132 episode reward:  6.0  Episode finished after 376 timesteps\n",
      "    PARAMS.epsilon:  0.8985784600022018  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1133 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.898477480002204  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1134 episode reward:  4.0  Episode finished after 295 timesteps\n",
      "    PARAMS.epsilon:  0.8983309600022071  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1135 episode reward:  3.0  Episode finished after 259 timesteps\n",
      "    PARAMS.epsilon:  0.8982022600022099  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1136 episode reward:  3.0  Episode finished after 247 timesteps\n",
      "    PARAMS.epsilon:  0.8980795000022126  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1137 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.8979745600022149  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1138 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.8978894200022167  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1139 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.8978260600022181  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1140 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.8977191400022204  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1141 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.8976181600022226  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1142 episode reward:  3.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.8974775800022257  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1143 episode reward:  4.0  Episode finished after 289 timesteps\n",
      "    PARAMS.epsilon:  0.8973350200022288  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1144 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.8972558200022305  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1145 episode reward:  1.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.8971607800022325  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1146 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8970835600022342  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1147 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.8969825800022364  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1148 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.8968994200022382  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1149 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.89681626000224  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1150 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.8967449800022416  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1151 episode reward:  0.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.8966677600022432  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1152 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.8966024200022447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1153 episode reward:  2.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.8965073800022467  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1154 episode reward:  3.0  Episode finished after 245 timesteps\n",
      "    PARAMS.epsilon:  0.8963866000022493  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1155 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.8963034400022512  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1156 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.8962143400022531  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1157 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.8961331600022548  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1158 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.8960539600022566  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1159 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.8959906000022579  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1160 episode reward:  0.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.8959074400022597  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1161 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.8958401200022612  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1162 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.8957728000022627  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1163 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.895711420002264  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1164 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8956460800022654  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1165 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.8955569800022674  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1166 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.8954678800022693  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1167 episode reward:  5.0  Episode finished after 384 timesteps\n",
      "    PARAMS.epsilon:  0.8952778000022734  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1168 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.8952124600022748  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1169 episode reward:  2.0  Episode finished after 199 timesteps\n",
      "    PARAMS.epsilon:  0.895113460002277  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1170 episode reward:  0.0  Episode finished after 146 timesteps\n",
      "    PARAMS.epsilon:  0.8950421800022785  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1171 episode reward:  3.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.894929320002281  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1172 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.8948481400022827  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1173 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.8947669600022845  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1174 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.8947016200022859  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1175 episode reward:  3.0  Episode finished after 246 timesteps\n",
      "    PARAMS.epsilon:  0.8945808400022885  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1176 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.8944739200022909  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1177 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.8943868000022928  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1178 episode reward:  3.0  Episode finished after 244 timesteps\n",
      "    PARAMS.epsilon:  0.8942660200022954  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1179 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8942006800022968  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1180 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.8941096000022988  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1181 episode reward:  4.0  Episode finished after 306 timesteps\n",
      "    PARAMS.epsilon:  0.893959120002302  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1182 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8938937800023035  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1183 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.8938284400023049  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1184 episode reward:  5.0  Episode finished after 368 timesteps\n",
      "    PARAMS.epsilon:  0.8936462800023088  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1185 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.8935433200023111  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1186 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.8934799600023124  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1187 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.893410660002314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1188 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.8933215600023159  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1189 episode reward:  3.0  Episode finished after 264 timesteps\n",
      "    PARAMS.epsilon:  0.8931908800023187  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1190 episode reward:  2.0  Episode finished after 222 timesteps\n",
      "    PARAMS.epsilon:  0.8930800000023211  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1191 episode reward:  2.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.8929651600023236  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1192 episode reward:  2.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.892854280002326  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1193 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.8927533000023282  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1194 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.8926463800023305  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1195 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.8925572800023325  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1196 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.892487980002334  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1197 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.8924028400023358  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1198 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.8923097800023378  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1199 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.8922385000023394  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1200 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.8921692000023409  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1201 episode reward:  2.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.8920622800023432  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1202 episode reward:  2.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.8919454600023458  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1203 episode reward:  3.0  Episode finished after 272 timesteps\n",
      "    PARAMS.epsilon:  0.8918108200023487  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1204 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8917454800023501  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1205 episode reward:  2.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.8916524200023521  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1206 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.891567280002354  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1207 episode reward:  4.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.891426700002357  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1208 episode reward:  0.0  Episode finished after 146 timesteps\n",
      "    PARAMS.epsilon:  0.8913554200023586  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1209 episode reward:  2.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.8912405800023611  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1210 episode reward:  1.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.8911475200023631  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1211 episode reward:  2.0  Episode finished after 196 timesteps\n",
      "    PARAMS.epsilon:  0.8910505000023652  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1212 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.8909713000023669  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1213 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.8908802200023689  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1214 episode reward:  0.0  Episode finished after 149 timesteps\n",
      "    PARAMS.epsilon:  0.8908069600023705  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1215 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.8907277600023722  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1216 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.8906604400023737  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1217 episode reward:  3.0  Episode finished after 239 timesteps\n",
      "    PARAMS.epsilon:  0.8905436200023762  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1218 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.8904505600023782  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1219 episode reward:  3.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.8903119600023812  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1220 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.8902050400023835  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1221 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.890139700002385  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1222 episode reward:  1.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.890046640002387  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1223 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8899832800023884  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1224 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.8899159600023898  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1225 episode reward:  3.0  Episode finished after 237 timesteps\n",
      "    PARAMS.epsilon:  0.8897991400023924  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1226 episode reward:  4.0  Episode finished after 252 timesteps\n",
      "    PARAMS.epsilon:  0.8896744000023951  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1227 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.8895932200023968  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1228 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.8895041200023988  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1229 episode reward:  2.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.8893952200024011  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1230 episode reward:  2.0  Episode finished after 199 timesteps\n",
      "    PARAMS.epsilon:  0.8892962200024033  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1231 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.889217020002405  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1232 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.8891299000024069  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1233 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.8890526800024086  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1234 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.8889734800024103  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1235 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.8888843800024122  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1236 episode reward:  0.0  Episode finished after 124 timesteps\n",
      "    PARAMS.epsilon:  0.8888230000024135  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1237 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.8886962800024163  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1238 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8886329200024177  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1239 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.8885477800024195  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1240 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.888478480002421  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1241 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.8883775000024232  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1242 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.8883101800024247  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1243 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.8881993000024271  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1244 episode reward:  1.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.8881062400024291  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1245 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.8880290200024308  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1246 episode reward:  4.0  Episode finished after 301 timesteps\n",
      "    PARAMS.epsilon:  0.887880520002434  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1247 episode reward:  3.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.8877617200024366  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1248 episode reward:  5.0  Episode finished after 323 timesteps\n",
      "    PARAMS.epsilon:  0.8876013400024401  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1249 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.887514220002442  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1250 episode reward:  4.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.8873875000024447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1251 episode reward:  1.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.8872865200024469  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1252 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.8871835600024491  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1253 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8871182200024506  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1254 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.8870568400024519  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1255 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8869954600024532  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1256 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.8868905200024555  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1257 episode reward:  3.0  Episode finished after 276 timesteps\n",
      "    PARAMS.epsilon:  0.8867539000024585  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1258 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.88668460000246  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1259 episode reward:  2.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.8865776800024623  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1260 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.8864727400024646  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1261 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.8863816600024665  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1262 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8863183000024679  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1263 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8862529600024693  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1264 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.8861678200024712  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1265 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.886086640002473  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1266 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.8860015000024748  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1267 episode reward:  0.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.8859223000024765  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1268 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.8858193400024788  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1269 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.8857520200024802  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1270 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.8856510400024824  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1271 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.8855104600024855  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1272 episode reward:  4.0  Episode finished after 303 timesteps\n",
      "    PARAMS.epsilon:  0.8853599800024887  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1273 episode reward:  4.0  Episode finished after 289 timesteps\n",
      "    PARAMS.epsilon:  0.8852174200024918  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1274 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.8851065400024942  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1275 episode reward:  2.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.8849897200024968  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1276 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.8849243800024982  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1277 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.8848471600024999  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1278 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.8847798400025013  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1279 episode reward:  4.0  Episode finished after 291 timesteps\n",
      "    PARAMS.epsilon:  0.8846372800025044  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1280 episode reward:  3.0  Episode finished after 237 timesteps\n",
      "    PARAMS.epsilon:  0.884518480002507  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1281 episode reward:  3.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.8843897800025098  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1282 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.8843244400025112  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1283 episode reward:  3.0  Episode finished after 254 timesteps\n",
      "    PARAMS.epsilon:  0.8841997000025139  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1284 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.8841323800025154  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1285 episode reward:  5.0  Episode finished after 318 timesteps\n",
      "    PARAMS.epsilon:  0.8839759600025188  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1286 episode reward:  3.0  Episode finished after 252 timesteps\n",
      "    PARAMS.epsilon:  0.8838512200025215  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1287 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8837740000025232  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1288 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.8836750000025253  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1289 episode reward:  3.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.8835601600025278  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1290 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8834968000025292  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1291 episode reward:  2.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.8833859200025316  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1292 episode reward:  4.0  Episode finished after 298 timesteps\n",
      "    PARAMS.epsilon:  0.8832374200025348  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1293 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.8831681200025363  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1294 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.8830988200025378  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1295 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.8830374400025391  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1296 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.882952300002541  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1297 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.8828513200025432  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1298 episode reward:  2.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.8827404400025456  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1299 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.882677080002547  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1300 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.8825899600025489  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1301 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.8825127400025505  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1302 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8824355200025522  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1303 episode reward:  0.0  Episode finished after 147 timesteps\n",
      "    PARAMS.epsilon:  0.8823622600025538  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1304 episode reward:  2.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.8822513800025562  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1305 episode reward:  6.0  Episode finished after 403 timesteps\n",
      "    PARAMS.epsilon:  0.8820533800025605  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1306 episode reward:  3.0  Episode finished after 262 timesteps\n",
      "    PARAMS.epsilon:  0.8819227000025633  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1307 episode reward:  5.0  Episode finished after 324 timesteps\n",
      "    PARAMS.epsilon:  0.8817623200025668  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1308 episode reward:  4.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.8816217400025699  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1309 episode reward:  2.0  Episode finished after 220 timesteps\n",
      "    PARAMS.epsilon:  0.8815128400025722  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1310 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8814514600025736  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1311 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.8813742400025752  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1312 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.8813049400025768  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1313 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.8812237600025785  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1314 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.8811584200025799  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1315 episode reward:  2.0  Episode finished after 226 timesteps\n",
      "    PARAMS.epsilon:  0.8810455600025824  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1316 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.8809782400025838  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1317 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.8809188400025851  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1318 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.8808416200025868  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1319 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.8807782600025882  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1320 episode reward:  7.0  Episode finished after 397 timesteps\n",
      "    PARAMS.epsilon:  0.8805802600025925  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1321 episode reward:  4.0  Episode finished after 277 timesteps\n",
      "    PARAMS.epsilon:  0.8804436400025955  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1322 episode reward:  1.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.8803486000025975  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1323 episode reward:  4.0  Episode finished after 292 timesteps\n",
      "    PARAMS.epsilon:  0.8802040600026007  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1324 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.8800793200026034  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1325 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8800159600026047  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1326 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.879911020002607  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1327 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8798496400026083  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1328 episode reward:  5.0  Episode finished after 364 timesteps\n",
      "    PARAMS.epsilon:  0.8796694600026123  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1329 episode reward:  2.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.8795783800026142  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1330 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.8794774000026164  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1331 episode reward:  4.0  Episode finished after 297 timesteps\n",
      "    PARAMS.epsilon:  0.8793308800026196  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1332 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.8792437600026215  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1333 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8791804000026229  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1334 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.8790932800026248  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1335 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.878990320002627  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1336 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.8789051800026288  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1337 episode reward:  3.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.8787784600026316  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1338 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.8787091600026331  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1339 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.8786438200026345  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1340 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.8785666000026362  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1341 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.8784775000026381  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1342 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.8784161200026395  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1343 episode reward:  3.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.8782894000026422  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1344 episode reward:  2.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.8781765400026447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1345 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.8781072400026462  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1346 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.8780201200026481  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1347 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.8779409200026498  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1348 episode reward:  2.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.8778260800026523  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1349 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.877744900002654  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1350 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.8776439200026562  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1351 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.8775587800026581  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1352 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.8774597800026602  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1353 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.877380580002662  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1354 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.8772934600026638  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1355 episode reward:  3.0  Episode finished after 235 timesteps\n",
      "    PARAMS.epsilon:  0.8771786200026663  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1356 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.8770895200026683  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1357 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.8770004200026702  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1358 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.8769113200026721  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1359 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.8768420200026736  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1360 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.8767766800026751  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1361 episode reward:  4.0  Episode finished after 304 timesteps\n",
      "    PARAMS.epsilon:  0.8766262000026783  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1362 episode reward:  3.0  Episode finished after 273 timesteps\n",
      "    PARAMS.epsilon:  0.8764915600026812  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1363 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.876408400002683  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1364 episode reward:  4.0  Episode finished after 297 timesteps\n",
      "    PARAMS.epsilon:  0.8762618800026862  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1365 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.8761589200026885  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1366 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.8760737800026903  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1367 episode reward:  5.0  Episode finished after 348 timesteps\n",
      "    PARAMS.epsilon:  0.8759015200026941  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1368 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.8757985600026963  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1369 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.8756975800026985  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1370 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.8756342200026999  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1371 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.8755708600027012  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1372 episode reward:  2.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.8754659200027035  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1373 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.8753392000027063  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1374 episode reward:  3.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.8752045600027092  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1375 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.875119420002711  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1376 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.8750521000027125  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1377 episode reward:  3.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.8749253800027152  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1378 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.8748640000027166  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1379 episode reward:  0.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.8747867800027183  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1380 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.8747194600027197  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1381 episode reward:  4.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.8745967000027224  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1382 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8745194800027241  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1383 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.8744561200027254  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1384 episode reward:  4.0  Episode finished after 290 timesteps\n",
      "    PARAMS.epsilon:  0.8743135600027285  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1385 episode reward:  2.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.8742205000027305  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1386 episode reward:  2.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.8741274400027326  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1387 episode reward:  4.0  Episode finished after 269 timesteps\n",
      "    PARAMS.epsilon:  0.8739947800027354  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1388 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.8738898400027377  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1389 episode reward:  3.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.8737651000027404  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1390 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.8736720400027425  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1391 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8736086800027438  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1392 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.8735453200027452  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1393 episode reward:  4.0  Episode finished after 284 timesteps\n",
      "    PARAMS.epsilon:  0.8734047400027483  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1394 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.87332554000275  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1395 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.8732225800027522  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1396 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.8731433800027539  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1397 episode reward:  3.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.8730344800027563  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1398 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.8729533000027581  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1399 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8728760800027597  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1400 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.8728107400027612  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1401 episode reward:  1.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.8727196600027631  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1402 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.8726563000027645  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1403 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.8725751200027663  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1404 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.8725078000027677  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1405 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.8724266200027695  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1406 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.8723375200027714  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1407 episode reward:  4.0  Episode finished after 259 timesteps\n",
      "    PARAMS.epsilon:  0.8722088200027742  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1408 episode reward:  2.0  Episode finished after 235 timesteps\n",
      "    PARAMS.epsilon:  0.8720939800027767  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1409 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.8720167600027784  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1410 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.8719553800027797  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1411 episode reward:  4.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.8718167800027827  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1412 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.871713820002785  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1413 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.8716247200027869  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1414 episode reward:  2.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.8715098800027894  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1415 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.8714306800027911  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1416 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.8713316800027933  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1417 episode reward:  3.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.8712227800027956  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1418 episode reward:  2.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.871115860002798  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1419 episode reward:  3.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.8709911200028007  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1420 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.8709000400028026  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1421 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.870834700002804  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1422 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.8707099600028068  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1423 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.8706466000028081  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1424 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.8705674000028099  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1425 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.8704268200028129  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1426 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.8703575200028144  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1427 episode reward:  0.0  Episode finished after 147 timesteps\n",
      "    PARAMS.epsilon:  0.870284260002816  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1428 episode reward:  2.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.870193180002818  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1429 episode reward:  4.0  Episode finished after 267 timesteps\n",
      "    PARAMS.epsilon:  0.8700605200028209  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1430 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.869959540002823  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1431 episode reward:  4.0  Episode finished after 288 timesteps\n",
      "    PARAMS.epsilon:  0.8698169800028261  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1432 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.8697496600028276  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1433 episode reward:  3.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.8696288800028302  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1434 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.869547700002832  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1435 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.8694605800028339  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1436 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.8693675200028359  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1437 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.8692606000028382  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1438 episode reward:  2.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.8691675400028402  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1439 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.8691022000028417  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1440 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.8690131000028436  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1441 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.868947760002845  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1442 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.868854700002847  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1443 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.8687794600028487  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1444 episode reward:  4.0  Episode finished after 308 timesteps\n",
      "    PARAMS.epsilon:  0.868627000002852  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1445 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.8685121600028545  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1446 episode reward:  4.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.8683894000028571  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1447 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.8683003000028591  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1448 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.8682310000028606  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1449 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.868167640002862  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1450 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.8681003200028634  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1451 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.8680369600028648  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1452 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.8679676600028663  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1453 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.867840940002869  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1454 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.8677716400028705  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1455 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.867702340002872  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1456 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.8676231400028738  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1457 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.8675419600028755  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1458 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8674786000028769  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1459 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.8674132600028783  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1460 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.8673479200028797  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1461 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.8672608000028816  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1462 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.867197440002883  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1463 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.8670984400028852  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1464 episode reward:  4.0  Episode finished after 302 timesteps\n",
      "    PARAMS.epsilon:  0.8669479600028884  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1465 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.8668786600028899  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1466 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8668014400028916  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1467 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.8667182800028934  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1468 episode reward:  9.0  Episode finished after 438 timesteps\n",
      "    PARAMS.epsilon:  0.8665024600028981  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  9.0  agent.save() Done!\n",
      "PARAMS.episode_i:  1469 episode reward:  2.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.8663915800029005  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1470 episode reward:  3.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.8662708000029031  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1471 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.8661698200029053  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1472 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.8660787400029073  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1473 episode reward:  4.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.8659441000029102  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1474 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.8658827200029116  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1475 episode reward:  2.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.8657758000029139  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1476 episode reward:  3.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.8656609600029164  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1477 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.8655619600029185  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1478 episode reward:  4.0  Episode finished after 300 timesteps\n",
      "    PARAMS.epsilon:  0.8654134600029217  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1479 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.8653342600029235  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1480 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.865262980002925  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1481 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.8651778400029269  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1482 episode reward:  4.0  Episode finished after 292 timesteps\n",
      "    PARAMS.epsilon:  0.86503330000293  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1483 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.8649560800029317  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1484 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.8648610400029337  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1485 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.8647778800029355  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1486 episode reward:  3.0  Episode finished after 252 timesteps\n",
      "    PARAMS.epsilon:  0.8646531400029382  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1487 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8645897800029396  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1488 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.8645026600029415  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1489 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.8644393000029429  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1490 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.8643363400029451  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1491 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.8642333800029474  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1492 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8641680400029488  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1493 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.8641007200029502  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1494 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.8640056800029523  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1495 episode reward:  0.0  Episode finished after 122 timesteps\n",
      "    PARAMS.epsilon:  0.8639462800029536  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1496 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.863880940002955  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1497 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.8637958000029569  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1498 episode reward:  2.0  Episode finished after 221 timesteps\n",
      "    PARAMS.epsilon:  0.8636849200029593  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1499 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8636215600029606  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1500 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.8635403800029624  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1501 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.8634572200029642  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1502 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.8633324800029669  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1503 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.8632295200029692  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1504 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8631661600029705  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1505 episode reward:  6.0  Episode finished after 317 timesteps\n",
      "    PARAMS.epsilon:  0.863007760002974  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1506 episode reward:  4.0  Episode finished after 275 timesteps\n",
      "    PARAMS.epsilon:  0.8628731200029769  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1507 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.8627662000029792  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1508 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.862683040002981  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1509 episode reward:  0.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.8626038400029827  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1510 episode reward:  4.0  Episode finished after 303 timesteps\n",
      "    PARAMS.epsilon:  0.862453360002986  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1511 episode reward:  2.0  Episode finished after 193 timesteps\n",
      "    PARAMS.epsilon:  0.8623583200029881  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1512 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.8622910000029895  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1513 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.8622118000029912  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1514 episode reward:  4.0  Episode finished after 288 timesteps\n",
      "    PARAMS.epsilon:  0.8620692400029943  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1515 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.861992020002996  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1516 episode reward:  4.0  Episode finished after 266 timesteps\n",
      "    PARAMS.epsilon:  0.8618593600029989  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1517 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.8617960000030003  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1518 episode reward:  4.0  Episode finished after 333 timesteps\n",
      "    PARAMS.epsilon:  0.8616316600030038  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1519 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.8615504800030056  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1520 episode reward:  4.0  Episode finished after 273 timesteps\n",
      "    PARAMS.epsilon:  0.8614158400030085  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1521 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.8613386200030102  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1522 episode reward:  8.0  Episode finished after 450 timesteps\n",
      "    PARAMS.epsilon:  0.861116860003015  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1523 episode reward:  3.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.8610059800030174  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1524 episode reward:  3.0  Episode finished after 220 timesteps\n",
      "    PARAMS.epsilon:  0.8608970800030198  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1525 episode reward:  7.0  Episode finished after 350 timesteps\n",
      "    PARAMS.epsilon:  0.8607228400030236  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1526 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8606456200030252  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1527 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.8605565200030272  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1528 episode reward:  3.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.8604397000030297  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1529 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.8603743600030311  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1530 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.8602852600030331  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1531 episode reward:  1.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.8601902200030351  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1532 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.8601268600030365  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1533 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.8600357800030385  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1534 episode reward:  5.0  Episode finished after 308 timesteps\n",
      "    PARAMS.epsilon:  0.8598833200030418  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1535 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.8597783800030441  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1536 episode reward:  3.0  Episode finished after 272 timesteps\n",
      "    PARAMS.epsilon:  0.859643740003047  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1537 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.8595764200030485  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1538 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.8594952400030502  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1539 episode reward:  4.0  Episode finished after 269 timesteps\n",
      "    PARAMS.epsilon:  0.8593606000030531  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1540 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.8592913000030546  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1541 episode reward:  3.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.8591784400030571  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1542 episode reward:  0.0  Episode finished after 149 timesteps\n",
      "    PARAMS.epsilon:  0.8591051800030587  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1543 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.8590200400030605  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1544 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.8589408400030623  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1545 episode reward:  2.0  Episode finished after 195 timesteps\n",
      "    PARAMS.epsilon:  0.8588438200030644  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1546 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.858721060003067  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1547 episode reward:  4.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.85858642000307  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1548 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.8584973200030719  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1549 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.8584062400030739  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1550 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.8583428800030752  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1551 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.8582359600030776  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1552 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.8581646800030791  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1553 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.8580993400030805  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1554 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.8580161800030823  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1555 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.8579231200030843  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1556 episode reward:  2.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.8578300600030864  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1557 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.8577587800030879  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1558 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.8576756200030897  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1559 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.8575865200030917  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1560 episode reward:  4.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.8574479200030947  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1561 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.8573548600030967  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1562 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8572895200030981  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1563 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.8572024000031  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1564 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.8570994400031022  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1565 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.8570004400031044  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1566 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8569351000031058  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1567 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.8568539200031076  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1568 episode reward:  2.0  Episode finished after 226 timesteps\n",
      "    PARAMS.epsilon:  0.85674106000311  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1569 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.8566222600031126  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1570 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.8565173200031149  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1571 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.8564519800031163  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1572 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.8563866400031177  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1573 episode reward:  4.0  Episode finished after 294 timesteps\n",
      "    PARAMS.epsilon:  0.8562401200031209  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1574 episode reward:  3.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.8561114200031237  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1575 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.8560421200031252  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1576 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.8559748000031266  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1577 episode reward:  2.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.8558619400031291  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1578 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.8557966000031305  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1579 episode reward:  1.0  Episode finished after 195 timesteps\n",
      "    PARAMS.epsilon:  0.8556995800031326  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1580 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.8556184000031344  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1581 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.8555194000031365  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1582 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.8553946600031392  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1583 episode reward:  4.0  Episode finished after 305 timesteps\n",
      "    PARAMS.epsilon:  0.8552441800031425  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1584 episode reward:  2.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.8551352800031449  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1585 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.8550679600031463  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1586 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.8550006400031478  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1587 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.8549155000031496  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1588 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.8548501600031511  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1589 episode reward:  6.0  Episode finished after 391 timesteps\n",
      "    PARAMS.epsilon:  0.8546561200031553  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1590 episode reward:  5.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.8544917800031588  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1591 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.8543848600031612  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1592 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.8543215000031625  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1593 episode reward:  3.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.8542027000031651  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1594 episode reward:  8.0  Episode finished after 484 timesteps\n",
      "    PARAMS.epsilon:  0.8539631200031703  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1595 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.8538779800031722  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1596 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.853792840003174  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1597 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.8536978000031761  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1598 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.853610680003178  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1599 episode reward:  5.0  Episode finished after 306 timesteps\n",
      "    PARAMS.epsilon:  0.8534582200031813  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1600 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.853381000003183  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1601 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.8532760600031852  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1602 episode reward:  4.0  Episode finished after 308 timesteps\n",
      "    PARAMS.epsilon:  0.8531236000031885  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1603 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.85305430000319  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1604 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.8529790600031917  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1605 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.8528860000031937  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1606 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.8527830400031959  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1607 episode reward:  3.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.8526642400031985  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1608 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.8525612800032007  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1609 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.8524761400032026  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1610 episode reward:  4.0  Episode finished after 300 timesteps\n",
      "    PARAMS.epsilon:  0.8523276400032058  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1611 episode reward:  3.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.8522147800032083  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1612 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.8521494400032097  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1613 episode reward:  5.0  Episode finished after 344 timesteps\n",
      "    PARAMS.epsilon:  0.8519791600032134  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1614 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.8518900600032153  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1615 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.8517890800032175  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1616 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.8517059200032193  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1617 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.8516405800032207  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1618 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.8515752400032222  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1619 episode reward:  4.0  Episode finished after 287 timesteps\n",
      "    PARAMS.epsilon:  0.8514326800032253  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1620 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.8513297200032275  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1621 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.8512663600032289  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1622 episode reward:  2.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.8511535000032313  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1623 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.8510822200032329  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1624 episode reward:  0.0  Episode finished after 151 timesteps\n",
      "    PARAMS.epsilon:  0.8510069800032345  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1625 episode reward:  3.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.8508842200032372  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1626 episode reward:  4.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.85075552000324  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1627 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.8506862200032415  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1628 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.8506010800032433  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1629 episode reward:  2.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.8504882200032458  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1630 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.8503733800032482  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1631 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.8503060600032497  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1632 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8502407200032511  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1633 episode reward:  3.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.8501140000032539  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1634 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.8500308400032557  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1635 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.8499397600032577  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1636 episode reward:  5.0  Episode finished after 308 timesteps\n",
      "    PARAMS.epsilon:  0.849787300003261  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1637 episode reward:  4.0  Episode finished after 321 timesteps\n",
      "    PARAMS.epsilon:  0.8496289000032644  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1638 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8495497000032661  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1639 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.8494348600032686  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1640 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8493576400032703  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1641 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.8492923000032717  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1642 episode reward:  2.0  Episode finished after 194 timesteps\n",
      "    PARAMS.epsilon:  0.8491952800032738  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1643 episode reward:  3.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.8490685600032766  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1644 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.8489636200032789  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1645 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.8488982800032803  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1646 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.8488131400032821  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1647 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.848724040003284  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1648 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.8486606800032854  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1649 episode reward:  5.0  Episode finished after 311 timesteps\n",
      "    PARAMS.epsilon:  0.8485062400032888  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1650 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8484428800032902  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1651 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.8483815000032915  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1652 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.8482904200032935  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1653 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.8481894400032957  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1654 episode reward:  3.0  Episode finished after 254 timesteps\n",
      "    PARAMS.epsilon:  0.8480647000032984  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1655 episode reward:  3.0  Episode finished after 252 timesteps\n",
      "    PARAMS.epsilon:  0.8479399600033011  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1656 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.8478766000033024  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1657 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.847807300003304  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1658 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.8477399800033054  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1659 episode reward:  3.0  Episode finished after 268 timesteps\n",
      "    PARAMS.epsilon:  0.8476073200033083  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1660 episode reward:  5.0  Episode finished after 359 timesteps\n",
      "    PARAMS.epsilon:  0.8474291200033122  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1661 episode reward:  3.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.8473024000033149  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1662 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.8472370600033163  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1663 episode reward:  0.0  Episode finished after 147 timesteps\n",
      "    PARAMS.epsilon:  0.8471657800033179  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1664 episode reward:  3.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.8470529200033203  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1665 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.8469499600033226  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1666 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.846882640003324  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1667 episode reward:  3.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.8467658200033266  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1668 episode reward:  5.0  Episode finished after 324 timesteps\n",
      "    PARAMS.epsilon:  0.84660544000333  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1669 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.8465401000033315  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1670 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8464767400033328  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1671 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.8463975400033346  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1672 episode reward:  4.0  Episode finished after 309 timesteps\n",
      "    PARAMS.epsilon:  0.8462431000033379  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1673 episode reward:  3.0  Episode finished after 235 timesteps\n",
      "    PARAMS.epsilon:  0.8461282600033404  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1674 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.846056980003342  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1675 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.8459698600033438  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1676 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.8459045200033453  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1677 episode reward:  2.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.8457976000033476  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1678 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.8456708800033503  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1679 episode reward:  5.0  Episode finished after 315 timesteps\n",
      "    PARAMS.epsilon:  0.8455144600033537  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1680 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8454511000033551  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1681 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.8453877400033565  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1682 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.8453204200033579  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1683 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.8452432000033596  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1684 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.8451501400033616  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1685 episode reward:  2.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.845043220003364  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1686 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.8449580800033658  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1687 episode reward:  2.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.8448452200033683  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1688 episode reward:  3.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.8447363200033706  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1689 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8446591000033723  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1690 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.8445957400033737  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1691 episode reward:  3.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.8444670400033765  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1692 episode reward:  4.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.8443363600033793  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1693 episode reward:  5.0  Episode finished after 288 timesteps\n",
      "    PARAMS.epsilon:  0.8441938000033824  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1694 episode reward:  2.0  Episode finished after 194 timesteps\n",
      "    PARAMS.epsilon:  0.8440967800033845  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1695 episode reward:  2.0  Episode finished after 244 timesteps\n",
      "    PARAMS.epsilon:  0.8439760000033871  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1696 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.8438770000033893  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1697 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.8438096800033907  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1698 episode reward:  2.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.8437166200033928  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1699 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.8436314800033946  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1700 episode reward:  4.0  Episode finished after 292 timesteps\n",
      "    PARAMS.epsilon:  0.8434869400033977  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1701 episode reward:  2.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.8433958600033997  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1702 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.8433067600034017  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1703 episode reward:  3.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.8431939000034041  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1704 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.8430909400034063  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1705 episode reward:  4.0  Episode finished after 284 timesteps\n",
      "    PARAMS.epsilon:  0.8429503600034094  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1706 episode reward:  2.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.8428592800034114  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1707 episode reward:  2.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.8427682000034133  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1708 episode reward:  10.0  Episode finished after 377 timesteps\n",
      "    PARAMS.epsilon:  0.8425801000034174  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  10.0  agent.save() Done!\n",
      "PARAMS.episode_i:  1709 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.8424791200034196  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1710 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.8424019000034213  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1711 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.8422989400034235  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1712 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.8422355800034249  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1713 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.8421445000034269  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1714 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.8420672800034286  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1715 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.8419722400034306  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1716 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.8418673000034329  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1717 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.8417663200034351  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1718 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.8416891000034368  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1719 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.8416059400034386  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1720 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.84153862000344  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1721 episode reward:  2.0  Episode finished after 196 timesteps\n",
      "    PARAMS.epsilon:  0.8414416000034421  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1722 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.8413782400034435  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1723 episode reward:  9.0  Episode finished after 402 timesteps\n",
      "    PARAMS.epsilon:  0.8411802400034478  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1724 episode reward:  4.0  Episode finished after 261 timesteps\n",
      "    PARAMS.epsilon:  0.8410515400034506  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1725 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.8409723400034523  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1726 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.8408812600034543  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1727 episode reward:  2.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.8407921600034562  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1728 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.8407070200034581  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1729 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.8406238600034599  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1730 episode reward:  3.0  Episode finished after 238 timesteps\n",
      "    PARAMS.epsilon:  0.8405050600034625  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1731 episode reward:  1.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.8404120000034645  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1732 episode reward:  7.0  Episode finished after 421 timesteps\n",
      "    PARAMS.epsilon:  0.840204100003469  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1733 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.8401387600034704  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1734 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.8400278800034728  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1735 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.8399467000034746  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1736 episode reward:  0.0  Episode finished after 124 timesteps\n",
      "    PARAMS.epsilon:  0.8398853200034759  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1737 episode reward:  2.0  Episode finished after 198 timesteps\n",
      "    PARAMS.epsilon:  0.8397863200034781  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1738 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.8397209800034795  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1739 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.8396160400034818  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1740 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.8395388200034835  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1741 episode reward:  2.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.8394279400034859  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1742 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8393507200034875  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1743 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.8392636000034894  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1744 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.8391844000034911  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1745 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.839097280003493  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1746 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8390200600034947  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1747 episode reward:  1.0  Episode finished after 193 timesteps\n",
      "    PARAMS.epsilon:  0.8389250200034968  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1748 episode reward:  3.0  Episode finished after 261 timesteps\n",
      "    PARAMS.epsilon:  0.8387943400034996  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1749 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.8386537600035027  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1750 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.8385725800035044  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1751 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.8385072400035058  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1752 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.838406260003508  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1753 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.8382953800035104  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1754 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.8382043000035124  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1755 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8381409400035138  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1756 episode reward:  3.0  Episode finished after 238 timesteps\n",
      "    PARAMS.epsilon:  0.8380221400035164  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1757 episode reward:  4.0  Episode finished after 278 timesteps\n",
      "    PARAMS.epsilon:  0.8378855200035193  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1758 episode reward:  2.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.8377924600035214  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1759 episode reward:  4.0  Episode finished after 316 timesteps\n",
      "    PARAMS.epsilon:  0.8376360400035248  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1760 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.8375588200035264  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1761 episode reward:  0.0  Episode finished after 124 timesteps\n",
      "    PARAMS.epsilon:  0.8374974400035278  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1762 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.8374103200035297  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1763 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.8373311200035314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1764 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.8372638000035328  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1765 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.8372004400035342  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1766 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8371232200035359  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1767 episode reward:  4.0  Episode finished after 262 timesteps\n",
      "    PARAMS.epsilon:  0.8369945200035387  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1768 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.8369133400035405  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1769 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.8368499800035418  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1770 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.8367569200035438  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1771 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.8366876200035454  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1772 episode reward:  2.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.8365985200035473  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1773 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.8364975400035495  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1774 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.8364183400035512  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1775 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8363549800035526  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1776 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.8362777600035542  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1777 episode reward:  3.0  Episode finished after 235 timesteps\n",
      "    PARAMS.epsilon:  0.8361609400035568  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1778 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.8360837200035585  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1779 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.8360183800035599  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1780 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.8359391800035616  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1781 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.8358540400035634  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1782 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.8357510800035657  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1783 episode reward:  2.0  Episode finished after 197 timesteps\n",
      "    PARAMS.epsilon:  0.8356540600035678  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1784 episode reward:  2.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.8355629800035698  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1785 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.8354699200035718  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1786 episode reward:  4.0  Episode finished after 266 timesteps\n",
      "    PARAMS.epsilon:  0.8353392400035746  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1787 episode reward:  4.0  Episode finished after 305 timesteps\n",
      "    PARAMS.epsilon:  0.8351867800035779  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1788 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.8351095600035796  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1789 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.8350066000035818  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1790 episode reward:  5.0  Episode finished after 311 timesteps\n",
      "    PARAMS.epsilon:  0.8348521600035852  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1791 episode reward:  3.0  Episode finished after 226 timesteps\n",
      "    PARAMS.epsilon:  0.8347412800035876  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1792 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.8346363400035899  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1793 episode reward:  3.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.8345314000035922  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1794 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.8344680400035935  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1795 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.8343888400035953  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1796 episode reward:  1.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.8343136000035969  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1797 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.8342522200035982  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1798 episode reward:  4.0  Episode finished after 305 timesteps\n",
      "    PARAMS.epsilon:  0.8341017400036015  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1799 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.8340364000036029  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1800 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.8339651200036045  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1801 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.8338859200036062  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1802 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.8337809800036085  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1803 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8337176200036098  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1804 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.8336027800036123  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1805 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.833525560003614  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1806 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.8334206200036163  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1807 episode reward:  4.0  Episode finished after 282 timesteps\n",
      "    PARAMS.epsilon:  0.8332800400036193  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1808 episode reward:  3.0  Episode finished after 259 timesteps\n",
      "    PARAMS.epsilon:  0.8331533200036221  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1809 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8330741200036238  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1810 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.8329969000036255  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1811 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.8329157200036272  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1812 episode reward:  3.0  Episode finished after 276 timesteps\n",
      "    PARAMS.epsilon:  0.8327791000036302  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1813 episode reward:  3.0  Episode finished after 277 timesteps\n",
      "    PARAMS.epsilon:  0.8326424800036332  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1814 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.8325514000036351  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1815 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.832464280003637  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1816 episode reward:  5.0  Episode finished after 313 timesteps\n",
      "    PARAMS.epsilon:  0.8323098400036404  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1817 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.8322425200036419  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1818 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.8321613400036436  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1819 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.8320762000036455  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1820 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.8319871000036474  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1821 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.8319197800036489  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1822 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8318425600036505  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1823 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.831777220003652  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1824 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.8316940600036538  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1825 episode reward:  2.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.8316010000036558  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1826 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.8315099200036578  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1827 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.8314406200036593  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1828 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.8313198400036619  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1829 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.8312545000036633  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1830 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.831177280003665  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1831 episode reward:  1.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.831082240003667  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1832 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.8310030400036688  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1833 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.830902060003671  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1834 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8308367200036724  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1835 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.8307674200036739  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1836 episode reward:  3.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.8306466400036765  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1837 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.8305654600036783  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1838 episode reward:  3.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.830438740003681  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1839 episode reward:  8.0  Episode finished after 455 timesteps\n",
      "    PARAMS.epsilon:  0.8302150000036859  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1840 episode reward:  2.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.8300981800036884  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1841 episode reward:  3.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.8299873000036908  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1842 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.8299100800036925  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1843 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.829838800003694  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1844 episode reward:  5.0  Episode finished after 355 timesteps\n",
      "    PARAMS.epsilon:  0.8296645600036978  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1845 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.8295734800036998  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1846 episode reward:  2.0  Episode finished after 197 timesteps\n",
      "    PARAMS.epsilon:  0.8294764600037019  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1847 episode reward:  2.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.8293695400037042  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1848 episode reward:  10.0  Episode finished after 497 timesteps\n",
      "    PARAMS.epsilon:  0.8291240200037095  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1849 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.829056700003711  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1850 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.8289794800037127  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1851 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.8289002800037144  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1852 episode reward:  5.0  Episode finished after 355 timesteps\n",
      "    PARAMS.epsilon:  0.8287260400037182  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1853 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.8286587200037197  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1854 episode reward:  4.0  Episode finished after 269 timesteps\n",
      "    PARAMS.epsilon:  0.8285260600037225  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1855 episode reward:  2.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.8284310200037246  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1856 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.8283538000037263  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1857 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.8282686600037281  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1858 episode reward:  2.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.8281756000037301  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1859 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.8280488800037329  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1860 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.8279479000037351  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1861 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.8278845400037365  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1862 episode reward:  3.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.8277776200037388  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1863 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.8277063400037403  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1864 episode reward:  3.0  Episode finished after 239 timesteps\n",
      "    PARAMS.epsilon:  0.8275875400037429  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1865 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.8275261600037442  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1866 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8274647800037456  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1867 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.8273875600037472  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1868 episode reward:  2.0  Episode finished after 194 timesteps\n",
      "    PARAMS.epsilon:  0.8272905400037494  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1869 episode reward:  7.0  Episode finished after 265 timesteps\n",
      "    PARAMS.epsilon:  0.8271598600037522  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1870 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.827078680003754  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1871 episode reward:  6.0  Episode finished after 382 timesteps\n",
      "    PARAMS.epsilon:  0.826890580003758  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1872 episode reward:  3.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.8267797000037604  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1873 episode reward:  7.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.8266529800037632  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1874 episode reward:  3.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.8265460600037655  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1875 episode reward:  4.0  Episode finished after 268 timesteps\n",
      "    PARAMS.epsilon:  0.8264134000037684  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1876 episode reward:  3.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.826292620003771  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1877 episode reward:  3.0  Episode finished after 252 timesteps\n",
      "    PARAMS.epsilon:  0.8261678800037737  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1878 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.8260807600037756  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1879 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.8259877000037776  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1880 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.825924340003779  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1881 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.8258392000037809  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1882 episode reward:  6.0  Episode finished after 357 timesteps\n",
      "    PARAMS.epsilon:  0.8256629800037847  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1883 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.8255837800037864  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1884 episode reward:  6.0  Episode finished after 355 timesteps\n",
      "    PARAMS.epsilon:  0.8254075600037902  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1885 episode reward:  5.0  Episode finished after 334 timesteps\n",
      "    PARAMS.epsilon:  0.8252432200037938  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1886 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.825140260003796  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1887 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.8250769000037974  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1888 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.8250095800037989  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1889 episode reward:  5.0  Episode finished after 319 timesteps\n",
      "    PARAMS.epsilon:  0.8248511800038023  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1890 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.8247700000038041  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1891 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8247066400038054  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1892 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.8246036800038077  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1893 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.8245007200038099  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1894 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8244393400038112  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1895 episode reward:  2.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.8243462800038133  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1896 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.8242472800038154  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1897 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.8241641200038172  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1898 episode reward:  2.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.8240730400038192  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1899 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8240077000038206  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1900 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.8239403800038221  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1901 episode reward:  0.0  Episode finished after 124 timesteps\n",
      "    PARAMS.epsilon:  0.8238790000038234  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1902 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.8237780200038256  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1903 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.8237166400038269  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1904 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8236532800038283  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1905 episode reward:  3.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.8235483400038306  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1906 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.8234592400038325  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1907 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.8233958800038339  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1908 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.823255300003837  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1909 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.8231780800038386  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1910 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.8230771000038408  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1911 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.8230078000038423  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1912 episode reward:  3.0  Episode finished after 241 timesteps\n",
      "    PARAMS.epsilon:  0.822887020003845  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1913 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.8227959400038469  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1914 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.8227325800038483  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1915 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.8226118000038509  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1916 episode reward:  3.0  Episode finished after 259 timesteps\n",
      "    PARAMS.epsilon:  0.8224850800038537  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1917 episode reward:  3.0  Episode finished after 252 timesteps\n",
      "    PARAMS.epsilon:  0.8223603400038564  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1918 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.8222811400038581  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1919 episode reward:  1.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.8222059000038597  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1920 episode reward:  3.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.8220772000038625  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1921 episode reward:  3.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.8219485000038653  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1922 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.8218475200038675  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1923 episode reward:  5.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.8217089200038705  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1924 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.821639620003872  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1925 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.8215287400038744  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1926 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.8214257800038767  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1927 episode reward:  3.0  Episode finished after 241 timesteps\n",
      "    PARAMS.epsilon:  0.8213069800038793  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1928 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.8212020400038815  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1929 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.8211169000038834  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1930 episode reward:  3.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.8210099800038857  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1931 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8209307800038874  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1932 episode reward:  5.0  Episode finished after 296 timesteps\n",
      "    PARAMS.epsilon:  0.8207842600038906  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1933 episode reward:  7.0  Episode finished after 422 timesteps\n",
      "    PARAMS.epsilon:  0.8205763600038951  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1934 episode reward:  3.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.8204575600038977  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1935 episode reward:  2.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.8203645000038997  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1936 episode reward:  4.0  Episode finished after 312 timesteps\n",
      "    PARAMS.epsilon:  0.8202100600039031  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1937 episode reward:  0.0  Episode finished after 151 timesteps\n",
      "    PARAMS.epsilon:  0.8201348200039047  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1938 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.820029880003907  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1939 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.8199031600039097  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1940 episode reward:  2.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.8197922800039121  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1941 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.819705160003914  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1942 episode reward:  4.0  Episode finished after 300 timesteps\n",
      "    PARAMS.epsilon:  0.8195566600039172  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1943 episode reward:  6.0  Episode finished after 367 timesteps\n",
      "    PARAMS.epsilon:  0.8193764800039212  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1944 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.8193091600039226  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1945 episode reward:  3.0  Episode finished after 265 timesteps\n",
      "    PARAMS.epsilon:  0.8191765000039255  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1946 episode reward:  4.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.8190438400039284  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1947 episode reward:  3.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.8189052400039314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1948 episode reward:  3.0  Episode finished after 252 timesteps\n",
      "    PARAMS.epsilon:  0.8187805000039341  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1949 episode reward:  5.0  Episode finished after 312 timesteps\n",
      "    PARAMS.epsilon:  0.8186260600039375  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1950 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.8185369600039394  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1951 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.8184439000039414  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1952 episode reward:  4.0  Episode finished after 312 timesteps\n",
      "    PARAMS.epsilon:  0.8182894600039448  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1953 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.8182201600039463  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1954 episode reward:  4.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.818093440003949  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1955 episode reward:  2.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.818000380003951  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1956 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8179370200039524  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1957 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.8178459400039544  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1958 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.8177667400039561  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1959 episode reward:  4.0  Episode finished after 312 timesteps\n",
      "    PARAMS.epsilon:  0.8176123000039595  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1960 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.8175331000039612  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1961 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.8174519200039629  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1962 episode reward:  2.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.8173450000039653  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1963 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.8172776800039667  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1964 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.8171767000039689  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1965 episode reward:  4.0  Episode finished after 287 timesteps\n",
      "    PARAMS.epsilon:  0.817034140003972  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1966 episode reward:  4.0  Episode finished after 317 timesteps\n",
      "    PARAMS.epsilon:  0.8168777200039754  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1967 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8168123800039768  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1968 episode reward:  2.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.8167213000039788  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1969 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.8166500200039803  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1970 episode reward:  4.0  Episode finished after 316 timesteps\n",
      "    PARAMS.epsilon:  0.8164936000039837  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1971 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.8164144000039855  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1972 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.816297580003988  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1973 episode reward:  3.0  Episode finished after 238 timesteps\n",
      "    PARAMS.epsilon:  0.8161807600039905  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1974 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.816113440003992  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1975 episode reward:  4.0  Episode finished after 286 timesteps\n",
      "    PARAMS.epsilon:  0.815972860003995  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1976 episode reward:  2.0  Episode finished after 194 timesteps\n",
      "    PARAMS.epsilon:  0.8158758400039972  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1977 episode reward:  2.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.8157709000039994  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1978 episode reward:  2.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.8156639800040018  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1979 episode reward:  4.0  Episode finished after 272 timesteps\n",
      "    PARAMS.epsilon:  0.8155293400040047  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1980 episode reward:  3.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.815422420004007  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1981 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.8153590600040084  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1982 episode reward:  4.0  Episode finished after 292 timesteps\n",
      "    PARAMS.epsilon:  0.8152145200040115  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1983 episode reward:  3.0  Episode finished after 237 timesteps\n",
      "    PARAMS.epsilon:  0.815097700004014  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1984 episode reward:  2.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.8149907800040164  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1985 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.8149234600040178  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1986 episode reward:  3.0  Episode finished after 238 timesteps\n",
      "    PARAMS.epsilon:  0.8148066400040204  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1987 episode reward:  5.0  Episode finished after 332 timesteps\n",
      "    PARAMS.epsilon:  0.8146423000040239  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1988 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.8145611200040257  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1989 episode reward:  4.0  Episode finished after 296 timesteps\n",
      "    PARAMS.epsilon:  0.8144146000040289  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1990 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.8142898600040316  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1991 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.8141651200040343  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1992 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.8140780000040362  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1993 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.8139790000040383  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1994 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.8138938600040402  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1995 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.8138146600040419  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1996 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.8137453600040434  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1997 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.8136681400040451  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1998 episode reward:  3.0  Episode finished after 221 timesteps\n",
      "    PARAMS.epsilon:  0.8135592400040474  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  1999 episode reward:  3.0  Episode finished after 265 timesteps\n",
      "    PARAMS.epsilon:  0.8134285600040503  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2000 episode reward:  4.0  Episode finished after 273 timesteps\n",
      "    PARAMS.epsilon:  0.8132919400040532  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2001 episode reward:  2.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.8131988800040553  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2002 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.8131295800040568  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2003 episode reward:  2.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.8130345400040588  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2004 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.812933560004061  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2005 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.8128147600040636  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2006 episode reward:  5.0  Episode finished after 318 timesteps\n",
      "    PARAMS.epsilon:  0.812656360004067  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2007 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.8125375600040696  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2008 episode reward:  5.0  Episode finished after 356 timesteps\n",
      "    PARAMS.epsilon:  0.8123613400040735  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2009 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.8122544200040758  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2010 episode reward:  2.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.8121475000040781  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2011 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.81206038000408  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2012 episode reward:  3.0  Episode finished after 288 timesteps\n",
      "    PARAMS.epsilon:  0.8119178200040831  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2013 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.8118010000040856  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2014 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.8117138800040875  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2015 episode reward:  3.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.8115911200040902  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2016 episode reward:  2.0  Episode finished after 193 timesteps\n",
      "    PARAMS.epsilon:  0.8114941000040923  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2017 episode reward:  1.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.8114030200040943  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2018 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.8113357000040957  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2019 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.8112664000040972  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2020 episode reward:  6.0  Episode finished after 376 timesteps\n",
      "    PARAMS.epsilon:  0.8110802800041013  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2021 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.8110149400041027  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2022 episode reward:  3.0  Episode finished after 235 timesteps\n",
      "    PARAMS.epsilon:  0.8108981200041052  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2023 episode reward:  3.0  Episode finished after 238 timesteps\n",
      "    PARAMS.epsilon:  0.8107813000041078  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2024 episode reward:  5.0  Episode finished after 328 timesteps\n",
      "    PARAMS.epsilon:  0.8106189400041113  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2025 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.810537760004113  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2026 episode reward:  1.0  Episode finished after 198 timesteps\n",
      "    PARAMS.epsilon:  0.8104407400041151  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2027 episode reward:  3.0  Episode finished after 241 timesteps\n",
      "    PARAMS.epsilon:  0.8103219400041177  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2028 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.8102348200041196  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2029 episode reward:  2.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.8101417600041216  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2030 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.8100586000041234  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2031 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.8099833600041251  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2032 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.8098883200041271  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2033 episode reward:  2.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.8097972400041291  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2034 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.8097180400041308  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2035 episode reward:  4.0  Episode finished after 314 timesteps\n",
      "    PARAMS.epsilon:  0.8095636000041342  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2036 episode reward:  6.0  Episode finished after 319 timesteps\n",
      "    PARAMS.epsilon:  0.8094052000041376  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2037 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.8093260000041393  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2038 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.8092586800041408  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2039 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.8091775000041426  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2040 episode reward:  4.0  Episode finished after 294 timesteps\n",
      "    PARAMS.epsilon:  0.8090309800041457  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2041 episode reward:  3.0  Episode finished after 220 timesteps\n",
      "    PARAMS.epsilon:  0.8089220800041481  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2042 episode reward:  13.0  Episode finished after 540 timesteps\n",
      "    PARAMS.epsilon:  0.8086547800041539  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  13.0  agent.save() Done!\n",
      "PARAMS.episode_i:  2043 episode reward:  3.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.8085478600041562  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2044 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8084825200041577  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2045 episode reward:  5.0  Episode finished after 369 timesteps\n",
      "    PARAMS.epsilon:  0.8083003600041616  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2046 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.8082211600041633  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2047 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.8081558200041647  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2048 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.8080786000041664  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2049 episode reward:  2.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.8079657400041689  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2050 episode reward:  4.0  Episode finished after 259 timesteps\n",
      "    PARAMS.epsilon:  0.8078370400041717  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2051 episode reward:  2.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.8077439800041737  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2052 episode reward:  1.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.8076489400041758  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2053 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.8075558800041778  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2054 episode reward:  2.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.8074489600041801  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2055 episode reward:  0.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.8073737200041817  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2056 episode reward:  6.0  Episode finished after 342 timesteps\n",
      "    PARAMS.epsilon:  0.8072034400041854  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2057 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.8071004800041877  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2058 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.8069975200041899  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2059 episode reward:  3.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.8068688200041927  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2060 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.8067440800041954  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2061 episode reward:  4.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.8066114200041983  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2062 episode reward:  3.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.8064965800042008  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2063 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.806395600004203  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2064 episode reward:  0.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.8063203600042046  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2065 episode reward:  2.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.806207500004207  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2066 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.8061005800042094  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2067 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.8060154400042112  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2068 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.805888720004214  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2069 episode reward:  3.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.8057758600042164  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2070 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.8057085400042179  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2071 episode reward:  2.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.8055897400042205  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2072 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.8054907400042226  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2073 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.805425400004224  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2074 episode reward:  2.0  Episode finished after 194 timesteps\n",
      "    PARAMS.epsilon:  0.8053303600042261  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2075 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.8052452200042279  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2076 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.8051204800042306  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2077 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.8050175200042329  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2078 episode reward:  4.0  Episode finished after 295 timesteps\n",
      "    PARAMS.epsilon:  0.804872980004236  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2079 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.8047779400042381  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2080 episode reward:  1.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.8046947800042399  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2081 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.8046017200042419  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2082 episode reward:  5.0  Episode finished after 300 timesteps\n",
      "    PARAMS.epsilon:  0.8044532200042451  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2083 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.8043502600042474  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2084 episode reward:  3.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.8042354200042499  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2085 episode reward:  3.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.8041067200042527  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2086 episode reward:  1.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.8040116800042547  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2087 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.8039324800042564  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2088 episode reward:  4.0  Episode finished after 294 timesteps\n",
      "    PARAMS.epsilon:  0.8037859600042596  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2089 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.803720620004261  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2090 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.8036572600042624  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2091 episode reward:  6.0  Episode finished after 350 timesteps\n",
      "    PARAMS.epsilon:  0.8034830200042662  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2092 episode reward:  3.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.8033761000042685  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2093 episode reward:  3.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.8032533400042712  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2094 episode reward:  3.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.8031345400042738  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2095 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.8030414800042758  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2096 episode reward:  2.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.8029484200042778  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2097 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.8028434800042801  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2098 episode reward:  5.0  Episode finished after 298 timesteps\n",
      "    PARAMS.epsilon:  0.8026969600042833  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2099 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.8025959800042854  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2100 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.8024930200042877  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2101 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.8024138200042894  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2102 episode reward:  3.0  Episode finished after 241 timesteps\n",
      "    PARAMS.epsilon:  0.802295020004292  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2103 episode reward:  3.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.8021623600042949  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2104 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.8020950400042963  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2105 episode reward:  5.0  Episode finished after 298 timesteps\n",
      "    PARAMS.epsilon:  0.8019465400042995  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2106 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.8018297200043021  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2107 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.8017069600043047  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2108 episode reward:  4.0  Episode finished after 269 timesteps\n",
      "    PARAMS.epsilon:  0.8015723200043077  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2109 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.8014832200043096  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2110 episode reward:  3.0  Episode finished after 265 timesteps\n",
      "    PARAMS.epsilon:  0.8013505600043125  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2111 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.8012634400043144  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2112 episode reward:  5.0  Episode finished after 336 timesteps\n",
      "    PARAMS.epsilon:  0.801097120004318  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2113 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.8010080200043199  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2114 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.8009288200043216  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2115 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.8008397200043236  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2116 episode reward:  4.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.8007110200043264  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2117 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.8006080600043286  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2118 episode reward:  3.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.8005011400043309  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2119 episode reward:  1.0  Episode finished after 193 timesteps\n",
      "    PARAMS.epsilon:  0.800406100004333  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2120 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.8003427400043344  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2121 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.8002615600043361  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2122 episode reward:  3.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.8001328600043389  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2123 episode reward:  2.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.8000259400043412  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2124 episode reward:  5.0  Episode finished after 313 timesteps\n",
      "    PARAMS.epsilon:  0.7998715000043446  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2125 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.7997705200043468  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2126 episode reward:  5.0  Episode finished after 315 timesteps\n",
      "    PARAMS.epsilon:  0.7996141000043502  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2127 episode reward:  2.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.7995012400043526  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2128 episode reward:  4.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.7993626400043556  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2129 episode reward:  2.0  Episode finished after 198 timesteps\n",
      "    PARAMS.epsilon:  0.7992656200043577  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2130 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.7991824600043596  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2131 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.7990814800043617  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2132 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.7989824800043639  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2133 episode reward:  4.0  Episode finished after 268 timesteps\n",
      "    PARAMS.epsilon:  0.7988498200043668  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2134 episode reward:  2.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.7987349800043693  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2135 episode reward:  4.0  Episode finished after 312 timesteps\n",
      "    PARAMS.epsilon:  0.7985805400043726  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2136 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.7985112400043741  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2137 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.7983845200043769  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2138 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.7982815600043791  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2139 episode reward:  3.0  Episode finished after 252 timesteps\n",
      "    PARAMS.epsilon:  0.7981568200043818  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2140 episode reward:  3.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.7980518800043841  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2141 episode reward:  3.0  Episode finished after 221 timesteps\n",
      "    PARAMS.epsilon:  0.7979429800043865  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2142 episode reward:  3.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.7978024000043895  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2143 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.7977232000043912  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2144 episode reward:  2.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.7976281600043933  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2145 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.797550940004395  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2146 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.7974519400043971  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2147 episode reward:  1.0  Episode finished after 150 timesteps\n",
      "    PARAMS.epsilon:  0.7973786800043987  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2148 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.7972856200044007  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2149 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.7972044400044025  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2150 episode reward:  3.0  Episode finished after 244 timesteps\n",
      "    PARAMS.epsilon:  0.7970836600044051  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2151 episode reward:  5.0  Episode finished after 293 timesteps\n",
      "    PARAMS.epsilon:  0.7969391200044083  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2152 episode reward:  3.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.796814380004411  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2153 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.796721320004413  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2154 episode reward:  2.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.796626280004415  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2155 episode reward:  5.0  Episode finished after 334 timesteps\n",
      "    PARAMS.epsilon:  0.7964599600044187  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2156 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.7963609600044208  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2157 episode reward:  3.0  Episode finished after 252 timesteps\n",
      "    PARAMS.epsilon:  0.7962362200044235  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2158 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.7961312800044258  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2159 episode reward:  3.0  Episode finished after 237 timesteps\n",
      "    PARAMS.epsilon:  0.7960144600044283  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2160 episode reward:  4.0  Episode finished after 268 timesteps\n",
      "    PARAMS.epsilon:  0.7958818000044312  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2161 episode reward:  2.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.7957748800044335  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2162 episode reward:  0.0  Episode finished after 124 timesteps\n",
      "    PARAMS.epsilon:  0.7957135000044349  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2163 episode reward:  3.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.7955788600044378  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2164 episode reward:  4.0  Episode finished after 271 timesteps\n",
      "    PARAMS.epsilon:  0.7954462000044407  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2165 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.7953808600044421  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2166 episode reward:  3.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.7952620600044447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2167 episode reward:  2.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.7951571200044469  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2168 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.7950878200044484  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2169 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.7949868400044506  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2170 episode reward:  5.0  Episode finished after 318 timesteps\n",
      "    PARAMS.epsilon:  0.7948284400044541  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2171 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.7947650800044554  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2172 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.7946977600044569  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2173 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.7946324200044583  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2174 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.7945472800044602  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2175 episode reward:  4.0  Episode finished after 259 timesteps\n",
      "    PARAMS.epsilon:  0.794418580004463  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2176 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.794325520004465  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2177 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.7942443400044668  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2178 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.7941809800044681  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2179 episode reward:  2.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.7940859400044702  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2180 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.7939869400044723  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2181 episode reward:  2.0  Episode finished after 195 timesteps\n",
      "    PARAMS.epsilon:  0.7938899200044744  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2182 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.7938008200044764  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2183 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.7936859800044789  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2184 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.7936226200044803  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2185 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.7935196600044825  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2186 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.793452340004484  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2187 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.7933810600044855  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2188 episode reward:  2.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.7932899800044875  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2189 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.7931870200044897  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2190 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.7930999000044916  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2191 episode reward:  0.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.7930187200044934  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2192 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.792943480004495  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2193 episode reward:  0.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.7928623000044968  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2194 episode reward:  4.0  Episode finished after 269 timesteps\n",
      "    PARAMS.epsilon:  0.7927296400044996  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2195 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.7926504400045014  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2196 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.7925851000045028  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2197 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.7924702600045053  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2198 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.7923752200045073  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2199 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.7922940400045091  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2200 episode reward:  2.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.7921831600045115  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2201 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.792068320004514  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2202 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.7919633800045163  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2203 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.7919000200045176  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2204 episode reward:  4.0  Episode finished after 245 timesteps\n",
      "    PARAMS.epsilon:  0.7917792400045203  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2205 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.7916802400045224  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2206 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.7915792600045246  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2207 episode reward:  3.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.7914644200045271  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2208 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.7914030400045284  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2209 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.7913218600045302  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2210 episode reward:  3.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.791193160004533  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2211 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.7911159400045347  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2212 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.7909931800045373  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2213 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.7908902200045396  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2214 episode reward:  4.0  Episode finished after 329 timesteps\n",
      "    PARAMS.epsilon:  0.7907278600045431  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2215 episode reward:  4.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.7905872800045461  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2216 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.7905219400045476  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2217 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.7904269000045496  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2218 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.7903595800045511  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2219 episode reward:  6.0  Episode finished after 361 timesteps\n",
      "    PARAMS.epsilon:  0.790181380004555  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2220 episode reward:  2.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.7900744600045573  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2221 episode reward:  2.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.7899833800045593  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2222 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.7898824000045614  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2223 episode reward:  3.0  Episode finished after 238 timesteps\n",
      "    PARAMS.epsilon:  0.789763600004564  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2224 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.7896962800045655  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2225 episode reward:  1.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.7896032200045675  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2226 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.789533920004569  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2227 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.7894547200045707  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2228 episode reward:  5.0  Episode finished after 315 timesteps\n",
      "    PARAMS.epsilon:  0.7892983000045741  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2229 episode reward:  2.0  Episode finished after 193 timesteps\n",
      "    PARAMS.epsilon:  0.7892032600045762  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2230 episode reward:  0.0  Episode finished after 146 timesteps\n",
      "    PARAMS.epsilon:  0.7891319800045777  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2231 episode reward:  1.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.7890567400045794  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2232 episode reward:  2.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.7889498200045817  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2233 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.7888488400045839  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2234 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.7887696400045856  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2235 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.7886666800045878  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2236 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.78856570000459  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2237 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.7884983800045915  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2238 episode reward:  4.0  Episode finished after 309 timesteps\n",
      "    PARAMS.epsilon:  0.7883459200045948  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2239 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.7882687000045965  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2240 episode reward:  5.0  Episode finished after 306 timesteps\n",
      "    PARAMS.epsilon:  0.7881162400045998  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2241 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.788013280004602  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2242 episode reward:  2.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.787920220004604  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2243 episode reward:  4.0  Episode finished after 313 timesteps\n",
      "    PARAMS.epsilon:  0.7877657800046074  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2244 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.7877024200046088  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2245 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.7876133200046107  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2246 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.7875499600046121  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2247 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.7874430400046144  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2248 episode reward:  4.0  Episode finished after 291 timesteps\n",
      "    PARAMS.epsilon:  0.7873004800046175  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2249 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.7872054400046196  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2250 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.7871242600046213  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2251 episode reward:  4.0  Episode finished after 264 timesteps\n",
      "    PARAMS.epsilon:  0.7869935800046242  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2252 episode reward:  3.0  Episode finished after 284 timesteps\n",
      "    PARAMS.epsilon:  0.7868530000046272  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2253 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.7867817200046288  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2254 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.7867005400046305  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2255 episode reward:  3.0  Episode finished after 246 timesteps\n",
      "    PARAMS.epsilon:  0.7865797600046331  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2256 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.786494620004635  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2257 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.7863956200046371  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2258 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.7862906800046394  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2259 episode reward:  3.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.7861857400046417  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2260 episode reward:  4.0  Episode finished after 277 timesteps\n",
      "    PARAMS.epsilon:  0.7860471400046447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2261 episode reward:  4.0  Episode finished after 268 timesteps\n",
      "    PARAMS.epsilon:  0.7859144800046476  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2262 episode reward:  5.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.7857679600046508  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2263 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.7856966800046523  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2264 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.7855957000046545  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2265 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.785526400004656  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2266 episode reward:  4.0  Episode finished after 286 timesteps\n",
      "    PARAMS.epsilon:  0.7853838400046591  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2267 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.7852808800046613  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2268 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.785203660004663  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2269 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.7851323800046646  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2270 episode reward:  3.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.7850036800046674  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2271 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.7849205200046692  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2272 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.7848413200046709  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2273 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.7847245000046734  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2274 episode reward:  6.0  Episode finished after 319 timesteps\n",
      "    PARAMS.epsilon:  0.7845661000046769  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2275 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.7844750200046788  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2276 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.7843562200046814  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2277 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.7842948400046827  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2278 episode reward:  4.0  Episode finished after 287 timesteps\n",
      "    PARAMS.epsilon:  0.7841522800046858  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2279 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.7840117000046889  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2280 episode reward:  2.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.7838988400046913  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2281 episode reward:  6.0  Episode finished after 394 timesteps\n",
      "    PARAMS.epsilon:  0.7837048000046956  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2282 episode reward:  6.0  Episode finished after 407 timesteps\n",
      "    PARAMS.epsilon:  0.7835028400046999  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2283 episode reward:  4.0  Episode finished after 291 timesteps\n",
      "    PARAMS.epsilon:  0.7833583000047031  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2284 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.7832553400047053  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2285 episode reward:  8.0  Episode finished after 404 timesteps\n",
      "    PARAMS.epsilon:  0.7830553600047097  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2286 episode reward:  2.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.7829603200047117  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2287 episode reward:  0.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.7828771600047135  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2288 episode reward:  2.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.782762320004716  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2289 episode reward:  3.0  Episode finished after 252 timesteps\n",
      "    PARAMS.epsilon:  0.7826375800047187  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2290 episode reward:  3.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.7824989800047217  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2291 episode reward:  4.0  Episode finished after 267 timesteps\n",
      "    PARAMS.epsilon:  0.7823663200047246  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2292 episode reward:  2.0  Episode finished after 199 timesteps\n",
      "    PARAMS.epsilon:  0.7822693000047267  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2293 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.7821980200047283  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2294 episode reward:  3.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.782073280004731  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2295 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.7819465600047337  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2296 episode reward:  2.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.7818535000047357  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2297 episode reward:  3.0  Episode finished after 238 timesteps\n",
      "    PARAMS.epsilon:  0.7817366800047383  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2298 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.7816673800047398  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2299 episode reward:  4.0  Episode finished after 272 timesteps\n",
      "    PARAMS.epsilon:  0.7815327400047427  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2300 episode reward:  3.0  Episode finished after 264 timesteps\n",
      "    PARAMS.epsilon:  0.7814020600047455  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2301 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.7812753400047483  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2302 episode reward:  0.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.78119614000475  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2303 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.7811288200047515  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2304 episode reward:  4.0  Episode finished after 306 timesteps\n",
      "    PARAMS.epsilon:  0.7809783400047547  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2305 episode reward:  3.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.7808615200047573  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2306 episode reward:  2.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.7807486600047597  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2307 episode reward:  2.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.7806556000047618  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2308 episode reward:  2.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.7805486800047641  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2309 episode reward:  4.0  Episode finished after 314 timesteps\n",
      "    PARAMS.epsilon:  0.7803942400047674  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2310 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.78027742000477  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2311 episode reward:  1.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.7801942600047718  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2312 episode reward:  4.0  Episode finished after 271 timesteps\n",
      "    PARAMS.epsilon:  0.7800616000047746  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2313 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.7799923000047762  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2314 episode reward:  6.0  Episode finished after 363 timesteps\n",
      "    PARAMS.epsilon:  0.77981410000478  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2315 episode reward:  6.0  Episode finished after 359 timesteps\n",
      "    PARAMS.epsilon:  0.7796359000047839  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2316 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.7795527400047857  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2317 episode reward:  8.0  Episode finished after 421 timesteps\n",
      "    PARAMS.epsilon:  0.7793448400047902  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2318 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.7792577200047921  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2319 episode reward:  5.0  Episode finished after 317 timesteps\n",
      "    PARAMS.epsilon:  0.7791013000047955  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2320 episode reward:  0.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.7790221000047972  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2321 episode reward:  4.0  Episode finished after 312 timesteps\n",
      "    PARAMS.epsilon:  0.7788676600048006  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2322 episode reward:  5.0  Episode finished after 313 timesteps\n",
      "    PARAMS.epsilon:  0.7787132200048039  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2323 episode reward:  3.0  Episode finished after 262 timesteps\n",
      "    PARAMS.epsilon:  0.7785825400048068  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2324 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.7785013600048085  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2325 episode reward:  5.0  Episode finished after 351 timesteps\n",
      "    PARAMS.epsilon:  0.7783291000048123  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2326 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.7782439600048141  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2327 episode reward:  6.0  Episode finished after 351 timesteps\n",
      "    PARAMS.epsilon:  0.7780697200048179  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2328 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.7779430000048206  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2329 episode reward:  3.0  Episode finished after 244 timesteps\n",
      "    PARAMS.epsilon:  0.7778222200048233  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2330 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.7777291600048253  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2331 episode reward:  5.0  Episode finished after 353 timesteps\n",
      "    PARAMS.epsilon:  0.7775529400048291  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2332 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.777463840004831  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2333 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.7773391000048337  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2334 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.7772698000048353  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2335 episode reward:  1.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.7771866400048371  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2336 episode reward:  2.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.7770777400048394  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2337 episode reward:  3.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.7769648800048419  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2338 episode reward:  7.0  Episode finished after 446 timesteps\n",
      "    PARAMS.epsilon:  0.7767431200048467  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2339 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.7766579800048485  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2340 episode reward:  0.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.7765787800048503  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2341 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.7765154200048516  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2342 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.7764322600048534  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2343 episode reward:  5.0  Episode finished after 304 timesteps\n",
      "    PARAMS.epsilon:  0.7762817800048567  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2344 episode reward:  4.0  Episode finished after 275 timesteps\n",
      "    PARAMS.epsilon:  0.7761471400048596  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2345 episode reward:  5.0  Episode finished after 340 timesteps\n",
      "    PARAMS.epsilon:  0.7759788400048633  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2346 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.775901620004865  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2347 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.7758224200048667  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2348 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.7757432200048684  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2349 episode reward:  2.0  Episode finished after 197 timesteps\n",
      "    PARAMS.epsilon:  0.7756462000048705  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2350 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.7755452200048727  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2351 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.7754779000048742  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2352 episode reward:  2.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.7753848400048762  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2353 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.7753234600048775  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2354 episode reward:  4.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.7751769400048807  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2355 episode reward:  3.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.7750640800048831  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2356 episode reward:  7.0  Episode finished after 272 timesteps\n",
      "    PARAMS.epsilon:  0.7749294400048861  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2357 episode reward:  5.0  Episode finished after 297 timesteps\n",
      "    PARAMS.epsilon:  0.7747809400048893  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2358 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.7746819400048914  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2359 episode reward:  9.0  Episode finished after 368 timesteps\n",
      "    PARAMS.epsilon:  0.7744997800048954  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2360 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.7743968200048976  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2361 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.7742918800048999  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2362 episode reward:  2.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.7741810000049023  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2363 episode reward:  4.0  Episode finished after 289 timesteps\n",
      "    PARAMS.epsilon:  0.7740384400049054  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2364 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.773917660004908  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2365 episode reward:  4.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.7737949000049107  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2366 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.7736919400049129  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2367 episode reward:  5.0  Episode finished after 360 timesteps\n",
      "    PARAMS.epsilon:  0.7735137400049168  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2368 episode reward:  2.0  Episode finished after 194 timesteps\n",
      "    PARAMS.epsilon:  0.7734167200049189  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2369 episode reward:  3.0  Episode finished after 247 timesteps\n",
      "    PARAMS.epsilon:  0.7732959400049215  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2370 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.7731929800049238  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2371 episode reward:  4.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.7730642800049266  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2372 episode reward:  10.0  Episode finished after 424 timesteps\n",
      "    PARAMS.epsilon:  0.7728544000049311  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2373 episode reward:  4.0  Episode finished after 333 timesteps\n",
      "    PARAMS.epsilon:  0.7726900600049347  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2374 episode reward:  6.0  Episode finished after 315 timesteps\n",
      "    PARAMS.epsilon:  0.7725336400049381  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2375 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.7724504800049399  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2376 episode reward:  3.0  Episode finished after 254 timesteps\n",
      "    PARAMS.epsilon:  0.7723257400049426  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2377 episode reward:  1.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.7722307000049446  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2378 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.7721594200049462  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2379 episode reward:  2.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.7720525000049485  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2380 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.7719515200049507  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2381 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.7718525200049529  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2382 episode reward:  0.0  Episode finished after 150 timesteps\n",
      "    PARAMS.epsilon:  0.7717772800049545  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2383 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.7716525400049572  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2384 episode reward:  3.0  Episode finished after 237 timesteps\n",
      "    PARAMS.epsilon:  0.7715357200049597  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2385 episode reward:  1.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.7714604800049614  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2386 episode reward:  5.0  Episode finished after 307 timesteps\n",
      "    PARAMS.epsilon:  0.7713080200049647  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2387 episode reward:  5.0  Episode finished after 316 timesteps\n",
      "    PARAMS.epsilon:  0.7711516000049681  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2388 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.7710862600049695  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2389 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.7709971600049714  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2390 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.7709298400049729  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2391 episode reward:  5.0  Episode finished after 329 timesteps\n",
      "    PARAMS.epsilon:  0.7707674800049764  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2392 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.7706882800049781  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2393 episode reward:  5.0  Episode finished after 330 timesteps\n",
      "    PARAMS.epsilon:  0.7705239400049817  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2394 episode reward:  2.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.7704328600049837  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2395 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.7703556400049854  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2396 episode reward:  5.0  Episode finished after 308 timesteps\n",
      "    PARAMS.epsilon:  0.7702031800049887  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2397 episode reward:  4.0  Episode finished after 264 timesteps\n",
      "    PARAMS.epsilon:  0.7700725000049915  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2398 episode reward:  4.0  Episode finished after 287 timesteps\n",
      "    PARAMS.epsilon:  0.7699319200049946  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2399 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.7698428200049965  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2400 episode reward:  4.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.7697081800049994  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2401 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.7695834400050021  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2402 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.7694923600050041  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2403 episode reward:  2.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.7693874200050064  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2404 episode reward:  6.0  Episode finished after 351 timesteps\n",
      "    PARAMS.epsilon:  0.7692131800050102  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2405 episode reward:  1.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.7691201200050122  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2406 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.7689953800050149  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2407 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.7689102400050167  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2408 episode reward:  4.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.7687874800050194  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2409 episode reward:  3.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.7686528400050223  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2410 episode reward:  5.0  Episode finished after 367 timesteps\n",
      "    PARAMS.epsilon:  0.7684726600050262  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2411 episode reward:  5.0  Episode finished after 339 timesteps\n",
      "    PARAMS.epsilon:  0.7683043600050299  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2412 episode reward:  2.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.7681895200050324  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2413 episode reward:  5.0  Episode finished after 328 timesteps\n",
      "    PARAMS.epsilon:  0.7680271600050359  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2414 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.7679004400050387  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2415 episode reward:  2.0  Episode finished after 239 timesteps\n",
      "    PARAMS.epsilon:  0.7677816400050412  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2416 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.7676826400050434  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2417 episode reward:  3.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.7675737400050457  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2418 episode reward:  4.0  Episode finished after 329 timesteps\n",
      "    PARAMS.epsilon:  0.7674113800050493  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2419 episode reward:  3.0  Episode finished after 221 timesteps\n",
      "    PARAMS.epsilon:  0.7673024800050516  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2420 episode reward:  7.0  Episode finished after 359 timesteps\n",
      "    PARAMS.epsilon:  0.7671242800050555  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2421 episode reward:  7.0  Episode finished after 378 timesteps\n",
      "    PARAMS.epsilon:  0.7669381600050595  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2422 episode reward:  3.0  Episode finished after 241 timesteps\n",
      "    PARAMS.epsilon:  0.7668173800050622  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2423 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.7667480800050637  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2424 episode reward:  2.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.766641160005066  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2425 episode reward:  4.0  Episode finished after 289 timesteps\n",
      "    PARAMS.epsilon:  0.7664986000050691  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2426 episode reward:  7.0  Episode finished after 353 timesteps\n",
      "    PARAMS.epsilon:  0.7663243600050729  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2427 episode reward:  3.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.7661976400050756  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2428 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.766086760005078  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2429 episode reward:  3.0  Episode finished after 226 timesteps\n",
      "    PARAMS.epsilon:  0.7659758800050804  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2430 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.7659085600050819  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2431 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.7658313400050836  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2432 episode reward:  2.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.7657363000050856  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2433 episode reward:  6.0  Episode finished after 351 timesteps\n",
      "    PARAMS.epsilon:  0.7655640400050894  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2434 episode reward:  5.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.7654155400050926  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2435 episode reward:  8.0  Episode finished after 296 timesteps\n",
      "    PARAMS.epsilon:  0.7652690200050958  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2436 episode reward:  4.0  Episode finished after 314 timesteps\n",
      "    PARAMS.epsilon:  0.7651126000050992  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2437 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.765029440005101  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2438 episode reward:  4.0  Episode finished after 275 timesteps\n",
      "    PARAMS.epsilon:  0.764892820005104  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2439 episode reward:  6.0  Episode finished after 339 timesteps\n",
      "    PARAMS.epsilon:  0.7647245200051076  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2440 episode reward:  4.0  Episode finished after 303 timesteps\n",
      "    PARAMS.epsilon:  0.7645740400051109  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2441 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.7644710800051131  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2442 episode reward:  4.0  Episode finished after 282 timesteps\n",
      "    PARAMS.epsilon:  0.7643305000051162  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2443 episode reward:  2.0  Episode finished after 222 timesteps\n",
      "    PARAMS.epsilon:  0.7642216000051185  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2444 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.7641166600051208  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2445 episode reward:  4.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.7639939000051235  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2446 episode reward:  3.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.7638671800051262  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2447 episode reward:  0.0  Episode finished after 148 timesteps\n",
      "    PARAMS.epsilon:  0.7637939200051278  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2448 episode reward:  2.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.7637028400051298  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2449 episode reward:  3.0  Episode finished after 222 timesteps\n",
      "    PARAMS.epsilon:  0.7635919600051322  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2450 episode reward:  2.0  Episode finished after 198 timesteps\n",
      "    PARAMS.epsilon:  0.7634949400051343  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2451 episode reward:  2.0  Episode finished after 220 timesteps\n",
      "    PARAMS.epsilon:  0.7633860400051367  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2452 episode reward:  7.0  Episode finished after 442 timesteps\n",
      "    PARAMS.epsilon:  0.7631662600051414  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2453 episode reward:  4.0  Episode finished after 282 timesteps\n",
      "    PARAMS.epsilon:  0.7630276600051444  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2454 episode reward:  4.0  Episode finished after 278 timesteps\n",
      "    PARAMS.epsilon:  0.7628890600051474  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2455 episode reward:  3.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.7627524400051504  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2456 episode reward:  9.0  Episode finished after 490 timesteps\n",
      "    PARAMS.epsilon:  0.7625089000051557  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2457 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.7624455400051571  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2458 episode reward:  4.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.7623069400051601  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2459 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.7622119000051621  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2460 episode reward:  2.0  Episode finished after 193 timesteps\n",
      "    PARAMS.epsilon:  0.7621168600051642  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2461 episode reward:  2.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.7620040000051667  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2462 episode reward:  1.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.7619109400051687  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2463 episode reward:  3.0  Episode finished after 247 timesteps\n",
      "    PARAMS.epsilon:  0.7617881800051713  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2464 episode reward:  3.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.7616693800051739  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2465 episode reward:  6.0  Episode finished after 338 timesteps\n",
      "    PARAMS.epsilon:  0.7615030600051775  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2466 episode reward:  15.0  Episode finished after 433 timesteps\n",
      "    PARAMS.epsilon:  0.7612892200051822  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  15.0  agent.save() Done!\n",
      "PARAMS.episode_i:  2467 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.7612258600051836  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2468 episode reward:  2.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.761113000005186  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2469 episode reward:  3.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.7609942000051886  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2470 episode reward:  3.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.760885300005191  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2471 episode reward:  3.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.7607665000051935  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2472 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.760699180005195  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2473 episode reward:  7.0  Episode finished after 397 timesteps\n",
      "    PARAMS.epsilon:  0.7605031600051992  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2474 episode reward:  2.0  Episode finished after 199 timesteps\n",
      "    PARAMS.epsilon:  0.7604041600052014  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2475 episode reward:  3.0  Episode finished after 268 timesteps\n",
      "    PARAMS.epsilon:  0.7602715000052043  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2476 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.7601843800052062  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2477 episode reward:  2.0  Episode finished after 195 timesteps\n",
      "    PARAMS.epsilon:  0.7600873600052083  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2478 episode reward:  6.0  Episode finished after 337 timesteps\n",
      "    PARAMS.epsilon:  0.7599210400052119  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2479 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.7598418400052136  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2480 episode reward:  3.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.7597190800052163  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2481 episode reward:  5.0  Episode finished after 318 timesteps\n",
      "    PARAMS.epsilon:  0.7595606800052197  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2482 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.7594834600052214  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2483 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.7593805000052236  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2484 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.7593092200052252  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2485 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.7592320000052268  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2486 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.7591290400052291  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2487 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.7590280600052313  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2488 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.7589567800052328  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2489 episode reward:  3.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.7588439200052353  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2490 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.758762740005237  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2491 episode reward:  2.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.7586498800052395  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2492 episode reward:  6.0  Episode finished after 387 timesteps\n",
      "    PARAMS.epsilon:  0.7584578200052436  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2493 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.758350900005246  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2494 episode reward:  5.0  Episode finished after 329 timesteps\n",
      "    PARAMS.epsilon:  0.7581885400052495  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2495 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.7581093400052512  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2496 episode reward:  13.0  Episode finished after 365 timesteps\n",
      "    PARAMS.epsilon:  0.7579271800052552  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2497 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.7578281800052573  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2498 episode reward:  2.0  Episode finished after 199 timesteps\n",
      "    PARAMS.epsilon:  0.7577311600052594  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2499 episode reward:  4.0  Episode finished after 295 timesteps\n",
      "    PARAMS.epsilon:  0.7575846400052626  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2500 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.7574836600052648  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2501 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.7573589200052675  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2502 episode reward:  2.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.7572678400052695  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2503 episode reward:  1.0  Episode finished after 151 timesteps\n",
      "    PARAMS.epsilon:  0.7571945800052711  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2504 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.7570777600052736  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2505 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.7569767800052758  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2506 episode reward:  1.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.7568817400052779  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2507 episode reward:  3.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.7567589800052805  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2508 episode reward:  0.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.7566837400052822  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2509 episode reward:  4.0  Episode finished after 290 timesteps\n",
      "    PARAMS.epsilon:  0.7565392000052853  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2510 episode reward:  2.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.7564342600052876  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2511 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.7563431800052896  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2512 episode reward:  3.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.7562026000052926  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2513 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.7561095400052946  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2514 episode reward:  0.0  Episode finished after 148 timesteps\n",
      "    PARAMS.epsilon:  0.7560362800052962  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2515 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.7559709400052976  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2516 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.7558660000052999  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2517 episode reward:  2.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.7557729400053019  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2518 episode reward:  3.0  Episode finished after 273 timesteps\n",
      "    PARAMS.epsilon:  0.7556383000053049  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2519 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.755537320005307  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2520 episode reward:  2.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.7554323800053093  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2521 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.7553294200053116  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2522 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.755214580005314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2523 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.7551353800053158  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2524 episode reward:  3.0  Episode finished after 239 timesteps\n",
      "    PARAMS.epsilon:  0.7550185600053183  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2525 episode reward:  2.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.7549255000053203  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2526 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.7548383800053222  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2527 episode reward:  5.0  Episode finished after 355 timesteps\n",
      "    PARAMS.epsilon:  0.754662160005326  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2528 episode reward:  3.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.7545433600053286  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2529 episode reward:  1.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.7544384200053309  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2530 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.7543552600053327  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2531 episode reward:  2.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.7542661600053346  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2532 episode reward:  4.0  Episode finished after 296 timesteps\n",
      "    PARAMS.epsilon:  0.7541196400053378  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2533 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.7540285600053398  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2534 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.7539394600053417  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2535 episode reward:  4.0  Episode finished after 265 timesteps\n",
      "    PARAMS.epsilon:  0.7538087800053446  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2536 episode reward:  0.0  Episode finished after 148 timesteps\n",
      "    PARAMS.epsilon:  0.7537355200053462  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2537 episode reward:  3.0  Episode finished after 261 timesteps\n",
      "    PARAMS.epsilon:  0.753606820005349  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2538 episode reward:  3.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.7534781200053517  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2539 episode reward:  1.0  Episode finished after 195 timesteps\n",
      "    PARAMS.epsilon:  0.7533811000053539  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2540 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.7532761600053561  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2541 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.7531712200053584  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2542 episode reward:  2.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.7530563800053609  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2543 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.7529672800053628  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2544 episode reward:  3.0  Episode finished after 241 timesteps\n",
      "    PARAMS.epsilon:  0.7528465000053655  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2545 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.7527455200053677  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2546 episode reward:  2.0  Episode finished after 199 timesteps\n",
      "    PARAMS.epsilon:  0.7526465200053698  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2547 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.7525673200053715  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2548 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.7525019800053729  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2549 episode reward:  4.0  Episode finished after 284 timesteps\n",
      "    PARAMS.epsilon:  0.752361400005376  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2550 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.7522782400053778  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2551 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.7521990400053795  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2552 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.7520782600053821  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2553 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.7519753000053844  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2554 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.7518485800053871  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2555 episode reward:  2.0  Episode finished after 195 timesteps\n",
      "    PARAMS.epsilon:  0.7517515600053892  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2556 episode reward:  5.0  Episode finished after 330 timesteps\n",
      "    PARAMS.epsilon:  0.7515892000053928  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2557 episode reward:  4.0  Episode finished after 301 timesteps\n",
      "    PARAMS.epsilon:  0.751438720005396  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2558 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.7513555600053978  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2559 episode reward:  1.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.7512625000053998  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2560 episode reward:  1.0  Episode finished after 199 timesteps\n",
      "    PARAMS.epsilon:  0.751163500005402  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2561 episode reward:  5.0  Episode finished after 338 timesteps\n",
      "    PARAMS.epsilon:  0.7509952000054056  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2562 episode reward:  2.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.7509021400054077  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2563 episode reward:  1.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.7508011600054099  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2564 episode reward:  5.0  Episode finished after 320 timesteps\n",
      "    PARAMS.epsilon:  0.7506427600054133  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2565 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.7505774200054147  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2566 episode reward:  5.0  Episode finished after 333 timesteps\n",
      "    PARAMS.epsilon:  0.7504130800054183  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2567 episode reward:  5.0  Episode finished after 316 timesteps\n",
      "    PARAMS.epsilon:  0.7502566600054217  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2568 episode reward:  6.0  Episode finished after 376 timesteps\n",
      "    PARAMS.epsilon:  0.7500705400054257  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2569 episode reward:  4.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.7499299600054288  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2570 episode reward:  6.0  Episode finished after 389 timesteps\n",
      "    PARAMS.epsilon:  0.749737900005433  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2571 episode reward:  4.0  Episode finished after 266 timesteps\n",
      "    PARAMS.epsilon:  0.7496072200054358  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2572 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.7494963400054382  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2573 episode reward:  4.0  Episode finished after 296 timesteps\n",
      "    PARAMS.epsilon:  0.7493498200054414  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2574 episode reward:  5.0  Episode finished after 315 timesteps\n",
      "    PARAMS.epsilon:  0.7491934000054448  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2575 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.749092420005447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2576 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.7490072800054488  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2577 episode reward:  3.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.7488845200054515  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2578 episode reward:  2.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.7487894800054535  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2579 episode reward:  4.0  Episode finished after 291 timesteps\n",
      "    PARAMS.epsilon:  0.7486449400054567  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2580 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.7485538600054586  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2581 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.7484667400054605  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2582 episode reward:  2.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.7483598200054629  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2583 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.748258840005465  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2584 episode reward:  6.0  Episode finished after 379 timesteps\n",
      "    PARAMS.epsilon:  0.7480727200054691  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2585 episode reward:  2.0  Episode finished after 222 timesteps\n",
      "    PARAMS.epsilon:  0.7479618400054715  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2586 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.7478866000054731  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2587 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.7478034400054749  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2588 episode reward:  5.0  Episode finished after 317 timesteps\n",
      "    PARAMS.epsilon:  0.7476470200054783  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2589 episode reward:  5.0  Episode finished after 296 timesteps\n",
      "    PARAMS.epsilon:  0.7475005000054815  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2590 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.7474232800054832  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2591 episode reward:  5.0  Episode finished after 325 timesteps\n",
      "    PARAMS.epsilon:  0.7472629000054867  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2592 episode reward:  4.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.7471243000054897  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2593 episode reward:  6.0  Episode finished after 361 timesteps\n",
      "    PARAMS.epsilon:  0.7469441200054936  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2594 episode reward:  3.0  Episode finished after 241 timesteps\n",
      "    PARAMS.epsilon:  0.7468253200054962  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2595 episode reward:  5.0  Episode finished after 321 timesteps\n",
      "    PARAMS.epsilon:  0.7466669200054996  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2596 episode reward:  4.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.7465263400055027  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2597 episode reward:  4.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.7463877400055057  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2598 episode reward:  3.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.7462689400055083  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2599 episode reward:  7.0  Episode finished after 407 timesteps\n",
      "    PARAMS.epsilon:  0.7460669800055126  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2600 episode reward:  3.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.745960060005515  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2601 episode reward:  2.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.7458472000055174  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2602 episode reward:  2.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.7457244400055201  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2603 episode reward:  1.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.745633360005522  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2604 episode reward:  5.0  Episode finished after 355 timesteps\n",
      "    PARAMS.epsilon:  0.7454571400055259  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2605 episode reward:  3.0  Episode finished after 226 timesteps\n",
      "    PARAMS.epsilon:  0.7453442800055283  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2606 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.7452809200055297  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2607 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.7452096400055312  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2608 episode reward:  3.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.7450967800055337  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2609 episode reward:  4.0  Episode finished after 292 timesteps\n",
      "    PARAMS.epsilon:  0.7449522400055368  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2610 episode reward:  2.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.7448453200055392  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2611 episode reward:  3.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.7447186000055419  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2612 episode reward:  3.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.7445998000055445  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2613 episode reward:  4.0  Episode finished after 274 timesteps\n",
      "    PARAMS.epsilon:  0.7444631800055475  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2614 episode reward:  5.0  Episode finished after 372 timesteps\n",
      "    PARAMS.epsilon:  0.7442790400055515  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2615 episode reward:  5.0  Episode finished after 296 timesteps\n",
      "    PARAMS.epsilon:  0.7441325200055546  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2616 episode reward:  4.0  Episode finished after 340 timesteps\n",
      "    PARAMS.epsilon:  0.7439642200055583  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2617 episode reward:  5.0  Episode finished after 323 timesteps\n",
      "    PARAMS.epsilon:  0.7438058200055617  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2618 episode reward:  3.0  Episode finished after 267 timesteps\n",
      "    PARAMS.epsilon:  0.7436731600055646  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2619 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.7435464400055674  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2620 episode reward:  2.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.7434335800055698  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2621 episode reward:  3.0  Episode finished after 239 timesteps\n",
      "    PARAMS.epsilon:  0.7433147800055724  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2622 episode reward:  4.0  Episode finished after 294 timesteps\n",
      "    PARAMS.epsilon:  0.7431702400055755  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2623 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.7430989600055771  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2624 episode reward:  4.0  Episode finished after 266 timesteps\n",
      "    PARAMS.epsilon:  0.74296630000558  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2625 episode reward:  8.0  Episode finished after 444 timesteps\n",
      "    PARAMS.epsilon:  0.7427465200055847  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2626 episode reward:  4.0  Episode finished after 302 timesteps\n",
      "    PARAMS.epsilon:  0.7425980200055879  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2627 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.7424950600055902  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2628 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.7424020000055922  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2629 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.7422950800055945  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2630 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.7421921200055968  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2631 episode reward:  4.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.7420614400055996  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2632 episode reward:  4.0  Episode finished after 294 timesteps\n",
      "    PARAMS.epsilon:  0.7419169000056027  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2633 episode reward:  10.0  Episode finished after 504 timesteps\n",
      "    PARAMS.epsilon:  0.7416674200056081  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2634 episode reward:  1.0  Episode finished after 195 timesteps\n",
      "    PARAMS.epsilon:  0.7415704000056103  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2635 episode reward:  2.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.7414753600056123  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2636 episode reward:  4.0  Episode finished after 284 timesteps\n",
      "    PARAMS.epsilon:  0.7413347800056154  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2637 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.7412674600056168  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2638 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.7411902400056185  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2639 episode reward:  3.0  Episode finished after 274 timesteps\n",
      "    PARAMS.epsilon:  0.7410536200056215  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2640 episode reward:  2.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.7409625400056234  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2641 episode reward:  2.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.7408536400056258  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2642 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.7407665200056277  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2643 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.7406794000056296  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2644 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.7405942600056314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2645 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.740524960005633  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2646 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.7404596200056344  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2647 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.7403923000056358  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2648 episode reward:  3.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.7402675600056385  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2649 episode reward:  4.0  Episode finished after 306 timesteps\n",
      "    PARAMS.epsilon:  0.7401170800056418  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2650 episode reward:  3.0  Episode finished after 241 timesteps\n",
      "    PARAMS.epsilon:  0.7399963000056444  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2651 episode reward:  4.0  Episode finished after 284 timesteps\n",
      "    PARAMS.epsilon:  0.7398557200056475  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2652 episode reward:  5.0  Episode finished after 356 timesteps\n",
      "    PARAMS.epsilon:  0.7396795000056513  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2653 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.7395646600056538  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2654 episode reward:  5.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.739418140005657  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2655 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.7393389400056587  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2656 episode reward:  5.0  Episode finished after 302 timesteps\n",
      "    PARAMS.epsilon:  0.739188460005662  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2657 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.7391072800056637  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2658 episode reward:  1.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.7390162000056657  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2659 episode reward:  4.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.7388974000056683  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2660 episode reward:  3.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.7387904800056706  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2661 episode reward:  2.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.7386994000056726  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2662 episode reward:  7.0  Episode finished after 431 timesteps\n",
      "    PARAMS.epsilon:  0.7384855600056772  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2663 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.7384083400056789  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2664 episode reward:  7.0  Episode finished after 412 timesteps\n",
      "    PARAMS.epsilon:  0.7382044000056833  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2665 episode reward:  8.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.7380559000056865  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2666 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.7379945200056879  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2667 episode reward:  5.0  Episode finished after 330 timesteps\n",
      "    PARAMS.epsilon:  0.7378321600056914  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2668 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.7377529600056931  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2669 episode reward:  5.0  Episode finished after 300 timesteps\n",
      "    PARAMS.epsilon:  0.7376044600056963  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2670 episode reward:  3.0  Episode finished after 254 timesteps\n",
      "    PARAMS.epsilon:  0.7374777400056991  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2671 episode reward:  2.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.7373866600057011  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2672 episode reward:  3.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.7372797400057034  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2673 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.7371787600057056  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2674 episode reward:  3.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.737067880005708  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2675 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.7370065000057093  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2676 episode reward:  4.0  Episode finished after 278 timesteps\n",
      "    PARAMS.epsilon:  0.7368679000057123  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2677 episode reward:  3.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.7367590000057147  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2678 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.7366441600057172  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2679 episode reward:  3.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.7365372400057195  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2680 episode reward:  1.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.7364620000057212  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2681 episode reward:  6.0  Episode finished after 358 timesteps\n",
      "    PARAMS.epsilon:  0.736285780005725  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2682 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.7361432200057281  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2683 episode reward:  7.0  Episode finished after 382 timesteps\n",
      "    PARAMS.epsilon:  0.7359551200057322  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2684 episode reward:  2.0  Episode finished after 220 timesteps\n",
      "    PARAMS.epsilon:  0.7358462200057345  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2685 episode reward:  3.0  Episode finished after 247 timesteps\n",
      "    PARAMS.epsilon:  0.7357234600057372  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2686 episode reward:  2.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.7356165400057395  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2687 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.7355333800057413  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2688 episode reward:  7.0  Episode finished after 397 timesteps\n",
      "    PARAMS.epsilon:  0.7353373600057456  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2689 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.7352740000057469  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2690 episode reward:  5.0  Episode finished after 323 timesteps\n",
      "    PARAMS.epsilon:  0.7351136200057504  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2691 episode reward:  4.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.7349750200057534  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2692 episode reward:  5.0  Episode finished after 354 timesteps\n",
      "    PARAMS.epsilon:  0.7347988000057573  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2693 episode reward:  4.0  Episode finished after 290 timesteps\n",
      "    PARAMS.epsilon:  0.7346562400057604  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2694 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.7345671400057623  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2695 episode reward:  6.0  Episode finished after 388 timesteps\n",
      "    PARAMS.epsilon:  0.7343750800057665  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2696 episode reward:  5.0  Episode finished after 296 timesteps\n",
      "    PARAMS.epsilon:  0.7342285600057696  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2697 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.7341513400057713  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2698 episode reward:  4.0  Episode finished after 264 timesteps\n",
      "    PARAMS.epsilon:  0.7340206600057742  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2699 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.7339276000057762  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2700 episode reward:  3.0  Episode finished after 230 timesteps\n",
      "    PARAMS.epsilon:  0.7338127600057787  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2701 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.7336979200057812  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2702 episode reward:  3.0  Episode finished after 267 timesteps\n",
      "    PARAMS.epsilon:  0.733565260005784  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2703 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.7334900200057857  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2704 episode reward:  4.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.7333573600057885  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2705 episode reward:  4.0  Episode finished after 289 timesteps\n",
      "    PARAMS.epsilon:  0.7332128200057917  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2706 episode reward:  5.0  Episode finished after 295 timesteps\n",
      "    PARAMS.epsilon:  0.7330682800057948  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2707 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.7329791800057968  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2708 episode reward:  2.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.7328861200057988  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2709 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.7328009800058006  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2710 episode reward:  5.0  Episode finished after 341 timesteps\n",
      "    PARAMS.epsilon:  0.7326307000058043  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2711 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.7325435800058062  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2712 episode reward:  3.0  Episode finished after 230 timesteps\n",
      "    PARAMS.epsilon:  0.7324307200058087  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2713 episode reward:  3.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.7323079600058113  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2714 episode reward:  7.0  Episode finished after 375 timesteps\n",
      "    PARAMS.epsilon:  0.7321218400058154  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2715 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.7319951200058181  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2716 episode reward:  8.0  Episode finished after 482 timesteps\n",
      "    PARAMS.epsilon:  0.7317575200058233  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2717 episode reward:  2.0  Episode finished after 221 timesteps\n",
      "    PARAMS.epsilon:  0.7316466400058257  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2718 episode reward:  4.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.7315179400058285  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2719 episode reward:  4.0  Episode finished after 282 timesteps\n",
      "    PARAMS.epsilon:  0.7313773600058315  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2720 episode reward:  9.0  Episode finished after 478 timesteps\n",
      "    PARAMS.epsilon:  0.7311417400058366  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2721 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.7310744200058381  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2722 episode reward:  3.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.7309655200058405  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2723 episode reward:  4.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.7308269200058435  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2724 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.7307259400058457  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2725 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.7306467400058474  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2726 episode reward:  3.0  Episode finished after 235 timesteps\n",
      "    PARAMS.epsilon:  0.7305319000058499  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2727 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.7304546800058516  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2728 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.7303556800058537  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2729 episode reward:  0.0  Episode finished after 124 timesteps\n",
      "    PARAMS.epsilon:  0.730294300005855  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2730 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.7302071800058569  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2731 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.7301438200058583  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2732 episode reward:  3.0  Episode finished after 241 timesteps\n",
      "    PARAMS.epsilon:  0.7300250200058609  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2733 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.7299002800058636  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2734 episode reward:  4.0  Episode finished after 267 timesteps\n",
      "    PARAMS.epsilon:  0.7297696000058664  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2735 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.7296686200058686  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2736 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.7295636800058709  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2737 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.7294409200058736  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2738 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.729375580005875  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2739 episode reward:  3.0  Episode finished after 239 timesteps\n",
      "    PARAMS.epsilon:  0.7292587600058775  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2740 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.7291577800058797  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2741 episode reward:  6.0  Episode finished after 407 timesteps\n",
      "    PARAMS.epsilon:  0.7289558200058841  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2742 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.7288528600058863  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2743 episode reward:  5.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.7287122800058894  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2744 episode reward:  3.0  Episode finished after 254 timesteps\n",
      "    PARAMS.epsilon:  0.7285855600058921  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2745 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.7284845800058943  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2746 episode reward:  5.0  Episode finished after 346 timesteps\n",
      "    PARAMS.epsilon:  0.728314300005898  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2747 episode reward:  3.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.7281974800059006  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2748 episode reward:  6.0  Episode finished after 323 timesteps\n",
      "    PARAMS.epsilon:  0.728037100005904  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2749 episode reward:  4.0  Episode finished after 286 timesteps\n",
      "    PARAMS.epsilon:  0.7278965200059071  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2750 episode reward:  4.0  Episode finished after 282 timesteps\n",
      "    PARAMS.epsilon:  0.7277559400059102  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2751 episode reward:  3.0  Episode finished after 246 timesteps\n",
      "    PARAMS.epsilon:  0.7276351600059128  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2752 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.7275203200059153  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2753 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.727395580005918  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2754 episode reward:  4.0  Episode finished after 290 timesteps\n",
      "    PARAMS.epsilon:  0.7272510400059211  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2755 episode reward:  5.0  Episode finished after 275 timesteps\n",
      "    PARAMS.epsilon:  0.727116400005924  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2756 episode reward:  8.0  Episode finished after 323 timesteps\n",
      "    PARAMS.epsilon:  0.7269560200059275  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2757 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.7268312800059302  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2758 episode reward:  9.0  Episode finished after 491 timesteps\n",
      "    PARAMS.epsilon:  0.7265897200059355  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2759 episode reward:  6.0  Episode finished after 337 timesteps\n",
      "    PARAMS.epsilon:  0.7264214200059391  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2760 episode reward:  4.0  Episode finished after 266 timesteps\n",
      "    PARAMS.epsilon:  0.726290740005942  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2761 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.7261759000059445  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2762 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.7260986800059461  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2763 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.7259759200059488  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2764 episode reward:  5.0  Episode finished after 338 timesteps\n",
      "    PARAMS.epsilon:  0.7258076200059524  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2765 episode reward:  4.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.7256848600059551  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2766 episode reward:  4.0  Episode finished after 275 timesteps\n",
      "    PARAMS.epsilon:  0.7255482400059581  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2767 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.7254472600059603  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2768 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.725368060005962  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2769 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.7252512400059645  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2770 episode reward:  5.0  Episode finished after 329 timesteps\n",
      "    PARAMS.epsilon:  0.725088880005968  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2771 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.7250096800059698  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2772 episode reward:  0.0  Episode finished after 124 timesteps\n",
      "    PARAMS.epsilon:  0.7249483000059711  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2773 episode reward:  4.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.7248196000059739  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2774 episode reward:  2.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.7247285200059759  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2775 episode reward:  5.0  Episode finished after 350 timesteps\n",
      "    PARAMS.epsilon:  0.7245562600059796  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2776 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.7244750800059814  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2777 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.7243602400059839  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2778 episode reward:  1.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.7242850000059855  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2779 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.7242216400059869  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2780 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.7241424400059886  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2781 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.7240573000059904  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2782 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.7239147400059935  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2783 episode reward:  2.0  Episode finished after 226 timesteps\n",
      "    PARAMS.epsilon:  0.723803860005996  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2784 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.7237266400059976  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2785 episode reward:  3.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.723615760006  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2786 episode reward:  0.0  Episode finished after 122 timesteps\n",
      "    PARAMS.epsilon:  0.7235543800060014  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2787 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.7234534000060036  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2788 episode reward:  6.0  Episode finished after 362 timesteps\n",
      "    PARAMS.epsilon:  0.7232732200060075  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2789 episode reward:  4.0  Episode finished after 297 timesteps\n",
      "    PARAMS.epsilon:  0.7231267000060106  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2790 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.7230336400060127  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2791 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.7229069200060154  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2792 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.7228297000060171  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2793 episode reward:  6.0  Episode finished after 320 timesteps\n",
      "    PARAMS.epsilon:  0.7226713000060205  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2794 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.7225861600060224  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2795 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.7224970600060243  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2796 episode reward:  4.0  Episode finished after 303 timesteps\n",
      "    PARAMS.epsilon:  0.7223485600060275  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2797 episode reward:  5.0  Episode finished after 318 timesteps\n",
      "    PARAMS.epsilon:  0.722190160006031  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2798 episode reward:  7.0  Episode finished after 428 timesteps\n",
      "    PARAMS.epsilon:  0.7219783000060356  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2799 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.7218634600060381  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2800 episode reward:  4.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.7217387200060408  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2801 episode reward:  3.0  Episode finished after 272 timesteps\n",
      "    PARAMS.epsilon:  0.7216040800060437  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2802 episode reward:  5.0  Episode finished after 319 timesteps\n",
      "    PARAMS.epsilon:  0.7214456800060471  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2803 episode reward:  3.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.7213328200060496  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2804 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.7212338200060517  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2805 episode reward:  2.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.7211427400060537  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2806 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.7210754200060552  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2807 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.7210001800060568  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2808 episode reward:  3.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.7208734600060596  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2809 episode reward:  2.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.7207843600060615  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2810 episode reward:  2.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.7206952600060634  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2811 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.7206101200060653  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2812 episode reward:  4.0  Episode finished after 301 timesteps\n",
      "    PARAMS.epsilon:  0.7204616200060685  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2813 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.7203606400060707  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2814 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.720299260006072  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2815 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.7202220400060737  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2816 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.7201586800060751  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2817 episode reward:  5.0  Episode finished after 318 timesteps\n",
      "    PARAMS.epsilon:  0.7200022600060785  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2818 episode reward:  5.0  Episode finished after 312 timesteps\n",
      "    PARAMS.epsilon:  0.7198478200060818  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2819 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.7197824800060832  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2820 episode reward:  2.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.7196933800060852  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2821 episode reward:  10.0  Episode finished after 379 timesteps\n",
      "    PARAMS.epsilon:  0.7195052800060893  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2822 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.7194300400060909  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2823 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.7193488600060927  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2824 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.7192617400060946  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2825 episode reward:  2.0  Episode finished after 198 timesteps\n",
      "    PARAMS.epsilon:  0.7191647200060967  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2826 episode reward:  3.0  Episode finished after 261 timesteps\n",
      "    PARAMS.epsilon:  0.7190360200060995  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2827 episode reward:  6.0  Episode finished after 392 timesteps\n",
      "    PARAMS.epsilon:  0.7188419800061037  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2828 episode reward:  3.0  Episode finished after 246 timesteps\n",
      "    PARAMS.epsilon:  0.7187192200061063  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2829 episode reward:  5.0  Episode finished after 289 timesteps\n",
      "    PARAMS.epsilon:  0.7185766600061094  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2830 episode reward:  6.0  Episode finished after 319 timesteps\n",
      "    PARAMS.epsilon:  0.7184182600061129  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2831 episode reward:  13.0  Episode finished after 501 timesteps\n",
      "    PARAMS.epsilon:  0.7181707600061182  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2832 episode reward:  3.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.7180638400061206  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2833 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.7179707800061226  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2834 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.7178698000061248  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2835 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.717766840006127  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2836 episode reward:  6.0  Episode finished after 362 timesteps\n",
      "    PARAMS.epsilon:  0.7175866600061309  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2837 episode reward:  6.0  Episode finished after 344 timesteps\n",
      "    PARAMS.epsilon:  0.7174163800061346  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2838 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.717355000006136  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2839 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.7172777800061376  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2840 episode reward:  3.0  Episode finished after 252 timesteps\n",
      "    PARAMS.epsilon:  0.7171530400061403  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2841 episode reward:  2.0  Episode finished after 221 timesteps\n",
      "    PARAMS.epsilon:  0.7170441400061427  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2842 episode reward:  2.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.7169550400061446  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2843 episode reward:  7.0  Episode finished after 397 timesteps\n",
      "    PARAMS.epsilon:  0.7167590200061489  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2844 episode reward:  3.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.7166323000061516  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2845 episode reward:  4.0  Episode finished after 305 timesteps\n",
      "    PARAMS.epsilon:  0.7164798400061549  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2846 episode reward:  4.0  Episode finished after 271 timesteps\n",
      "    PARAMS.epsilon:  0.7163471800061578  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2847 episode reward:  1.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.7162719400061595  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2848 episode reward:  4.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.7161472000061622  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2849 episode reward:  3.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.7160204800061649  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2850 episode reward:  3.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.7158977200061676  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2851 episode reward:  3.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.7157749600061702  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2852 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.7156739800061724  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2853 episode reward:  4.0  Episode finished after 246 timesteps\n",
      "    PARAMS.epsilon:  0.7155512200061751  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2854 episode reward:  2.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.7154403400061775  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2855 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.7153373800061797  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2856 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.7152760000061811  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2857 episode reward:  4.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.7151275000061843  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2858 episode reward:  4.0  Episode finished after 289 timesteps\n",
      "    PARAMS.epsilon:  0.7149849400061874  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2859 episode reward:  10.0  Episode finished after 507 timesteps\n",
      "    PARAMS.epsilon:  0.7147334800061929  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2860 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.7146226000061953  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2861 episode reward:  9.0  Episode finished after 478 timesteps\n",
      "    PARAMS.epsilon:  0.7143850000062004  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2862 episode reward:  4.0  Episode finished after 261 timesteps\n",
      "    PARAMS.epsilon:  0.7142563000062032  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2863 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.7141929400062046  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2864 episode reward:  4.0  Episode finished after 289 timesteps\n",
      "    PARAMS.epsilon:  0.7140503800062077  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2865 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.7139553400062097  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2866 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.7138702000062116  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2867 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.7137929800062133  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2868 episode reward:  3.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.7136801200062157  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2869 episode reward:  6.0  Episode finished after 338 timesteps\n",
      "    PARAMS.epsilon:  0.7135118200062194  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2870 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.7134128200062215  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2871 episode reward:  2.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.713297980006224  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2872 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.7132207600062257  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2873 episode reward:  5.0  Episode finished after 353 timesteps\n",
      "    PARAMS.epsilon:  0.7130465200062295  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2874 episode reward:  5.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.7128980200062327  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2875 episode reward:  5.0  Episode finished after 322 timesteps\n",
      "    PARAMS.epsilon:  0.7127396200062361  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2876 episode reward:  3.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.7126327000062385  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2877 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.7125693400062398  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2878 episode reward:  4.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.7124426200062426  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2879 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.7123416400062448  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2880 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.7122545200062467  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2881 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.7121693800062485  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2882 episode reward:  3.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.7120505800062511  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2883 episode reward:  3.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.7119436600062534  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2884 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.711826840006256  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2885 episode reward:  2.0  Episode finished after 220 timesteps\n",
      "    PARAMS.epsilon:  0.7117179400062583  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2886 episode reward:  4.0  Episode finished after 300 timesteps\n",
      "    PARAMS.epsilon:  0.7115694400062615  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2887 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.711454600006264  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2888 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.7113773800062657  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2889 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.7113001600062674  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2890 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.7112368000062688  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2891 episode reward:  3.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.711131860006271  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2892 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.7110289000062733  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2893 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.7109695000062746  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2894 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.7108903000062763  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2895 episode reward:  4.0  Episode finished after 271 timesteps\n",
      "    PARAMS.epsilon:  0.7107556600062792  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2896 episode reward:  9.0  Episode finished after 451 timesteps\n",
      "    PARAMS.epsilon:  0.7105319200062841  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2897 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.7104566800062857  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2898 episode reward:  8.0  Episode finished after 420 timesteps\n",
      "    PARAMS.epsilon:  0.7102487800062902  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2899 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.7101319600062928  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2900 episode reward:  5.0  Episode finished after 344 timesteps\n",
      "    PARAMS.epsilon:  0.7099616800062964  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2901 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.7098963400062979  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2902 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.7097933800063001  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2903 episode reward:  2.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.709704280006302  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2904 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.7095894400063045  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2905 episode reward:  7.0  Episode finished after 405 timesteps\n",
      "    PARAMS.epsilon:  0.7093874800063089  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2906 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.7092884800063111  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2907 episode reward:  4.0  Episode finished after 271 timesteps\n",
      "    PARAMS.epsilon:  0.709153840006314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2908 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.7090687000063158  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2909 episode reward:  2.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.7089776200063178  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2910 episode reward:  6.0  Episode finished after 340 timesteps\n",
      "    PARAMS.epsilon:  0.7088093200063215  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2911 episode reward:  3.0  Episode finished after 239 timesteps\n",
      "    PARAMS.epsilon:  0.708690520006324  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2912 episode reward:  3.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.7085657800063268  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2913 episode reward:  4.0  Episode finished after 302 timesteps\n",
      "    PARAMS.epsilon:  0.70841530000633  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2914 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.7083163000063322  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2915 episode reward:  6.0  Episode finished after 333 timesteps\n",
      "    PARAMS.epsilon:  0.7081519600063357  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2916 episode reward:  4.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.7080252400063385  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2917 episode reward:  4.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.7078846600063415  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2918 episode reward:  2.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.7077737800063439  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2919 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.707678740006346  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2920 episode reward:  3.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.7075480600063488  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2921 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.7074629200063507  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2922 episode reward:  5.0  Episode finished after 297 timesteps\n",
      "    PARAMS.epsilon:  0.7073144200063539  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2923 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.7072372000063556  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2924 episode reward:  4.0  Episode finished after 274 timesteps\n",
      "    PARAMS.epsilon:  0.7071005800063586  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2925 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.7070233600063602  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2926 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.7069619800063616  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2927 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.7068610000063638  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2928 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.7067738800063657  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2929 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.7066867600063675  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2930 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.7066234000063689  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2931 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.7065164800063712  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2932 episode reward:  3.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.7063838200063741  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2933 episode reward:  3.0  Episode finished after 230 timesteps\n",
      "    PARAMS.epsilon:  0.7062689800063766  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2934 episode reward:  3.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.7061462200063793  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2935 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.7060452400063815  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2936 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.7059818800063828  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2937 episode reward:  3.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.7058591200063855  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2938 episode reward:  5.0  Episode finished after 352 timesteps\n",
      "    PARAMS.epsilon:  0.7056848800063893  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2939 episode reward:  4.0  Episode finished after 282 timesteps\n",
      "    PARAMS.epsilon:  0.7055443000063923  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2940 episode reward:  3.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.705421540006395  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2941 episode reward:  5.0  Episode finished after 319 timesteps\n",
      "    PARAMS.epsilon:  0.7052631400063984  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2942 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.7051879000064001  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2943 episode reward:  2.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.7050968200064021  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2944 episode reward:  4.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.7049582200064051  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2945 episode reward:  3.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.7048513000064074  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2946 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.7047879400064088  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2947 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.704686960006411  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2948 episode reward:  5.0  Episode finished after 326 timesteps\n",
      "    PARAMS.epsilon:  0.7045246000064145  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2949 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.7044493600064161  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2950 episode reward:  4.0  Episode finished after 272 timesteps\n",
      "    PARAMS.epsilon:  0.704314720006419  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2951 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.7042157200064212  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2952 episode reward:  6.0  Episode finished after 358 timesteps\n",
      "    PARAMS.epsilon:  0.704037520006425  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2953 episode reward:  5.0  Episode finished after 284 timesteps\n",
      "    PARAMS.epsilon:  0.7038969400064281  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2954 episode reward:  6.0  Episode finished after 366 timesteps\n",
      "    PARAMS.epsilon:  0.703716760006432  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2955 episode reward:  5.0  Episode finished after 295 timesteps\n",
      "    PARAMS.epsilon:  0.7035702400064352  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2956 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.7034455000064379  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2957 episode reward:  4.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.703304920006441  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2958 episode reward:  5.0  Episode finished after 314 timesteps\n",
      "    PARAMS.epsilon:  0.7031504800064443  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2959 episode reward:  4.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.703025740006447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2960 episode reward:  3.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.7029188200064493  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2961 episode reward:  5.0  Episode finished after 350 timesteps\n",
      "    PARAMS.epsilon:  0.7027465600064531  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2962 episode reward:  4.0  Episode finished after 301 timesteps\n",
      "    PARAMS.epsilon:  0.7025960800064563  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2963 episode reward:  12.0  Episode finished after 460 timesteps\n",
      "    PARAMS.epsilon:  0.7023683800064613  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2964 episode reward:  3.0  Episode finished after 245 timesteps\n",
      "    PARAMS.epsilon:  0.7022476000064639  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2965 episode reward:  3.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.7021426600064662  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2966 episode reward:  4.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.7020060400064692  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2967 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.7019288200064708  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2968 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.7018436800064727  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2969 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.7017288400064752  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2970 episode reward:  3.0  Episode finished after 222 timesteps\n",
      "    PARAMS.epsilon:  0.7016179600064776  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2971 episode reward:  4.0  Episode finished after 295 timesteps\n",
      "    PARAMS.epsilon:  0.7014734200064807  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2972 episode reward:  4.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.7013328400064838  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2973 episode reward:  2.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.7012219600064862  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2974 episode reward:  4.0  Episode finished after 264 timesteps\n",
      "    PARAMS.epsilon:  0.701091280006489  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2975 episode reward:  2.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.7009804000064914  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2976 episode reward:  2.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.7008913000064934  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2977 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.7008041800064952  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2978 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.7007289400064969  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2979 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.7006517200064986  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2980 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.7005764800065002  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2981 episode reward:  3.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.7004497600065029  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2982 episode reward:  5.0  Episode finished after 323 timesteps\n",
      "    PARAMS.epsilon:  0.7002893800065064  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2983 episode reward:  0.0  Episode finished after 124 timesteps\n",
      "    PARAMS.epsilon:  0.7002280000065078  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2984 episode reward:  8.0  Episode finished after 425 timesteps\n",
      "    PARAMS.epsilon:  0.7000181200065123  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2985 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.6999171400065145  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2986 episode reward:  10.0  Episode finished after 405 timesteps\n",
      "    PARAMS.epsilon:  0.6997151800065189  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2987 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.6996300400065207  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2988 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.699527080006523  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2989 episode reward:  5.0  Episode finished after 288 timesteps\n",
      "    PARAMS.epsilon:  0.6993845200065261  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2990 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.6993053200065278  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2991 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.6991647400065308  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2992 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.699065740006533  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2993 episode reward:  3.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.6989390200065357  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2994 episode reward:  4.0  Episode finished after 306 timesteps\n",
      "    PARAMS.epsilon:  0.698788540006539  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2995 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.698697460006541  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2996 episode reward:  5.0  Episode finished after 320 timesteps\n",
      "    PARAMS.epsilon:  0.6985390600065444  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2997 episode reward:  6.0  Episode finished after 386 timesteps\n",
      "    PARAMS.epsilon:  0.6983470000065486  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2998 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.6982579000065505  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  2999 episode reward:  3.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.6981391000065531  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3000 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.6980401000065553  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3001 episode reward:  7.0  Episode finished after 400 timesteps\n",
      "    PARAMS.epsilon:  0.6978421000065596  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3002 episode reward:  3.0  Episode finished after 266 timesteps\n",
      "    PARAMS.epsilon:  0.6977094400065624  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3003 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.6976421200065639  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3004 episode reward:  8.0  Episode finished after 475 timesteps\n",
      "    PARAMS.epsilon:  0.697406500006569  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3005 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.6973055200065712  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3006 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.6971629600065743  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3007 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.697083760006576  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3008 episode reward:  4.0  Episode finished after 254 timesteps\n",
      "    PARAMS.epsilon:  0.6969570400065788  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3009 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.6968778400065805  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3010 episode reward:  4.0  Episode finished after 308 timesteps\n",
      "    PARAMS.epsilon:  0.6967253800065838  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3011 episode reward:  0.0  Episode finished after 124 timesteps\n",
      "    PARAMS.epsilon:  0.6966640000065851  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3012 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.6965887600065868  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3013 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.6965056000065886  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3014 episode reward:  5.0  Episode finished after 351 timesteps\n",
      "    PARAMS.epsilon:  0.6963333400065923  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3015 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.6962323600065945  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3016 episode reward:  5.0  Episode finished after 329 timesteps\n",
      "    PARAMS.epsilon:  0.696070000006598  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3017 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.6959828800065999  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3018 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.6959195200066013  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3019 episode reward:  2.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.6958066600066037  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3020 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.6957215200066056  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3021 episode reward:  3.0  Episode finished after 271 timesteps\n",
      "    PARAMS.epsilon:  0.6955868800066085  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3022 episode reward:  4.0  Episode finished after 302 timesteps\n",
      "    PARAMS.epsilon:  0.6954364000066118  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3023 episode reward:  3.0  Episode finished after 235 timesteps\n",
      "    PARAMS.epsilon:  0.6953215600066143  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3024 episode reward:  4.0  Episode finished after 290 timesteps\n",
      "    PARAMS.epsilon:  0.6951770200066174  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3025 episode reward:  4.0  Episode finished after 254 timesteps\n",
      "    PARAMS.epsilon:  0.6950522800066201  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3026 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.6949493200066224  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3027 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.6948859600066237  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3028 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.6948226000066251  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3029 episode reward:  5.0  Episode finished after 298 timesteps\n",
      "    PARAMS.epsilon:  0.6946741000066283  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3030 episode reward:  4.0  Episode finished after 295 timesteps\n",
      "    PARAMS.epsilon:  0.6945275800066315  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3031 episode reward:  3.0  Episode finished after 276 timesteps\n",
      "    PARAMS.epsilon:  0.6943909600066345  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3032 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.6942880000066367  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3033 episode reward:  7.0  Episode finished after 376 timesteps\n",
      "    PARAMS.epsilon:  0.6941018800066407  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3034 episode reward:  2.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.6939890200066432  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3035 episode reward:  4.0  Episode finished after 327 timesteps\n",
      "    PARAMS.epsilon:  0.6938266600066467  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3036 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.6937454800066485  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3037 episode reward:  6.0  Episode finished after 379 timesteps\n",
      "    PARAMS.epsilon:  0.6935593600066525  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3038 episode reward:  7.0  Episode finished after 454 timesteps\n",
      "    PARAMS.epsilon:  0.6933336400066574  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3039 episode reward:  7.0  Episode finished after 452 timesteps\n",
      "    PARAMS.epsilon:  0.6931099000066623  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3040 episode reward:  2.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.6930188200066643  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3041 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.6929138800066665  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3042 episode reward:  5.0  Episode finished after 348 timesteps\n",
      "    PARAMS.epsilon:  0.6927416200066703  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3043 episode reward:  3.0  Episode finished after 262 timesteps\n",
      "    PARAMS.epsilon:  0.6926109400066731  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3044 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.6925079800066753  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3045 episode reward:  4.0  Episode finished after 302 timesteps\n",
      "    PARAMS.epsilon:  0.6923594800066786  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3046 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.6922802800066803  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3047 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.6921951400066821  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3048 episode reward:  3.0  Episode finished after 269 timesteps\n",
      "    PARAMS.epsilon:  0.692062480006685  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3049 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.6920011000066864  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3050 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.6919060600066884  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3051 episode reward:  6.0  Episode finished after 385 timesteps\n",
      "    PARAMS.epsilon:  0.6917159800066925  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3052 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.6916288600066944  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3053 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.6915278800066966  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3054 episode reward:  6.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.6913635400067002  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3055 episode reward:  4.0  Episode finished after 295 timesteps\n",
      "    PARAMS.epsilon:  0.6912170200067034  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3056 episode reward:  4.0  Episode finished after 282 timesteps\n",
      "    PARAMS.epsilon:  0.6910784200067064  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3057 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.6909893200067083  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3058 episode reward:  4.0  Episode finished after 261 timesteps\n",
      "    PARAMS.epsilon:  0.6908606200067111  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3059 episode reward:  6.0  Episode finished after 368 timesteps\n",
      "    PARAMS.epsilon:  0.6906784600067151  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3060 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.6905755000067173  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3061 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.6904824400067193  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3062 episode reward:  7.0  Episode finished after 461 timesteps\n",
      "    PARAMS.epsilon:  0.6902547400067243  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3063 episode reward:  6.0  Episode finished after 380 timesteps\n",
      "    PARAMS.epsilon:  0.6900666400067283  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3064 episode reward:  4.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.6899280400067314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3065 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.689850820006733  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3066 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.6897260800067357  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3067 episode reward:  5.0  Episode finished after 344 timesteps\n",
      "    PARAMS.epsilon:  0.6895558000067394  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3068 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.6894944200067408  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3069 episode reward:  5.0  Episode finished after 329 timesteps\n",
      "    PARAMS.epsilon:  0.6893320600067443  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3070 episode reward:  4.0  Episode finished after 277 timesteps\n",
      "    PARAMS.epsilon:  0.6891934600067473  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3071 episode reward:  2.0  Episode finished after 221 timesteps\n",
      "    PARAMS.epsilon:  0.6890845600067497  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3072 episode reward:  1.0  Episode finished after 197 timesteps\n",
      "    PARAMS.epsilon:  0.6889875400067518  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3073 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.6889004200067537  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3074 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.6888331000067551  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3075 episode reward:  3.0  Episode finished after 277 timesteps\n",
      "    PARAMS.epsilon:  0.6886964800067581  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3076 episode reward:  6.0  Episode finished after 383 timesteps\n",
      "    PARAMS.epsilon:  0.6885064000067622  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3077 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.6884054200067644  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3078 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.6883064200067666  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3079 episode reward:  5.0  Episode finished after 351 timesteps\n",
      "    PARAMS.epsilon:  0.6881321800067703  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3080 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.6880450600067722  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3081 episode reward:  3.0  Episode finished after 274 timesteps\n",
      "    PARAMS.epsilon:  0.6879104200067752  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3082 episode reward:  6.0  Episode finished after 404 timesteps\n",
      "    PARAMS.epsilon:  0.6877104400067795  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3083 episode reward:  4.0  Episode finished after 274 timesteps\n",
      "    PARAMS.epsilon:  0.6875738200067825  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3084 episode reward:  2.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.6874490800067852  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3085 episode reward:  0.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.6873679000067869  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3086 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.6872471200067896  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3087 episode reward:  0.0  Episode finished after 149 timesteps\n",
      "    PARAMS.epsilon:  0.6871738600067911  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3088 episode reward:  2.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.6870788200067932  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3089 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.6869897200067951  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3090 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.686904580006797  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3091 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.6868352800067985  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3092 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.6867461800068004  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3093 episode reward:  0.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.6866689600068021  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3094 episode reward:  4.0  Episode finished after 287 timesteps\n",
      "    PARAMS.epsilon:  0.6865264000068052  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3095 episode reward:  5.0  Episode finished after 351 timesteps\n",
      "    PARAMS.epsilon:  0.686352160006809  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3096 episode reward:  2.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.6862373200068115  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3097 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.6861343600068137  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3098 episode reward:  2.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.6860254600068161  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3099 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.6859601200068175  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3100 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.6858967600068189  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3101 episode reward:  4.0  Episode finished after 300 timesteps\n",
      "    PARAMS.epsilon:  0.6857482600068221  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3102 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.685659160006824  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3103 episode reward:  0.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.6855799600068258  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3104 episode reward:  9.0  Episode finished after 384 timesteps\n",
      "    PARAMS.epsilon:  0.6853898800068299  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3105 episode reward:  5.0  Episode finished after 345 timesteps\n",
      "    PARAMS.epsilon:  0.6852196000068336  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3106 episode reward:  5.0  Episode finished after 397 timesteps\n",
      "    PARAMS.epsilon:  0.6850216000068379  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3107 episode reward:  2.0  Episode finished after 226 timesteps\n",
      "    PARAMS.epsilon:  0.6849107200068403  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3108 episode reward:  2.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.6847879600068429  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3109 episode reward:  1.0  Episode finished after 195 timesteps\n",
      "    PARAMS.epsilon:  0.684690940006845  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3110 episode reward:  4.0  Episode finished after 301 timesteps\n",
      "    PARAMS.epsilon:  0.6845424400068483  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3111 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.6844592800068501  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3112 episode reward:  3.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.6843206800068531  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3113 episode reward:  8.0  Episode finished after 466 timesteps\n",
      "    PARAMS.epsilon:  0.6840890200068581  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3114 episode reward:  5.0  Episode finished after 342 timesteps\n",
      "    PARAMS.epsilon:  0.6839207200068618  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3115 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.683817760006864  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3116 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.6837464800068656  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3117 episode reward:  1.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.6836712400068672  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3118 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.6835781800068692  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3119 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.6835088800068707  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3120 episode reward:  3.0  Episode finished after 275 timesteps\n",
      "    PARAMS.epsilon:  0.6833742400068736  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3121 episode reward:  2.0  Episode finished after 241 timesteps\n",
      "    PARAMS.epsilon:  0.6832534600068763  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3122 episode reward:  1.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.6831604000068783  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3123 episode reward:  6.0  Episode finished after 362 timesteps\n",
      "    PARAMS.epsilon:  0.6829822000068821  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3124 episode reward:  3.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.6828436000068852  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3125 episode reward:  4.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.6827050000068882  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3126 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.6826416400068895  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3127 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.6825386800068918  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3128 episode reward:  2.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.6824278000068942  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3129 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.6823486000068959  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3130 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.6822476200068981  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3131 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.6821783200068996  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3132 episode reward:  3.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.6820377400069026  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3133 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.681974380006904  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3134 episode reward:  11.0  Episode finished after 499 timesteps\n",
      "    PARAMS.epsilon:  0.6817288600069094  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3135 episode reward:  4.0  Episode finished after 313 timesteps\n",
      "    PARAMS.epsilon:  0.6815724400069127  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3136 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.6815051200069142  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3137 episode reward:  2.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.6814001800069165  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3138 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.681332860006918  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3139 episode reward:  2.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.6812259400069203  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3140 episode reward:  3.0  Episode finished after 246 timesteps\n",
      "    PARAMS.epsilon:  0.6811031800069229  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3141 episode reward:  1.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.681010120006925  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3142 episode reward:  4.0  Episode finished after 276 timesteps\n",
      "    PARAMS.epsilon:  0.6808735000069279  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3143 episode reward:  0.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.6807982600069296  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3144 episode reward:  2.0  Episode finished after 238 timesteps\n",
      "    PARAMS.epsilon:  0.6806814400069321  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3145 episode reward:  2.0  Episode finished after 226 timesteps\n",
      "    PARAMS.epsilon:  0.6805685800069345  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3146 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.6804834400069364  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3147 episode reward:  7.0  Episode finished after 402 timesteps\n",
      "    PARAMS.epsilon:  0.6802854400069407  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3148 episode reward:  2.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.680176540006943  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3149 episode reward:  6.0  Episode finished after 365 timesteps\n",
      "    PARAMS.epsilon:  0.679996360006947  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3150 episode reward:  3.0  Episode finished after 291 timesteps\n",
      "    PARAMS.epsilon:  0.6798518200069501  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3151 episode reward:  15.0  Episode finished after 499 timesteps\n",
      "    PARAMS.epsilon:  0.6796043200069555  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3152 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.679533040006957  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3153 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.6794657200069585  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3154 episode reward:  3.0  Episode finished after 259 timesteps\n",
      "    PARAMS.epsilon:  0.6793370200069613  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3155 episode reward:  5.0  Episode finished after 351 timesteps\n",
      "    PARAMS.epsilon:  0.679164760006965  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3156 episode reward:  0.0  Episode finished after 147 timesteps\n",
      "    PARAMS.epsilon:  0.6790915000069666  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3157 episode reward:  2.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.678982600006969  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3158 episode reward:  0.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.6789034000069707  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3159 episode reward:  7.0  Episode finished after 407 timesteps\n",
      "    PARAMS.epsilon:  0.6787014400069751  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3160 episode reward:  6.0  Episode finished after 359 timesteps\n",
      "    PARAMS.epsilon:  0.678523240006979  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3161 episode reward:  5.0  Episode finished after 347 timesteps\n",
      "    PARAMS.epsilon:  0.6783509800069827  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3162 episode reward:  3.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.6782282200069853  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3163 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.6781391200069873  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3164 episode reward:  4.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.6780203200069899  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3165 episode reward:  3.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.6779054800069924  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3166 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.6778401400069938  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3167 episode reward:  2.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.6777272800069962  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3168 episode reward:  3.0  Episode finished after 267 timesteps\n",
      "    PARAMS.epsilon:  0.6775946200069991  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3169 episode reward:  6.0  Episode finished after 362 timesteps\n",
      "    PARAMS.epsilon:  0.677416420007003  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3170 episode reward:  4.0  Episode finished after 301 timesteps\n",
      "    PARAMS.epsilon:  0.6772679200070062  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3171 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.6772025800070076  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3172 episode reward:  5.0  Episode finished after 309 timesteps\n",
      "    PARAMS.epsilon:  0.6770501200070109  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3173 episode reward:  4.0  Episode finished after 327 timesteps\n",
      "    PARAMS.epsilon:  0.6768877600070144  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3174 episode reward:  6.0  Episode finished after 401 timesteps\n",
      "    PARAMS.epsilon:  0.6766897600070187  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3175 episode reward:  3.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.6765551200070217  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3176 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.676493740007023  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3177 episode reward:  4.0  Episode finished after 311 timesteps\n",
      "    PARAMS.epsilon:  0.6763393000070264  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3178 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.6762561400070282  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3179 episode reward:  6.0  Episode finished after 374 timesteps\n",
      "    PARAMS.epsilon:  0.6760700200070322  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3180 episode reward:  2.0  Episode finished after 222 timesteps\n",
      "    PARAMS.epsilon:  0.6759611200070346  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3181 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.6758839000070362  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3182 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.6758165800070377  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3183 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.675755200007039  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3184 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.6756443200070414  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3185 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.6755572000070433  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3186 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.6754918600070448  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3187 episode reward:  3.0  Episode finished after 235 timesteps\n",
      "    PARAMS.epsilon:  0.6753750400070473  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3188 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.6753116800070487  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3189 episode reward:  9.0  Episode finished after 389 timesteps\n",
      "    PARAMS.epsilon:  0.6751176400070529  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3190 episode reward:  3.0  Episode finished after 262 timesteps\n",
      "    PARAMS.epsilon:  0.6749889400070557  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3191 episode reward:  10.0  Episode finished after 438 timesteps\n",
      "    PARAMS.epsilon:  0.6747711400070604  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3192 episode reward:  7.0  Episode finished after 391 timesteps\n",
      "    PARAMS.epsilon:  0.6745790800070646  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3193 episode reward:  5.0  Episode finished after 338 timesteps\n",
      "    PARAMS.epsilon:  0.6744107800070682  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3194 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.6743474200070696  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3195 episode reward:  5.0  Episode finished after 342 timesteps\n",
      "    PARAMS.epsilon:  0.6741791200070733  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3196 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.6740920000070751  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3197 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.6740029000070771  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3198 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.6739355800070785  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3199 episode reward:  4.0  Episode finished after 284 timesteps\n",
      "    PARAMS.epsilon:  0.6737950000070816  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3200 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.6736682800070843  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3201 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.6735811600070862  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3202 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.6734663200070887  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3203 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.6733772200070907  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3204 episode reward:  4.0  Episode finished after 296 timesteps\n",
      "    PARAMS.epsilon:  0.6732307000070938  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3205 episode reward:  6.0  Episode finished after 360 timesteps\n",
      "    PARAMS.epsilon:  0.6730525000070977  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3206 episode reward:  3.0  Episode finished after 284 timesteps\n",
      "    PARAMS.epsilon:  0.6729119200071008  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3207 episode reward:  4.0  Episode finished after 246 timesteps\n",
      "    PARAMS.epsilon:  0.6727891600071034  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3208 episode reward:  0.0  Episode finished after 124 timesteps\n",
      "    PARAMS.epsilon:  0.6727277800071048  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3209 episode reward:  2.0  Episode finished after 220 timesteps\n",
      "    PARAMS.epsilon:  0.6726188800071071  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3210 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.6725535400071085  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3211 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.67248622000711  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3212 episode reward:  4.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.672347620007113  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3213 episode reward:  1.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.6722723800071146  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3214 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.6722030800071161  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3215 episode reward:  7.0  Episode finished after 443 timesteps\n",
      "    PARAMS.epsilon:  0.6719852800071209  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3216 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.6719140000071224  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3217 episode reward:  3.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.6717872800071252  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3218 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.6717259000071265  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3219 episode reward:  3.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.6715912600071294  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3220 episode reward:  1.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.6715001800071314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3221 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.6714150400071333  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3222 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.6713516800071346  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3223 episode reward:  2.0  Episode finished after 238 timesteps\n",
      "    PARAMS.epsilon:  0.6712348600071372  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3224 episode reward:  0.0  Episode finished after 124 timesteps\n",
      "    PARAMS.epsilon:  0.6711734800071385  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3225 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.6710843800071404  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3226 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.6709992400071423  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3227 episode reward:  10.0  Episode finished after 571 timesteps\n",
      "    PARAMS.epsilon:  0.6707161000071484  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3228 episode reward:  5.0  Episode finished after 325 timesteps\n",
      "    PARAMS.epsilon:  0.6705557200071519  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3229 episode reward:  6.0  Episode finished after 388 timesteps\n",
      "    PARAMS.epsilon:  0.6703636600071561  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3230 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.6702607000071583  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3231 episode reward:  3.0  Episode finished after 247 timesteps\n",
      "    PARAMS.epsilon:  0.670137940007161  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3232 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.6700528000071628  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3233 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.6699656800071647  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3234 episode reward:  4.0  Episode finished after 318 timesteps\n",
      "    PARAMS.epsilon:  0.6698072800071682  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3235 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.6697459000071695  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3236 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.6696825400071709  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3237 episode reward:  5.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.6695182000071744  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3238 episode reward:  2.0  Episode finished after 245 timesteps\n",
      "    PARAMS.epsilon:  0.6693974200071771  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3239 episode reward:  4.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.6692568400071801  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3240 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.6691736800071819  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3241 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.6690925000071837  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3242 episode reward:  4.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.6689657800071864  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3243 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.6689024200071878  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3244 episode reward:  5.0  Episode finished after 287 timesteps\n",
      "    PARAMS.epsilon:  0.6687598600071909  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3245 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.6686965000071923  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3246 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.6686113600071941  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3247 episode reward:  5.0  Episode finished after 306 timesteps\n",
      "    PARAMS.epsilon:  0.6684608800071974  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3248 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.6683995000071987  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3249 episode reward:  4.0  Episode finished after 310 timesteps\n",
      "    PARAMS.epsilon:  0.668247040007202  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3250 episode reward:  3.0  Episode finished after 278 timesteps\n",
      "    PARAMS.epsilon:  0.668108440007205  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3251 episode reward:  7.0  Episode finished after 407 timesteps\n",
      "    PARAMS.epsilon:  0.6679064800072094  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3252 episode reward:  3.0  Episode finished after 273 timesteps\n",
      "    PARAMS.epsilon:  0.6677718400072123  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3253 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.6676728400072145  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3254 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.6675857200072164  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3255 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.6674847400072186  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3256 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.66741940000722  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3257 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.6673520800072215  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3258 episode reward:  5.0  Episode finished after 343 timesteps\n",
      "    PARAMS.epsilon:  0.6671837800072251  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3259 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.6671006200072269  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3260 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.6670016200072291  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3261 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.6669006400072313  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3262 episode reward:  6.0  Episode finished after 378 timesteps\n",
      "    PARAMS.epsilon:  0.6667125400072353  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3263 episode reward:  3.0  Episode finished after 277 timesteps\n",
      "    PARAMS.epsilon:  0.6665759200072383  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3264 episode reward:  3.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.6664373200072413  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3265 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.6663502000072432  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3266 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.6662492200072454  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3267 episode reward:  4.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.6661185400072482  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3268 episode reward:  5.0  Episode finished after 336 timesteps\n",
      "    PARAMS.epsilon:  0.6659522200072518  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3269 episode reward:  7.0  Episode finished after 323 timesteps\n",
      "    PARAMS.epsilon:  0.6657918400072553  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3270 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.6657067000072572  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3271 episode reward:  3.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.6655681000072602  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3272 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.6655027600072616  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3273 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.6654413800072629  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3274 episode reward:  4.0  Episode finished after 277 timesteps\n",
      "    PARAMS.epsilon:  0.6653047600072659  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3275 episode reward:  5.0  Episode finished after 389 timesteps\n",
      "    PARAMS.epsilon:  0.6651127000072701  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3276 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.6650453800072715  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3277 episode reward:  3.0  Episode finished after 238 timesteps\n",
      "    PARAMS.epsilon:  0.6649265800072741  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3278 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.6648038200072768  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3279 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.6646790800072795  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3280 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.664611760007281  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3281 episode reward:  1.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.6645365200072826  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3282 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.6644593000072843  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3283 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.6643919800072857  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3284 episode reward:  5.0  Episode finished after 321 timesteps\n",
      "    PARAMS.epsilon:  0.6642335800072892  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3285 episode reward:  0.0  Episode finished after 146 timesteps\n",
      "    PARAMS.epsilon:  0.6641603200072907  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3286 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.6640910200072923  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3287 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.6640058800072941  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3288 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.6639346000072956  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3289 episode reward:  4.0  Episode finished after 265 timesteps\n",
      "    PARAMS.epsilon:  0.6638039200072985  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3290 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.6636989800073008  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3291 episode reward:  5.0  Episode finished after 358 timesteps\n",
      "    PARAMS.epsilon:  0.6635207800073046  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3292 episode reward:  4.0  Episode finished after 287 timesteps\n",
      "    PARAMS.epsilon:  0.6633802000073077  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3293 episode reward:  2.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.6632653600073102  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3294 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.6631960600073117  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3295 episode reward:  4.0  Episode finished after 273 timesteps\n",
      "    PARAMS.epsilon:  0.6630614200073146  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3296 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.6629941000073161  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3297 episode reward:  1.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.6629010400073181  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3298 episode reward:  5.0  Episode finished after 329 timesteps\n",
      "    PARAMS.epsilon:  0.6627367000073217  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3299 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.6626535400073235  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3300 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.6625644400073254  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3301 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.6624793000073272  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3302 episode reward:  2.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.6623605000073298  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3303 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.6622872400073314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3304 episode reward:  4.0  Episode finished after 286 timesteps\n",
      "    PARAMS.epsilon:  0.6621466600073345  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3305 episode reward:  0.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.6620555800073364  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3306 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.6619328200073391  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3307 episode reward:  2.0  Episode finished after 221 timesteps\n",
      "    PARAMS.epsilon:  0.6618219400073415  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3308 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.661752640007343  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3309 episode reward:  9.0  Episode finished after 465 timesteps\n",
      "    PARAMS.epsilon:  0.661522960007348  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3310 episode reward:  4.0  Episode finished after 298 timesteps\n",
      "    PARAMS.epsilon:  0.6613744600073512  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3311 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.6612972400073529  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3312 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.6612299200073544  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3313 episode reward:  7.0  Episode finished after 410 timesteps\n",
      "    PARAMS.epsilon:  0.6610259800073588  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3314 episode reward:  4.0  Episode finished after 288 timesteps\n",
      "    PARAMS.epsilon:  0.6608834200073619  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3315 episode reward:  4.0  Episode finished after 336 timesteps\n",
      "    PARAMS.epsilon:  0.6607171000073655  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3316 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.6606161200073677  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3317 episode reward:  0.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.6605309800073695  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3318 episode reward:  0.0  Episode finished after 147 timesteps\n",
      "    PARAMS.epsilon:  0.6604577200073711  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3319 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.6603547600073734  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3320 episode reward:  2.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.6602419000073758  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3321 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.6601785400073772  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3322 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.6600736000073795  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3323 episode reward:  3.0  Episode finished after 245 timesteps\n",
      "    PARAMS.epsilon:  0.6599508400073821  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3324 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.6598716400073839  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3325 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.6598043200073853  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3326 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.6597231400073871  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3327 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.6596578000073885  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3328 episode reward:  3.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.6595310800073912  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3329 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.6594400000073932  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3330 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.6593707000073947  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3331 episode reward:  2.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.6592618000073971  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3332 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.6591964600073985  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3333 episode reward:  3.0  Episode finished after 244 timesteps\n",
      "    PARAMS.epsilon:  0.6590756800074011  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3334 episode reward:  0.0  Episode finished after 150 timesteps\n",
      "    PARAMS.epsilon:  0.6590024200074027  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3335 episode reward:  3.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.6588757000074055  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3336 episode reward:  0.0  Episode finished after 146 timesteps\n",
      "    PARAMS.epsilon:  0.6588024400074071  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3337 episode reward:  4.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.6586638400074101  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3338 episode reward:  0.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.6585886000074117  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3339 episode reward:  2.0  Episode finished after 220 timesteps\n",
      "    PARAMS.epsilon:  0.6584797000074141  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3340 episode reward:  1.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.6583846600074161  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3341 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.6583193200074176  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3342 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.6582203200074197  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3343 episode reward:  11.0  Episode finished after 564 timesteps\n",
      "    PARAMS.epsilon:  0.6579411400074258  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3344 episode reward:  3.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.6578144200074285  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3345 episode reward:  5.0  Episode finished after 303 timesteps\n",
      "    PARAMS.epsilon:  0.6576639400074318  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3346 episode reward:  0.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.6575867200074335  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3347 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.6575194000074349  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3348 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.6574540600074363  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3349 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.6573847600074378  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3350 episode reward:  4.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.6572540800074407  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3351 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.6571768600074424  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3352 episode reward:  5.0  Episode finished after 349 timesteps\n",
      "    PARAMS.epsilon:  0.6570046000074461  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3353 episode reward:  9.0  Episode finished after 363 timesteps\n",
      "    PARAMS.epsilon:  0.65682442000745  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3354 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.6567571000074515  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3355 episode reward:  3.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.656640280007454  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3356 episode reward:  3.0  Episode finished after 268 timesteps\n",
      "    PARAMS.epsilon:  0.6565076200074569  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3357 episode reward:  3.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.6563848600074595  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3358 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.656319520007461  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3359 episode reward:  4.0  Episode finished after 277 timesteps\n",
      "    PARAMS.epsilon:  0.6561829000074639  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3360 episode reward:  0.0  Episode finished after 150 timesteps\n",
      "    PARAMS.epsilon:  0.6561096400074655  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3361 episode reward:  2.0  Episode finished after 207 timesteps\n",
      "    PARAMS.epsilon:  0.6560066800074678  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3362 episode reward:  4.0  Episode finished after 302 timesteps\n",
      "    PARAMS.epsilon:  0.655856200007471  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3363 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.6557532400074733  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3364 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.6556502800074755  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3365 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.655580980007477  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3366 episode reward:  3.0  Episode finished after 238 timesteps\n",
      "    PARAMS.epsilon:  0.6554641600074795  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3367 episode reward:  3.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.655351300007482  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3368 episode reward:  3.0  Episode finished after 247 timesteps\n",
      "    PARAMS.epsilon:  0.6552285400074846  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3369 episode reward:  1.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.6551354800074867  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3370 episode reward:  3.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.655026580007489  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3371 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.6549058000074917  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3372 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.6548206600074935  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3373 episode reward:  0.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.6547414600074952  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3374 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.654614740007498  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3375 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.6545375200074997  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3376 episode reward:  4.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.6544108000075024  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3377 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.6543217000075043  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3378 episode reward:  4.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.6541811200075074  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3379 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.6540563800075101  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3380 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.6539296600075128  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3381 episode reward:  3.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.6538069000075155  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3382 episode reward:  6.0  Episode finished after 319 timesteps\n",
      "    PARAMS.epsilon:  0.653648500007519  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3383 episode reward:  6.0  Episode finished after 341 timesteps\n",
      "    PARAMS.epsilon:  0.6534802000075226  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3384 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.6533653600075251  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3385 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.6532624000075273  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3386 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.6531772600075292  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3387 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.6531119200075306  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3388 episode reward:  4.0  Episode finished after 301 timesteps\n",
      "    PARAMS.epsilon:  0.6529614400075339  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3389 episode reward:  7.0  Episode finished after 438 timesteps\n",
      "    PARAMS.epsilon:  0.6527456200075386  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3390 episode reward:  5.0  Episode finished after 317 timesteps\n",
      "    PARAMS.epsilon:  0.652589200007542  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3391 episode reward:  4.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.6524624800075447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3392 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.6523615000075469  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3393 episode reward:  6.0  Episode finished after 334 timesteps\n",
      "    PARAMS.epsilon:  0.6521951800075505  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3394 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.652127860007552  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3395 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.6520486600075537  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3396 episode reward:  6.0  Episode finished after 396 timesteps\n",
      "    PARAMS.epsilon:  0.6518526400075579  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3397 episode reward:  3.0  Episode finished after 269 timesteps\n",
      "    PARAMS.epsilon:  0.6517199800075608  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3398 episode reward:  2.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.6516071200075633  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3399 episode reward:  1.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.6515041600075655  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3400 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.651436840007567  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3401 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.6513378400075691  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3402 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.6512705200075706  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3403 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.6512012200075721  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3404 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.6511339000075735  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3405 episode reward:  3.0  Episode finished after 274 timesteps\n",
      "    PARAMS.epsilon:  0.6509992600075765  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3406 episode reward:  9.0  Episode finished after 343 timesteps\n",
      "    PARAMS.epsilon:  0.6508289800075802  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3407 episode reward:  4.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.650698300007583  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3408 episode reward:  3.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.650559700007586  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3409 episode reward:  3.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.6504310000075888  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3410 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.6503636800075903  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3411 episode reward:  3.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.650234980007593  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3412 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.6501300400075953  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3413 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.6500369800075974  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3414 episode reward:  8.0  Episode finished after 449 timesteps\n",
      "    PARAMS.epsilon:  0.6498152200076022  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3415 episode reward:  1.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.6497201800076042  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3416 episode reward:  9.0  Episode finished after 463 timesteps\n",
      "    PARAMS.epsilon:  0.6494905000076092  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3417 episode reward:  0.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.6494113000076109  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3418 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.6493103200076131  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3419 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.6492430000076146  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3420 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.6491558800076165  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3421 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.6490747000076182  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3422 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.6489856000076202  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3423 episode reward:  2.0  Episode finished after 220 timesteps\n",
      "    PARAMS.epsilon:  0.6488767000076225  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3424 episode reward:  5.0  Episode finished after 307 timesteps\n",
      "    PARAMS.epsilon:  0.6487242400076259  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3425 episode reward:  2.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.6486133600076283  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3426 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.6485104000076305  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3427 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.648441100007632  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3428 episode reward:  4.0  Episode finished after 288 timesteps\n",
      "    PARAMS.epsilon:  0.6482985400076351  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3429 episode reward:  5.0  Episode finished after 326 timesteps\n",
      "    PARAMS.epsilon:  0.6481381600076386  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3430 episode reward:  5.0  Episode finished after 347 timesteps\n",
      "    PARAMS.epsilon:  0.6479659000076423  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3431 episode reward:  5.0  Episode finished after 343 timesteps\n",
      "    PARAMS.epsilon:  0.647795620007646  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3432 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.6477283000076475  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3433 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.6476431600076493  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3434 episode reward:  0.0  Episode finished after 148 timesteps\n",
      "    PARAMS.epsilon:  0.6475699000076509  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3435 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.6475045600076523  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3436 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.6474372400076538  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3437 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.6473481400076557  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3438 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.6472313200076583  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3439 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.6471442000076602  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3440 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.6470828200076615  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3441 episode reward:  6.0  Episode finished after 344 timesteps\n",
      "    PARAMS.epsilon:  0.6469125400076652  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3442 episode reward:  3.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.6468016600076676  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3443 episode reward:  1.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.6467125600076695  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3444 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.6466313800076713  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3445 episode reward:  7.0  Episode finished after 409 timesteps\n",
      "    PARAMS.epsilon:  0.6464294200076757  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3446 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.6463640800076771  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3447 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.6462928000076786  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3448 episode reward:  3.0  Episode finished after 269 timesteps\n",
      "    PARAMS.epsilon:  0.6461581600076816  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3449 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.646043320007684  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3450 episode reward:  3.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.6459106600076869  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3451 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.6458077000076892  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3452 episode reward:  0.0  Episode finished after 131 timesteps\n",
      "    PARAMS.epsilon:  0.6457423600076906  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3453 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.645675040007692  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3454 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.6456057400076936  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3455 episode reward:  7.0  Episode finished after 375 timesteps\n",
      "    PARAMS.epsilon:  0.6454216000076975  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3456 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.6453344800076994  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3457 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.6452671600077009  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3458 episode reward:  4.0  Episode finished after 277 timesteps\n",
      "    PARAMS.epsilon:  0.6451305400077039  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3459 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.6450612400077054  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3460 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.6449345200077081  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3461 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.6448335400077103  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3462 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.6447701800077117  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3463 episode reward:  0.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.6446949400077133  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3464 episode reward:  8.0  Episode finished after 459 timesteps\n",
      "    PARAMS.epsilon:  0.6444692200077182  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3465 episode reward:  3.0  Episode finished after 262 timesteps\n",
      "    PARAMS.epsilon:  0.6443385400077211  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3466 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.6442692400077226  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3467 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.6441781600077245  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3468 episode reward:  2.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.6440831200077266  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3469 episode reward:  2.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.6439702600077291  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3470 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.6438712600077312  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3471 episode reward:  0.0  Episode finished after 136 timesteps\n",
      "    PARAMS.epsilon:  0.6438039400077327  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3472 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.6437247400077344  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3473 episode reward:  2.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.6436178200077367  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3474 episode reward:  3.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.6434891200077395  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3475 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.6433841800077418  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3476 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.6433069600077435  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3477 episode reward:  0.0  Episode finished after 150 timesteps\n",
      "    PARAMS.epsilon:  0.6432317200077451  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3478 episode reward:  0.0  Episode finished after 149 timesteps\n",
      "    PARAMS.epsilon:  0.6431584600077467  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3479 episode reward:  0.0  Episode finished after 138 timesteps\n",
      "    PARAMS.epsilon:  0.6430911400077481  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3480 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.6430198600077497  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3481 episode reward:  2.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.6429070000077521  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3482 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.6428416600077536  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3483 episode reward:  1.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.6427505800077555  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3484 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.642685240007757  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3485 episode reward:  4.0  Episode finished after 290 timesteps\n",
      "    PARAMS.epsilon:  0.6425407000077601  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3486 episode reward:  7.0  Episode finished after 390 timesteps\n",
      "    PARAMS.epsilon:  0.6423486400077643  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3487 episode reward:  0.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.6422714200077659  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3488 episode reward:  3.0  Episode finished after 265 timesteps\n",
      "    PARAMS.epsilon:  0.6421407400077688  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3489 episode reward:  1.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.6420496600077708  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3490 episode reward:  2.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.6419407600077731  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3491 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.6418496800077751  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3492 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.6417784000077766  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3493 episode reward:  2.0  Episode finished after 199 timesteps\n",
      "    PARAMS.epsilon:  0.6416813800077787  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3494 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.6416021800077805  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3495 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.6415031800077826  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3496 episode reward:  0.0  Episode finished after 140 timesteps\n",
      "    PARAMS.epsilon:  0.6414338800077841  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3497 episode reward:  5.0  Episode finished after 362 timesteps\n",
      "    PARAMS.epsilon:  0.641253700007788  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3498 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.6411507400077903  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3499 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.6410814400077918  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3500 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.6409963000077936  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3501 episode reward:  4.0  Episode finished after 289 timesteps\n",
      "    PARAMS.epsilon:  0.6408537400077967  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3502 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.640748800007799  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3503 episode reward:  5.0  Episode finished after 298 timesteps\n",
      "    PARAMS.epsilon:  0.6406022800078022  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3504 episode reward:  0.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.6405250600078038  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3505 episode reward:  3.0  Episode finished after 295 timesteps\n",
      "    PARAMS.epsilon:  0.640378540007807  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3506 episode reward:  0.0  Episode finished after 150 timesteps\n",
      "    PARAMS.epsilon:  0.6403052800078086  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3507 episode reward:  3.0  Episode finished after 241 timesteps\n",
      "    PARAMS.epsilon:  0.6401864800078112  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3508 episode reward:  2.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.6400795600078135  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3509 episode reward:  4.0  Episode finished after 303 timesteps\n",
      "    PARAMS.epsilon:  0.6399310600078167  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3510 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.6398637400078182  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3511 episode reward:  6.0  Episode finished after 350 timesteps\n",
      "    PARAMS.epsilon:  0.6396914800078219  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3512 episode reward:  1.0  Episode finished after 195 timesteps\n",
      "    PARAMS.epsilon:  0.639594460007824  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3513 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.6395251600078256  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3514 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.6394222000078278  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3515 episode reward:  2.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.6393014200078304  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3516 episode reward:  5.0  Episode finished after 332 timesteps\n",
      "    PARAMS.epsilon:  0.639137080007834  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3517 episode reward:  0.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.6390578800078357  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3518 episode reward:  2.0  Episode finished after 222 timesteps\n",
      "    PARAMS.epsilon:  0.6389470000078381  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3519 episode reward:  0.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.6388678000078398  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3520 episode reward:  2.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.6387529600078423  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3521 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.6386896000078437  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3522 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.6386183200078452  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3523 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.6385292200078472  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3524 episode reward:  1.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.6384302200078493  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3525 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.6383589400078509  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3526 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.6382936000078523  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3527 episode reward:  1.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.6382005400078543  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3528 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.6381173800078561  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3529 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.6380381800078578  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3530 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.6379471000078598  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3531 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.6378283000078624  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3532 episode reward:  2.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.6377154400078648  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3533 episode reward:  2.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.6376243600078668  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3534 episode reward:  1.0  Episode finished after 173 timesteps\n",
      "    PARAMS.epsilon:  0.6375392200078687  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3535 episode reward:  0.0  Episode finished after 150 timesteps\n",
      "    PARAMS.epsilon:  0.6374639800078703  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3536 episode reward:  9.0  Episode finished after 494 timesteps\n",
      "    PARAMS.epsilon:  0.6372204400078756  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3537 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.6371313400078775  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3538 episode reward:  4.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.6370026400078803  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3539 episode reward:  3.0  Episode finished after 262 timesteps\n",
      "    PARAMS.epsilon:  0.6368719600078832  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3540 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.636784840007885  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3541 episode reward:  3.0  Episode finished after 244 timesteps\n",
      "    PARAMS.epsilon:  0.6366640600078877  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3542 episode reward:  0.0  Episode finished after 151 timesteps\n",
      "    PARAMS.epsilon:  0.6365888200078893  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3543 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.6365254600078907  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3544 episode reward:  1.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.6364304200078927  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3545 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.6363433000078946  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3546 episode reward:  3.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.6362304400078971  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3547 episode reward:  7.0  Episode finished after 404 timesteps\n",
      "    PARAMS.epsilon:  0.6360304600079014  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3548 episode reward:  3.0  Episode finished after 288 timesteps\n",
      "    PARAMS.epsilon:  0.6358879000079045  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3549 episode reward:  3.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.6357493000079075  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3550 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.6356443600079098  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3551 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.6355631800079116  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3552 episode reward:  0.0  Episode finished after 142 timesteps\n",
      "    PARAMS.epsilon:  0.6354919000079131  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3553 episode reward:  1.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.6353988400079151  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3554 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.6352978600079173  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3555 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.6352147000079191  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3556 episode reward:  0.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.6351335200079209  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3557 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.6350464000079228  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3558 episode reward:  3.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.6349276000079254  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3559 episode reward:  2.0  Episode finished after 240 timesteps\n",
      "    PARAMS.epsilon:  0.6348088000079279  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3560 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.6347038600079302  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3561 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.6345890200079327  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3562 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.6344880400079349  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3563 episode reward:  0.0  Episode finished after 135 timesteps\n",
      "    PARAMS.epsilon:  0.6344207200079364  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3564 episode reward:  6.0  Episode finished after 363 timesteps\n",
      "    PARAMS.epsilon:  0.6342425200079402  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3565 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.6341375800079425  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3566 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.6340385800079447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3567 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.6339673000079462  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3568 episode reward:  5.0  Episode finished after 316 timesteps\n",
      "    PARAMS.epsilon:  0.6338108800079496  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3569 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.6337415800079511  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3570 episode reward:  5.0  Episode finished after 319 timesteps\n",
      "    PARAMS.epsilon:  0.6335831800079545  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3571 episode reward:  2.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.6334762600079569  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3572 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.6333970600079586  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3573 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.63333370000796  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3574 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.6332069800079627  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3575 episode reward:  2.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.6331119400079648  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3576 episode reward:  0.0  Episode finished after 141 timesteps\n",
      "    PARAMS.epsilon:  0.6330426400079663  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3577 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.6329713600079678  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3578 episode reward:  6.0  Episode finished after 351 timesteps\n",
      "    PARAMS.epsilon:  0.6327971200079716  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3579 episode reward:  1.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.6327139600079734  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3580 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.6326506000079748  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3581 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.632549620007977  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3582 episode reward:  3.0  Episode finished after 239 timesteps\n",
      "    PARAMS.epsilon:  0.6324308200079796  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3583 episode reward:  2.0  Episode finished after 226 timesteps\n",
      "    PARAMS.epsilon:  0.632319940007982  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3584 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.6322546000079834  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3585 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.632179360007985  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3586 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.6321021400079867  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3587 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.6320348200079882  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3588 episode reward:  0.0  Episode finished after 139 timesteps\n",
      "    PARAMS.epsilon:  0.6319655200079897  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3589 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.6318427600079923  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3590 episode reward:  4.0  Episode finished after 273 timesteps\n",
      "    PARAMS.epsilon:  0.6317061400079953  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3591 episode reward:  3.0  Episode finished after 247 timesteps\n",
      "    PARAMS.epsilon:  0.6315853600079979  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3592 episode reward:  1.0  Episode finished after 192 timesteps\n",
      "    PARAMS.epsilon:  0.631490320008  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3593 episode reward:  2.0  Episode finished after 222 timesteps\n",
      "    PARAMS.epsilon:  0.6313794400080024  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3594 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.6313160800080038  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3595 episode reward:  4.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.6311774800080068  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3596 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.6310903600080087  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3597 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.63102700000801  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3598 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.6309577000080115  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3599 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.6308765200080133  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3600 episode reward:  5.0  Episode finished after 339 timesteps\n",
      "    PARAMS.epsilon:  0.6307102000080169  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3601 episode reward:  1.0  Episode finished after 177 timesteps\n",
      "    PARAMS.epsilon:  0.6306211000080189  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3602 episode reward:  3.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.6305102200080213  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3603 episode reward:  4.0  Episode finished after 295 timesteps\n",
      "    PARAMS.epsilon:  0.6303656800080244  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3604 episode reward:  6.0  Episode finished after 329 timesteps\n",
      "    PARAMS.epsilon:  0.630201340008028  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3605 episode reward:  5.0  Episode finished after 326 timesteps\n",
      "    PARAMS.epsilon:  0.6300409600080314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3606 episode reward:  1.0  Episode finished after 161 timesteps\n",
      "    PARAMS.epsilon:  0.6299617600080332  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3607 episode reward:  1.0  Episode finished after 174 timesteps\n",
      "    PARAMS.epsilon:  0.6298746400080351  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3608 episode reward:  4.0  Episode finished after 291 timesteps\n",
      "    PARAMS.epsilon:  0.6297301000080382  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3609 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.62964892000804  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3610 episode reward:  1.0  Episode finished after 176 timesteps\n",
      "    PARAMS.epsilon:  0.6295618000080418  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3611 episode reward:  5.0  Episode finished after 349 timesteps\n",
      "    PARAMS.epsilon:  0.6293875600080456  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3612 episode reward:  2.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.629276680008048  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3613 episode reward:  5.0  Episode finished after 320 timesteps\n",
      "    PARAMS.epsilon:  0.6291182800080515  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3614 episode reward:  5.0  Episode finished after 359 timesteps\n",
      "    PARAMS.epsilon:  0.6289400800080553  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3615 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.628862860008057  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3616 episode reward:  4.0  Episode finished after 294 timesteps\n",
      "    PARAMS.epsilon:  0.6287183200080602  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3617 episode reward:  2.0  Episode finished after 194 timesteps\n",
      "    PARAMS.epsilon:  0.6286213000080623  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3618 episode reward:  1.0  Episode finished after 163 timesteps\n",
      "    PARAMS.epsilon:  0.628540120008064  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3619 episode reward:  3.0  Episode finished after 310 timesteps\n",
      "    PARAMS.epsilon:  0.6283876600080673  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3620 episode reward:  5.0  Episode finished after 351 timesteps\n",
      "    PARAMS.epsilon:  0.6282134200080711  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3621 episode reward:  1.0  Episode finished after 170 timesteps\n",
      "    PARAMS.epsilon:  0.6281302600080729  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3622 episode reward:  0.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.6280471000080747  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3623 episode reward:  4.0  Episode finished after 272 timesteps\n",
      "    PARAMS.epsilon:  0.6279124600080777  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3624 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.6278312800080794  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3625 episode reward:  3.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.6277204000080818  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3626 episode reward:  5.0  Episode finished after 300 timesteps\n",
      "    PARAMS.epsilon:  0.627571900008085  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3627 episode reward:  3.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.6274313200080881  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3628 episode reward:  1.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.6273303400080903  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3629 episode reward:  1.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.6272471800080921  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3630 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.6271462000080943  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3631 episode reward:  8.0  Episode finished after 310 timesteps\n",
      "    PARAMS.epsilon:  0.6269917600080976  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3632 episode reward:  4.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.6268650400081004  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3633 episode reward:  4.0  Episode finished after 278 timesteps\n",
      "    PARAMS.epsilon:  0.6267284200081034  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3634 episode reward:  4.0  Episode finished after 266 timesteps\n",
      "    PARAMS.epsilon:  0.6265957600081062  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3635 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.6264928000081085  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3636 episode reward:  9.0  Episode finished after 335 timesteps\n",
      "    PARAMS.epsilon:  0.6263264800081121  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3637 episode reward:  5.0  Episode finished after 298 timesteps\n",
      "    PARAMS.epsilon:  0.6261779800081153  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3638 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.6260789800081175  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3639 episode reward:  5.0  Episode finished after 307 timesteps\n",
      "    PARAMS.epsilon:  0.6259265200081208  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3640 episode reward:  7.0  Episode finished after 401 timesteps\n",
      "    PARAMS.epsilon:  0.6257285200081251  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3641 episode reward:  6.0  Episode finished after 371 timesteps\n",
      "    PARAMS.epsilon:  0.6255443800081291  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3642 episode reward:  1.0  Episode finished after 178 timesteps\n",
      "    PARAMS.epsilon:  0.625457260008131  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3643 episode reward:  0.0  Episode finished after 130 timesteps\n",
      "    PARAMS.epsilon:  0.6253919200081324  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3644 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.6253305400081337  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3645 episode reward:  3.0  Episode finished after 222 timesteps\n",
      "    PARAMS.epsilon:  0.6252196600081361  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3646 episode reward:  5.0  Episode finished after 303 timesteps\n",
      "    PARAMS.epsilon:  0.6250691800081394  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3647 episode reward:  5.0  Episode finished after 330 timesteps\n",
      "    PARAMS.epsilon:  0.6249068200081429  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3648 episode reward:  4.0  Episode finished after 266 timesteps\n",
      "    PARAMS.epsilon:  0.6247741600081458  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3649 episode reward:  9.0  Episode finished after 338 timesteps\n",
      "    PARAMS.epsilon:  0.6246078400081494  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3650 episode reward:  4.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.6244811200081521  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3651 episode reward:  5.0  Episode finished after 329 timesteps\n",
      "    PARAMS.epsilon:  0.6243167800081557  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3652 episode reward:  5.0  Episode finished after 321 timesteps\n",
      "    PARAMS.epsilon:  0.6241583800081592  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3653 episode reward:  4.0  Episode finished after 296 timesteps\n",
      "    PARAMS.epsilon:  0.6240118600081623  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3654 episode reward:  6.0  Episode finished after 377 timesteps\n",
      "    PARAMS.epsilon:  0.6238257400081664  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3655 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.6237227800081686  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3656 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.6236416000081704  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3657 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.6235564600081722  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3658 episode reward:  3.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.6234376600081748  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3659 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.6233564800081766  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3660 episode reward:  0.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.6232792600081782  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3661 episode reward:  1.0  Episode finished after 172 timesteps\n",
      "    PARAMS.epsilon:  0.6231941200081801  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3662 episode reward:  2.0  Episode finished after 227 timesteps\n",
      "    PARAMS.epsilon:  0.6230812600081825  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3663 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.6230000800081843  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3664 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.6228951400081866  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3665 episode reward:  4.0  Episode finished after 309 timesteps\n",
      "    PARAMS.epsilon:  0.6227426800081899  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3666 episode reward:  0.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.6226595200081917  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3667 episode reward:  6.0  Episode finished after 355 timesteps\n",
      "    PARAMS.epsilon:  0.6224833000081955  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3668 episode reward:  4.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.6223565800081983  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3669 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.622229860008201  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3670 episode reward:  5.0  Episode finished after 339 timesteps\n",
      "    PARAMS.epsilon:  0.6220635400082046  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3671 episode reward:  4.0  Episode finished after 276 timesteps\n",
      "    PARAMS.epsilon:  0.6219269200082076  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3672 episode reward:  1.0  Episode finished after 169 timesteps\n",
      "    PARAMS.epsilon:  0.6218417800082094  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3673 episode reward:  5.0  Episode finished after 321 timesteps\n",
      "    PARAMS.epsilon:  0.6216833800082129  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3674 episode reward:  5.0  Episode finished after 298 timesteps\n",
      "    PARAMS.epsilon:  0.6215368600082161  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3675 episode reward:  2.0  Episode finished after 221 timesteps\n",
      "    PARAMS.epsilon:  0.6214259800082185  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3676 episode reward:  4.0  Episode finished after 287 timesteps\n",
      "    PARAMS.epsilon:  0.6212854000082215  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3677 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.6211844200082237  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3678 episode reward:  3.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.621077500008226  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3679 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.6209903800082279  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3680 episode reward:  0.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.6209151400082296  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3681 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.6208300000082314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3682 episode reward:  0.0  Episode finished after 143 timesteps\n",
      "    PARAMS.epsilon:  0.620758720008233  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3683 episode reward:  3.0  Episode finished after 269 timesteps\n",
      "    PARAMS.epsilon:  0.6206260600082358  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3684 episode reward:  3.0  Episode finished after 268 timesteps\n",
      "    PARAMS.epsilon:  0.6204934000082387  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3685 episode reward:  4.0  Episode finished after 271 timesteps\n",
      "    PARAMS.epsilon:  0.6203587600082416  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3686 episode reward:  9.0  Episode finished after 464 timesteps\n",
      "    PARAMS.epsilon:  0.6201290800082466  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3687 episode reward:  2.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.6200360200082486  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3688 episode reward:  0.0  Episode finished after 134 timesteps\n",
      "    PARAMS.epsilon:  0.6199706800082501  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3689 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.6198697000082523  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3690 episode reward:  1.0  Episode finished after 175 timesteps\n",
      "    PARAMS.epsilon:  0.6197825800082541  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3691 episode reward:  4.0  Episode finished after 291 timesteps\n",
      "    PARAMS.epsilon:  0.6196380400082573  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3692 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.6195667600082588  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3693 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.6195053800082602  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3694 episode reward:  5.0  Episode finished after 320 timesteps\n",
      "    PARAMS.epsilon:  0.6193469800082636  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3695 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.6192460000082658  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3696 episode reward:  4.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.6191054200082688  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3697 episode reward:  5.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.6189668200082719  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3698 episode reward:  1.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.6188777200082738  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3699 episode reward:  0.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.6187945600082756  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3700 episode reward:  6.0  Episode finished after 351 timesteps\n",
      "    PARAMS.epsilon:  0.6186203200082794  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3701 episode reward:  3.0  Episode finished after 226 timesteps\n",
      "    PARAMS.epsilon:  0.6185094400082818  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3702 episode reward:  6.0  Episode finished after 395 timesteps\n",
      "    PARAMS.epsilon:  0.618313420008286  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3703 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.6182342200082878  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3704 episode reward:  1.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.6181589800082894  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3705 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.6180936400082908  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3706 episode reward:  11.0  Episode finished after 426 timesteps\n",
      "    PARAMS.epsilon:  0.6178837600082954  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3707 episode reward:  2.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.6177728800082978  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3708 episode reward:  0.0  Episode finished after 132 timesteps\n",
      "    PARAMS.epsilon:  0.6177075400082992  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3709 episode reward:  3.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.6175946800083016  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3710 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.6174937000083038  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3711 episode reward:  4.0  Episode finished after 288 timesteps\n",
      "    PARAMS.epsilon:  0.6173511400083069  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3712 episode reward:  3.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.6172382800083094  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3713 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.6170977000083124  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3714 episode reward:  5.0  Episode finished after 305 timesteps\n",
      "    PARAMS.epsilon:  0.6169472200083157  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3715 episode reward:  3.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.6168323800083182  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3716 episode reward:  0.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.6167531800083199  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3717 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.6166522000083221  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3718 episode reward:  2.0  Episode finished after 196 timesteps\n",
      "    PARAMS.epsilon:  0.6165551800083242  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3719 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.616474000008326  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3720 episode reward:  3.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.6163651000083283  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3721 episode reward:  2.0  Episode finished after 209 timesteps\n",
      "    PARAMS.epsilon:  0.6162621400083306  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3722 episode reward:  4.0  Episode finished after 292 timesteps\n",
      "    PARAMS.epsilon:  0.6161176000083337  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3723 episode reward:  3.0  Episode finished after 245 timesteps\n",
      "    PARAMS.epsilon:  0.6159968200083363  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3724 episode reward:  5.0  Episode finished after 358 timesteps\n",
      "    PARAMS.epsilon:  0.6158186200083402  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3725 episode reward:  3.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.615689920008343  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3726 episode reward:  3.0  Episode finished after 282 timesteps\n",
      "    PARAMS.epsilon:  0.615551320008346  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3727 episode reward:  2.0  Episode finished after 186 timesteps\n",
      "    PARAMS.epsilon:  0.615458260008348  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3728 episode reward:  13.0  Episode finished after 474 timesteps\n",
      "    PARAMS.epsilon:  0.6152246200083531  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3729 episode reward:  7.0  Episode finished after 384 timesteps\n",
      "    PARAMS.epsilon:  0.6150345400083572  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3730 episode reward:  8.0  Episode finished after 450 timesteps\n",
      "    PARAMS.epsilon:  0.6148108000083621  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3731 episode reward:  4.0  Episode finished after 267 timesteps\n",
      "    PARAMS.epsilon:  0.6146801200083649  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3732 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.6145633000083675  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3733 episode reward:  7.0  Episode finished after 389 timesteps\n",
      "    PARAMS.epsilon:  0.6143692600083717  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3734 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.6142524400083742  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3735 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.6141613600083762  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3736 episode reward:  3.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.6140386000083788  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3737 episode reward:  5.0  Episode finished after 317 timesteps\n",
      "    PARAMS.epsilon:  0.6138821800083822  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3738 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.6137673400083847  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3739 episode reward:  2.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.6136742800083868  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3740 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.6135950800083885  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3741 episode reward:  4.0  Episode finished after 291 timesteps\n",
      "    PARAMS.epsilon:  0.6134505400083916  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3742 episode reward:  4.0  Episode finished after 309 timesteps\n",
      "    PARAMS.epsilon:  0.6132980800083949  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3743 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.6132208600083966  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3744 episode reward:  5.0  Episode finished after 318 timesteps\n",
      "    PARAMS.epsilon:  0.6130624600084  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3745 episode reward:  3.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.6129575200084023  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3746 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.6128763400084041  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3747 episode reward:  1.0  Episode finished after 150 timesteps\n",
      "    PARAMS.epsilon:  0.6128030800084057  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3748 episode reward:  4.0  Episode finished after 295 timesteps\n",
      "    PARAMS.epsilon:  0.6126565600084088  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3749 episode reward:  4.0  Episode finished after 267 timesteps\n",
      "    PARAMS.epsilon:  0.6125239000084117  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3750 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.6124447000084134  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3751 episode reward:  5.0  Episode finished after 354 timesteps\n",
      "    PARAMS.epsilon:  0.6122684800084173  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3752 episode reward:  3.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.6121536400084198  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3753 episode reward:  3.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.6120427600084222  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3754 episode reward:  4.0  Episode finished after 306 timesteps\n",
      "    PARAMS.epsilon:  0.6118903000084255  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3755 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.6117635800084282  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3756 episode reward:  0.0  Episode finished after 129 timesteps\n",
      "    PARAMS.epsilon:  0.6117002200084296  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3757 episode reward:  9.0  Episode finished after 453 timesteps\n",
      "    PARAMS.epsilon:  0.6114764800084345  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3758 episode reward:  4.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.6113517400084372  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3759 episode reward:  6.0  Episode finished after 350 timesteps\n",
      "    PARAMS.epsilon:  0.6111794800084409  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3760 episode reward:  5.0  Episode finished after 324 timesteps\n",
      "    PARAMS.epsilon:  0.6110191000084444  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3761 episode reward:  3.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.6109082200084468  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3762 episode reward:  2.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.6108131800084489  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3763 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.6107478400084503  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3764 episode reward:  2.0  Episode finished after 190 timesteps\n",
      "    PARAMS.epsilon:  0.6106528000084523  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3765 episode reward:  4.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.610530040008455  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3766 episode reward:  6.0  Episode finished after 366 timesteps\n",
      "    PARAMS.epsilon:  0.6103498600084589  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3767 episode reward:  3.0  Episode finished after 262 timesteps\n",
      "    PARAMS.epsilon:  0.6102191800084618  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3768 episode reward:  6.0  Episode finished after 372 timesteps\n",
      "    PARAMS.epsilon:  0.6100350400084658  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3769 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.6098944600084688  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3770 episode reward:  9.0  Episode finished after 335 timesteps\n",
      "    PARAMS.epsilon:  0.6097281400084724  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3771 episode reward:  4.0  Episode finished after 284 timesteps\n",
      "    PARAMS.epsilon:  0.6095875600084755  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3772 episode reward:  6.0  Episode finished after 349 timesteps\n",
      "    PARAMS.epsilon:  0.6094153000084792  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3773 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.6093103600084815  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3774 episode reward:  7.0  Episode finished after 365 timesteps\n",
      "    PARAMS.epsilon:  0.6091301800084854  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3775 episode reward:  3.0  Episode finished after 254 timesteps\n",
      "    PARAMS.epsilon:  0.6090034600084882  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3776 episode reward:  10.0  Episode finished after 513 timesteps\n",
      "    PARAMS.epsilon:  0.6087500200084937  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3777 episode reward:  1.0  Episode finished after 166 timesteps\n",
      "    PARAMS.epsilon:  0.6086668600084955  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3778 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.6085916200084971  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3779 episode reward:  3.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.6084827200084995  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3780 episode reward:  7.0  Episode finished after 411 timesteps\n",
      "    PARAMS.epsilon:  0.6082787800085039  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3781 episode reward:  5.0  Episode finished after 337 timesteps\n",
      "    PARAMS.epsilon:  0.6081124600085075  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3782 episode reward:  5.0  Episode finished after 298 timesteps\n",
      "    PARAMS.epsilon:  0.6079659400085107  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3783 episode reward:  7.0  Episode finished after 375 timesteps\n",
      "    PARAMS.epsilon:  0.6077798200085147  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3784 episode reward:  14.0  Episode finished after 509 timesteps\n",
      "    PARAMS.epsilon:  0.6075283600085202  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3785 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.6074016400085229  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3786 episode reward:  4.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.6072769000085256  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3787 episode reward:  1.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.607168000008528  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3788 episode reward:  7.0  Episode finished after 367 timesteps\n",
      "    PARAMS.epsilon:  0.606985840008532  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3789 episode reward:  6.0  Episode finished after 358 timesteps\n",
      "    PARAMS.epsilon:  0.6068096200085358  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3790 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.6067244800085376  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3791 episode reward:  5.0  Episode finished after 319 timesteps\n",
      "    PARAMS.epsilon:  0.6065660800085411  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3792 episode reward:  3.0  Episode finished after 252 timesteps\n",
      "    PARAMS.epsilon:  0.6064413400085438  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3793 episode reward:  3.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.6063265000085463  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3794 episode reward:  6.0  Episode finished after 352 timesteps\n",
      "    PARAMS.epsilon:  0.60615226000855  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3795 episode reward:  5.0  Episode finished after 338 timesteps\n",
      "    PARAMS.epsilon:  0.6059839600085537  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3796 episode reward:  4.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.6058453600085567  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3797 episode reward:  8.0  Episode finished after 427 timesteps\n",
      "    PARAMS.epsilon:  0.6056354800085613  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3798 episode reward:  0.0  Episode finished after 144 timesteps\n",
      "    PARAMS.epsilon:  0.6055642000085628  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3799 episode reward:  7.0  Episode finished after 417 timesteps\n",
      "    PARAMS.epsilon:  0.6053563000085673  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3800 episode reward:  1.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.6052672000085693  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3801 episode reward:  5.0  Episode finished after 308 timesteps\n",
      "    PARAMS.epsilon:  0.6051147400085726  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3802 episode reward:  10.0  Episode finished after 459 timesteps\n",
      "    PARAMS.epsilon:  0.6048870400085775  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3803 episode reward:  4.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.6047642800085802  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3804 episode reward:  3.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.6046494400085827  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3805 episode reward:  9.0  Episode finished after 330 timesteps\n",
      "    PARAMS.epsilon:  0.6044851000085862  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3806 episode reward:  18.0  Episode finished after 545 timesteps\n",
      "    PARAMS.epsilon:  0.6042158200085921  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  18.0  agent.save() Done!\n",
      "PARAMS.episode_i:  3807 episode reward:  6.0  Episode finished after 340 timesteps\n",
      "    PARAMS.epsilon:  0.6040475200085957  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3808 episode reward:  9.0  Episode finished after 466 timesteps\n",
      "    PARAMS.epsilon:  0.6038178400086007  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3809 episode reward:  7.0  Episode finished after 406 timesteps\n",
      "    PARAMS.epsilon:  0.6036158800086051  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3810 episode reward:  4.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.6034970800086077  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3811 episode reward:  5.0  Episode finished after 294 timesteps\n",
      "    PARAMS.epsilon:  0.6033505600086109  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3812 episode reward:  1.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.6032495800086131  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3813 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.6031723600086147  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3814 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.6030793000086168  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3815 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.6029862400086188  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3816 episode reward:  5.0  Episode finished after 306 timesteps\n",
      "    PARAMS.epsilon:  0.602835760008622  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3817 episode reward:  7.0  Episode finished after 447 timesteps\n",
      "    PARAMS.epsilon:  0.6026140000086269  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3818 episode reward:  10.0  Episode finished after 521 timesteps\n",
      "    PARAMS.epsilon:  0.6023566000086324  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3819 episode reward:  1.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.6022615600086345  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3820 episode reward:  3.0  Episode finished after 244 timesteps\n",
      "    PARAMS.epsilon:  0.6021407800086371  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3821 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.6020239600086397  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3822 episode reward:  6.0  Episode finished after 356 timesteps\n",
      "    PARAMS.epsilon:  0.6018477400086435  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3823 episode reward:  4.0  Episode finished after 265 timesteps\n",
      "    PARAMS.epsilon:  0.6017170600086463  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3824 episode reward:  7.0  Episode finished after 404 timesteps\n",
      "    PARAMS.epsilon:  0.6015170800086507  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3825 episode reward:  0.0  Episode finished after 137 timesteps\n",
      "    PARAMS.epsilon:  0.6014497600086521  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3826 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.6013349200086546  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3827 episode reward:  10.0  Episode finished after 408 timesteps\n",
      "    PARAMS.epsilon:  0.601132960008659  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3828 episode reward:  4.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.6009983200086619  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3829 episode reward:  6.0  Episode finished after 341 timesteps\n",
      "    PARAMS.epsilon:  0.6008300200086656  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3830 episode reward:  5.0  Episode finished after 311 timesteps\n",
      "    PARAMS.epsilon:  0.6006755800086689  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3831 episode reward:  1.0  Episode finished after 162 timesteps\n",
      "    PARAMS.epsilon:  0.6005963800086707  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3832 episode reward:  4.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.6004657000086735  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3833 episode reward:  5.0  Episode finished after 350 timesteps\n",
      "    PARAMS.epsilon:  0.6002914600086773  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3834 episode reward:  6.0  Episode finished after 382 timesteps\n",
      "    PARAMS.epsilon:  0.6001033600086814  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3835 episode reward:  3.0  Episode finished after 222 timesteps\n",
      "    PARAMS.epsilon:  0.5999924800086838  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3836 episode reward:  4.0  Episode finished after 276 timesteps\n",
      "    PARAMS.epsilon:  0.5998558600086867  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3837 episode reward:  7.0  Episode finished after 371 timesteps\n",
      "    PARAMS.epsilon:  0.5996737000086907  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3838 episode reward:  6.0  Episode finished after 373 timesteps\n",
      "    PARAMS.epsilon:  0.5994875800086947  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3839 episode reward:  4.0  Episode finished after 313 timesteps\n",
      "    PARAMS.epsilon:  0.5993331400086981  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3840 episode reward:  5.0  Episode finished after 332 timesteps\n",
      "    PARAMS.epsilon:  0.5991688000087017  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3841 episode reward:  1.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.5990757400087037  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3842 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.5989490200087064  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3843 episode reward:  9.0  Episode finished after 470 timesteps\n",
      "    PARAMS.epsilon:  0.5987153800087115  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3844 episode reward:  11.0  Episode finished after 544 timesteps\n",
      "    PARAMS.epsilon:  0.5984461000087173  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3845 episode reward:  5.0  Episode finished after 310 timesteps\n",
      "    PARAMS.epsilon:  0.5982936400087207  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3846 episode reward:  11.0  Episode finished after 516 timesteps\n",
      "    PARAMS.epsilon:  0.5980382200087262  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3847 episode reward:  3.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.597909520008729  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3848 episode reward:  4.0  Episode finished after 282 timesteps\n",
      "    PARAMS.epsilon:  0.597768940008732  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3849 episode reward:  5.0  Episode finished after 304 timesteps\n",
      "    PARAMS.epsilon:  0.5976184600087353  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3850 episode reward:  6.0  Episode finished after 397 timesteps\n",
      "    PARAMS.epsilon:  0.5974224400087396  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3851 episode reward:  5.0  Episode finished after 332 timesteps\n",
      "    PARAMS.epsilon:  0.5972581000087431  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3852 episode reward:  6.0  Episode finished after 352 timesteps\n",
      "    PARAMS.epsilon:  0.5970838600087469  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3853 episode reward:  2.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.5969690200087494  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3854 episode reward:  7.0  Episode finished after 339 timesteps\n",
      "    PARAMS.epsilon:  0.5968007200087531  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3855 episode reward:  7.0  Episode finished after 376 timesteps\n",
      "    PARAMS.epsilon:  0.5966146000087571  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3856 episode reward:  2.0  Episode finished after 199 timesteps\n",
      "    PARAMS.epsilon:  0.5965175800087592  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3857 episode reward:  4.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.596388880008762  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3858 episode reward:  6.0  Episode finished after 333 timesteps\n",
      "    PARAMS.epsilon:  0.5962245400087656  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3859 episode reward:  5.0  Episode finished after 323 timesteps\n",
      "    PARAMS.epsilon:  0.596064160008769  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3860 episode reward:  7.0  Episode finished after 261 timesteps\n",
      "    PARAMS.epsilon:  0.5959354600087718  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3861 episode reward:  6.0  Episode finished after 408 timesteps\n",
      "    PARAMS.epsilon:  0.5957335000087762  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3862 episode reward:  2.0  Episode finished after 197 timesteps\n",
      "    PARAMS.epsilon:  0.5956364800087783  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3863 episode reward:  7.0  Episode finished after 387 timesteps\n",
      "    PARAMS.epsilon:  0.5954444200087825  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3864 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.5953038400087856  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3865 episode reward:  7.0  Episode finished after 446 timesteps\n",
      "    PARAMS.epsilon:  0.5950820800087904  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3866 episode reward:  12.0  Episode finished after 596 timesteps\n",
      "    PARAMS.epsilon:  0.5947870600087968  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3867 episode reward:  5.0  Episode finished after 301 timesteps\n",
      "    PARAMS.epsilon:  0.5946385600088  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3868 episode reward:  3.0  Episode finished after 230 timesteps\n",
      "    PARAMS.epsilon:  0.5945257000088024  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3869 episode reward:  3.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.5944148200088049  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3870 episode reward:  4.0  Episode finished after 275 timesteps\n",
      "    PARAMS.epsilon:  0.5942782000088078  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3871 episode reward:  5.0  Episode finished after 329 timesteps\n",
      "    PARAMS.epsilon:  0.5941158400088113  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3872 episode reward:  8.0  Episode finished after 425 timesteps\n",
      "    PARAMS.epsilon:  0.5939059600088159  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3873 episode reward:  8.0  Episode finished after 311 timesteps\n",
      "    PARAMS.epsilon:  0.5937515200088193  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3874 episode reward:  13.0  Episode finished after 505 timesteps\n",
      "    PARAMS.epsilon:  0.5935020400088247  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3875 episode reward:  1.0  Episode finished after 165 timesteps\n",
      "    PARAMS.epsilon:  0.5934188800088265  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3876 episode reward:  4.0  Episode finished after 314 timesteps\n",
      "    PARAMS.epsilon:  0.5932644400088298  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3877 episode reward:  0.0  Episode finished after 145 timesteps\n",
      "    PARAMS.epsilon:  0.5931931600088314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3878 episode reward:  3.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.5930644600088342  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3879 episode reward:  8.0  Episode finished after 430 timesteps\n",
      "    PARAMS.epsilon:  0.5928526000088388  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3880 episode reward:  2.0  Episode finished after 198 timesteps\n",
      "    PARAMS.epsilon:  0.5927536000088409  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3881 episode reward:  10.0  Episode finished after 468 timesteps\n",
      "    PARAMS.epsilon:  0.592521940008846  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3882 episode reward:  12.0  Episode finished after 514 timesteps\n",
      "    PARAMS.epsilon:  0.5922685000088515  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3883 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.5921655400088537  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3884 episode reward:  5.0  Episode finished after 311 timesteps\n",
      "    PARAMS.epsilon:  0.592011100008857  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3885 episode reward:  4.0  Episode finished after 304 timesteps\n",
      "    PARAMS.epsilon:  0.5918606200088603  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3886 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.5917794400088621  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3887 episode reward:  6.0  Episode finished after 377 timesteps\n",
      "    PARAMS.epsilon:  0.5915933200088661  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3888 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.5914943200088683  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3889 episode reward:  3.0  Episode finished after 239 timesteps\n",
      "    PARAMS.epsilon:  0.5913755200088708  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3890 episode reward:  4.0  Episode finished after 318 timesteps\n",
      "    PARAMS.epsilon:  0.5912171200088743  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3891 episode reward:  3.0  Episode finished after 266 timesteps\n",
      "    PARAMS.epsilon:  0.5910864400088771  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3892 episode reward:  3.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.5909755600088795  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3893 episode reward:  8.0  Episode finished after 417 timesteps\n",
      "    PARAMS.epsilon:  0.590769640008884  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3894 episode reward:  0.0  Episode finished after 133 timesteps\n",
      "    PARAMS.epsilon:  0.5907023200088855  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3895 episode reward:  9.0  Episode finished after 483 timesteps\n",
      "    PARAMS.epsilon:  0.5904647200088906  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3896 episode reward:  5.0  Episode finished after 301 timesteps\n",
      "    PARAMS.epsilon:  0.5903142400088939  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3897 episode reward:  11.0  Episode finished after 617 timesteps\n",
      "    PARAMS.epsilon:  0.5900093200089005  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3898 episode reward:  7.0  Episode finished after 412 timesteps\n",
      "    PARAMS.epsilon:  0.5898053800089049  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3899 episode reward:  11.0  Episode finished after 409 timesteps\n",
      "    PARAMS.epsilon:  0.5896034200089093  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3900 episode reward:  3.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.5894767000089121  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3901 episode reward:  5.0  Episode finished after 359 timesteps\n",
      "    PARAMS.epsilon:  0.5892985000089159  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3902 episode reward:  3.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.5891856400089184  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3903 episode reward:  7.0  Episode finished after 379 timesteps\n",
      "    PARAMS.epsilon:  0.5889975400089225  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3904 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.588880720008925  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3905 episode reward:  13.0  Episode finished after 529 timesteps\n",
      "    PARAMS.epsilon:  0.5886193600089307  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3906 episode reward:  4.0  Episode finished after 267 timesteps\n",
      "    PARAMS.epsilon:  0.5884867000089335  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3907 episode reward:  3.0  Episode finished after 304 timesteps\n",
      "    PARAMS.epsilon:  0.5883362200089368  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3908 episode reward:  8.0  Episode finished after 455 timesteps\n",
      "    PARAMS.epsilon:  0.5881105000089417  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3909 episode reward:  3.0  Episode finished after 272 timesteps\n",
      "    PARAMS.epsilon:  0.5879758600089446  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3910 episode reward:  7.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.5878531000089473  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3911 episode reward:  6.0  Episode finished after 320 timesteps\n",
      "    PARAMS.epsilon:  0.5876947000089507  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3912 episode reward:  8.0  Episode finished after 278 timesteps\n",
      "    PARAMS.epsilon:  0.5875561000089538  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3913 episode reward:  3.0  Episode finished after 222 timesteps\n",
      "    PARAMS.epsilon:  0.5874472000089561  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3914 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.5873521600089582  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3915 episode reward:  2.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.5872591000089602  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3916 episode reward:  4.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.587130400008963  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3917 episode reward:  9.0  Episode finished after 480 timesteps\n",
      "    PARAMS.epsilon:  0.5868928000089682  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3918 episode reward:  5.0  Episode finished after 297 timesteps\n",
      "    PARAMS.epsilon:  0.5867462800089713  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3919 episode reward:  7.0  Episode finished after 351 timesteps\n",
      "    PARAMS.epsilon:  0.5865720400089751  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3920 episode reward:  10.0  Episode finished after 464 timesteps\n",
      "    PARAMS.epsilon:  0.5863423600089801  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3921 episode reward:  4.0  Episode finished after 304 timesteps\n",
      "    PARAMS.epsilon:  0.5861918800089834  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3922 episode reward:  9.0  Episode finished after 466 timesteps\n",
      "    PARAMS.epsilon:  0.5859622000089884  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3923 episode reward:  9.0  Episode finished after 497 timesteps\n",
      "    PARAMS.epsilon:  0.5857166800089937  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3924 episode reward:  4.0  Episode finished after 287 timesteps\n",
      "    PARAMS.epsilon:  0.5855741200089968  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3925 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.5854949200089985  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3926 episode reward:  11.0  Episode finished after 402 timesteps\n",
      "    PARAMS.epsilon:  0.5852969200090028  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3927 episode reward:  8.0  Episode finished after 437 timesteps\n",
      "    PARAMS.epsilon:  0.5850811000090075  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3928 episode reward:  9.0  Episode finished after 482 timesteps\n",
      "    PARAMS.epsilon:  0.5848415200090127  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3929 episode reward:  5.0  Episode finished after 344 timesteps\n",
      "    PARAMS.epsilon:  0.5846712400090164  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3930 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.5845564000090189  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3931 episode reward:  4.0  Episode finished after 330 timesteps\n",
      "    PARAMS.epsilon:  0.5843940400090224  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3932 episode reward:  2.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.5842891000090247  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3933 episode reward:  5.0  Episode finished after 311 timesteps\n",
      "    PARAMS.epsilon:  0.584134660009028  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3934 episode reward:  4.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.583996060009031  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3935 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.5838911200090333  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3936 episode reward:  5.0  Episode finished after 300 timesteps\n",
      "    PARAMS.epsilon:  0.5837426200090365  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3937 episode reward:  7.0  Episode finished after 370 timesteps\n",
      "    PARAMS.epsilon:  0.5835604600090405  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3938 episode reward:  8.0  Episode finished after 452 timesteps\n",
      "    PARAMS.epsilon:  0.5833367200090454  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3939 episode reward:  4.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.5831961400090484  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3940 episode reward:  4.0  Episode finished after 327 timesteps\n",
      "    PARAMS.epsilon:  0.5830357600090519  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3941 episode reward:  4.0  Episode finished after 286 timesteps\n",
      "    PARAMS.epsilon:  0.582893200009055  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3942 episode reward:  7.0  Episode finished after 399 timesteps\n",
      "    PARAMS.epsilon:  0.5826952000090593  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3943 episode reward:  5.0  Episode finished after 288 timesteps\n",
      "    PARAMS.epsilon:  0.5825526400090624  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3944 episode reward:  10.0  Episode finished after 539 timesteps\n",
      "    PARAMS.epsilon:  0.5822873200090681  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3945 episode reward:  2.0  Episode finished after 199 timesteps\n",
      "    PARAMS.epsilon:  0.5821883200090703  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3946 episode reward:  8.0  Episode finished after 460 timesteps\n",
      "    PARAMS.epsilon:  0.5819606200090752  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3947 episode reward:  3.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.5818517200090776  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3948 episode reward:  4.0  Episode finished after 263 timesteps\n",
      "    PARAMS.epsilon:  0.5817230200090804  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3949 episode reward:  6.0  Episode finished after 349 timesteps\n",
      "    PARAMS.epsilon:  0.5815487800090842  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3950 episode reward:  6.0  Episode finished after 355 timesteps\n",
      "    PARAMS.epsilon:  0.581374540009088  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3951 episode reward:  11.0  Episode finished after 433 timesteps\n",
      "    PARAMS.epsilon:  0.5811587200090926  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3952 episode reward:  2.0  Episode finished after 188 timesteps\n",
      "    PARAMS.epsilon:  0.5810656600090947  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3953 episode reward:  11.0  Episode finished after 407 timesteps\n",
      "    PARAMS.epsilon:  0.580865680009099  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3954 episode reward:  6.0  Episode finished after 335 timesteps\n",
      "    PARAMS.epsilon:  0.5806993600091026  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3955 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.5805944200091049  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3956 episode reward:  9.0  Episode finished after 344 timesteps\n",
      "    PARAMS.epsilon:  0.5804241400091086  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3957 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.5803231600091108  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3958 episode reward:  4.0  Episode finished after 275 timesteps\n",
      "    PARAMS.epsilon:  0.5801865400091137  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3959 episode reward:  7.0  Episode finished after 402 timesteps\n",
      "    PARAMS.epsilon:  0.579988540009118  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3960 episode reward:  13.0  Episode finished after 472 timesteps\n",
      "    PARAMS.epsilon:  0.5797549000091231  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3961 episode reward:  6.0  Episode finished after 350 timesteps\n",
      "    PARAMS.epsilon:  0.5795806600091269  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3962 episode reward:  15.0  Episode finished after 466 timesteps\n",
      "    PARAMS.epsilon:  0.5793509800091319  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3963 episode reward:  6.0  Episode finished after 348 timesteps\n",
      "    PARAMS.epsilon:  0.5791787200091356  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3964 episode reward:  7.0  Episode finished after 420 timesteps\n",
      "    PARAMS.epsilon:  0.5789708200091401  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3965 episode reward:  4.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.5788421200091429  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3966 episode reward:  4.0  Episode finished after 262 timesteps\n",
      "    PARAMS.epsilon:  0.5787114400091458  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3967 episode reward:  4.0  Episode finished after 266 timesteps\n",
      "    PARAMS.epsilon:  0.5785807600091486  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3968 episode reward:  11.0  Episode finished after 422 timesteps\n",
      "    PARAMS.epsilon:  0.5783708800091532  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3969 episode reward:  7.0  Episode finished after 415 timesteps\n",
      "    PARAMS.epsilon:  0.5781669400091576  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3970 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.5780659600091598  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3971 episode reward:  5.0  Episode finished after 329 timesteps\n",
      "    PARAMS.epsilon:  0.5779016200091633  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3972 episode reward:  1.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.5778026200091655  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3973 episode reward:  13.0  Episode finished after 463 timesteps\n",
      "    PARAMS.epsilon:  0.5775749200091704  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3974 episode reward:  5.0  Episode finished after 304 timesteps\n",
      "    PARAMS.epsilon:  0.5774244400091737  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3975 episode reward:  7.0  Episode finished after 373 timesteps\n",
      "    PARAMS.epsilon:  0.5772383200091777  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3976 episode reward:  1.0  Episode finished after 160 timesteps\n",
      "    PARAMS.epsilon:  0.5771591200091795  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3977 episode reward:  3.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.5770363600091821  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3978 episode reward:  3.0  Episode finished after 245 timesteps\n",
      "    PARAMS.epsilon:  0.5769155800091847  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3979 episode reward:  3.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.576812620009187  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3980 episode reward:  9.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.5766482800091906  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3981 episode reward:  7.0  Episode finished after 417 timesteps\n",
      "    PARAMS.epsilon:  0.576442360009195  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3982 episode reward:  6.0  Episode finished after 347 timesteps\n",
      "    PARAMS.epsilon:  0.5762701000091988  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3983 episode reward:  7.0  Episode finished after 375 timesteps\n",
      "    PARAMS.epsilon:  0.5760859600092028  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3984 episode reward:  6.0  Episode finished after 363 timesteps\n",
      "    PARAMS.epsilon:  0.5759057800092067  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3985 episode reward:  5.0  Episode finished after 315 timesteps\n",
      "    PARAMS.epsilon:  0.5757493600092101  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3986 episode reward:  19.0  Episode finished after 681 timesteps\n",
      "    PARAMS.epsilon:  0.5754127600092174  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  19.0  agent.save() Done!\n",
      "PARAMS.episode_i:  3987 episode reward:  4.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.5752642600092206  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3988 episode reward:  1.0  Episode finished after 182 timesteps\n",
      "    PARAMS.epsilon:  0.5751751600092225  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3989 episode reward:  6.0  Episode finished after 381 timesteps\n",
      "    PARAMS.epsilon:  0.5749850800092267  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3990 episode reward:  2.0  Episode finished after 206 timesteps\n",
      "    PARAMS.epsilon:  0.5748841000092288  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3991 episode reward:  5.0  Episode finished after 320 timesteps\n",
      "    PARAMS.epsilon:  0.5747257000092323  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3992 episode reward:  5.0  Episode finished after 366 timesteps\n",
      "    PARAMS.epsilon:  0.5745435400092362  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3993 episode reward:  4.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.5744049400092393  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3994 episode reward:  10.0  Episode finished after 496 timesteps\n",
      "    PARAMS.epsilon:  0.5741594200092446  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3995 episode reward:  12.0  Episode finished after 580 timesteps\n",
      "    PARAMS.epsilon:  0.5738723200092508  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3996 episode reward:  6.0  Episode finished after 334 timesteps\n",
      "    PARAMS.epsilon:  0.5737060000092544  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3997 episode reward:  4.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.5735674000092574  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3998 episode reward:  3.0  Episode finished after 254 timesteps\n",
      "    PARAMS.epsilon:  0.5734426600092601  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  3999 episode reward:  4.0  Episode finished after 271 timesteps\n",
      "    PARAMS.epsilon:  0.5733080200092631  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4000 episode reward:  3.0  Episode finished after 220 timesteps\n",
      "    PARAMS.epsilon:  0.5731991200092654  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4001 episode reward:  7.0  Episode finished after 412 timesteps\n",
      "    PARAMS.epsilon:  0.5729951800092699  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4002 episode reward:  4.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.5728605400092728  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4003 episode reward:  5.0  Episode finished after 346 timesteps\n",
      "    PARAMS.epsilon:  0.5726902600092765  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4004 episode reward:  4.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.5725516600092795  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4005 episode reward:  5.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.5724031600092827  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4006 episode reward:  6.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.5722388200092863  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4007 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.5721239800092888  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4008 episode reward:  6.0  Episode finished after 384 timesteps\n",
      "    PARAMS.epsilon:  0.5719339000092929  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4009 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.571834900009295  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4010 episode reward:  5.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.5716943200092981  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4011 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.5715537400093011  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4012 episode reward:  5.0  Episode finished after 320 timesteps\n",
      "    PARAMS.epsilon:  0.5713953400093046  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4013 episode reward:  7.0  Episode finished after 358 timesteps\n",
      "    PARAMS.epsilon:  0.5712171400093085  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4014 episode reward:  7.0  Episode finished after 396 timesteps\n",
      "    PARAMS.epsilon:  0.5710211200093127  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4015 episode reward:  3.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.5708825200093157  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4016 episode reward:  5.0  Episode finished after 300 timesteps\n",
      "    PARAMS.epsilon:  0.5707340200093189  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4017 episode reward:  6.0  Episode finished after 397 timesteps\n",
      "    PARAMS.epsilon:  0.5705360200093232  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4018 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.5704211800093257  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4019 episode reward:  6.0  Episode finished after 356 timesteps\n",
      "    PARAMS.epsilon:  0.5702449600093296  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4020 episode reward:  7.0  Episode finished after 376 timesteps\n",
      "    PARAMS.epsilon:  0.5700588400093336  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4021 episode reward:  5.0  Episode finished after 321 timesteps\n",
      "    PARAMS.epsilon:  0.569900440009337  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4022 episode reward:  7.0  Episode finished after 384 timesteps\n",
      "    PARAMS.epsilon:  0.5697103600093412  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4023 episode reward:  6.0  Episode finished after 379 timesteps\n",
      "    PARAMS.epsilon:  0.5695222600093452  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4024 episode reward:  3.0  Episode finished after 237 timesteps\n",
      "    PARAMS.epsilon:  0.5694054400093478  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4025 episode reward:  5.0  Episode finished after 322 timesteps\n",
      "    PARAMS.epsilon:  0.5692450600093513  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4026 episode reward:  3.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.5691381400093536  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4027 episode reward:  4.0  Episode finished after 265 timesteps\n",
      "    PARAMS.epsilon:  0.5690074600093564  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4028 episode reward:  6.0  Episode finished after 324 timesteps\n",
      "    PARAMS.epsilon:  0.5688470800093599  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4029 episode reward:  6.0  Episode finished after 332 timesteps\n",
      "    PARAMS.epsilon:  0.5686827400093635  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4030 episode reward:  2.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.5685698800093659  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4031 episode reward:  5.0  Episode finished after 341 timesteps\n",
      "    PARAMS.epsilon:  0.5684015800093696  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4032 episode reward:  6.0  Episode finished after 363 timesteps\n",
      "    PARAMS.epsilon:  0.5682214000093735  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4033 episode reward:  6.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.5680570600093771  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4034 episode reward:  6.0  Episode finished after 345 timesteps\n",
      "    PARAMS.epsilon:  0.5678867800093808  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4035 episode reward:  4.0  Episode finished after 301 timesteps\n",
      "    PARAMS.epsilon:  0.567738280009384  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4036 episode reward:  3.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.5676313600093863  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4037 episode reward:  14.0  Episode finished after 616 timesteps\n",
      "    PARAMS.epsilon:  0.5673264400093929  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4038 episode reward:  5.0  Episode finished after 297 timesteps\n",
      "    PARAMS.epsilon:  0.5671779400093961  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4039 episode reward:  6.0  Episode finished after 389 timesteps\n",
      "    PARAMS.epsilon:  0.5669858800094003  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4040 episode reward:  8.0  Episode finished after 456 timesteps\n",
      "    PARAMS.epsilon:  0.5667601600094052  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4041 episode reward:  6.0  Episode finished after 380 timesteps\n",
      "    PARAMS.epsilon:  0.5665720600094093  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4042 episode reward:  2.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.5664671200094116  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4043 episode reward:  1.0  Episode finished after 168 timesteps\n",
      "    PARAMS.epsilon:  0.5663839600094134  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4044 episode reward:  7.0  Episode finished after 395 timesteps\n",
      "    PARAMS.epsilon:  0.5661899200094176  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4045 episode reward:  3.0  Episode finished after 276 timesteps\n",
      "    PARAMS.epsilon:  0.5660533000094206  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4046 episode reward:  6.0  Episode finished after 337 timesteps\n",
      "    PARAMS.epsilon:  0.5658850000094242  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4047 episode reward:  5.0  Episode finished after 290 timesteps\n",
      "    PARAMS.epsilon:  0.5657424400094273  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4048 episode reward:  2.0  Episode finished after 191 timesteps\n",
      "    PARAMS.epsilon:  0.5656474000094294  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4049 episode reward:  1.0  Episode finished after 179 timesteps\n",
      "    PARAMS.epsilon:  0.5655583000094313  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4050 episode reward:  13.0  Episode finished after 597 timesteps\n",
      "    PARAMS.epsilon:  0.5652632800094377  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4051 episode reward:  6.0  Episode finished after 364 timesteps\n",
      "    PARAMS.epsilon:  0.5650831000094416  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4052 episode reward:  2.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.5649940000094436  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4053 episode reward:  6.0  Episode finished after 361 timesteps\n",
      "    PARAMS.epsilon:  0.5648158000094474  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4054 episode reward:  4.0  Episode finished after 266 timesteps\n",
      "    PARAMS.epsilon:  0.5646831400094503  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4055 episode reward:  4.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.564556420009453  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4056 episode reward:  7.0  Episode finished after 385 timesteps\n",
      "    PARAMS.epsilon:  0.5643663400094572  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4057 episode reward:  7.0  Episode finished after 378 timesteps\n",
      "    PARAMS.epsilon:  0.5641802200094612  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4058 episode reward:  5.0  Episode finished after 295 timesteps\n",
      "    PARAMS.epsilon:  0.5640337000094644  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4059 episode reward:  5.0  Episode finished after 300 timesteps\n",
      "    PARAMS.epsilon:  0.5638852000094676  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4060 episode reward:  7.0  Episode finished after 381 timesteps\n",
      "    PARAMS.epsilon:  0.5636971000094717  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4061 episode reward:  7.0  Episode finished after 365 timesteps\n",
      "    PARAMS.epsilon:  0.5635149400094757  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4062 episode reward:  0.0  Episode finished after 125 timesteps\n",
      "    PARAMS.epsilon:  0.563453560009477  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4063 episode reward:  6.0  Episode finished after 346 timesteps\n",
      "    PARAMS.epsilon:  0.5632832800094807  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4064 episode reward:  7.0  Episode finished after 353 timesteps\n",
      "    PARAMS.epsilon:  0.5631070600094845  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4065 episode reward:  9.0  Episode finished after 446 timesteps\n",
      "    PARAMS.epsilon:  0.5628872800094893  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4066 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.5627863000094915  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4067 episode reward:  2.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.5626952200094935  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4068 episode reward:  3.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.5625744400094961  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4069 episode reward:  8.0  Episode finished after 310 timesteps\n",
      "    PARAMS.epsilon:  0.5624219800094994  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4070 episode reward:  4.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.5622952600095021  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4071 episode reward:  5.0  Episode finished after 291 timesteps\n",
      "    PARAMS.epsilon:  0.5621507200095053  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4072 episode reward:  9.0  Episode finished after 516 timesteps\n",
      "    PARAMS.epsilon:  0.5618953000095108  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4073 episode reward:  7.0  Episode finished after 425 timesteps\n",
      "    PARAMS.epsilon:  0.5616854200095154  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4074 episode reward:  5.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.5615369200095186  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4075 episode reward:  6.0  Episode finished after 359 timesteps\n",
      "    PARAMS.epsilon:  0.5613587200095225  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4076 episode reward:  6.0  Episode finished after 348 timesteps\n",
      "    PARAMS.epsilon:  0.5611864600095262  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4077 episode reward:  14.0  Episode finished after 385 timesteps\n",
      "    PARAMS.epsilon:  0.5609963800095303  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4078 episode reward:  5.0  Episode finished after 304 timesteps\n",
      "    PARAMS.epsilon:  0.5608459000095336  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4079 episode reward:  5.0  Episode finished after 320 timesteps\n",
      "    PARAMS.epsilon:  0.560687500009537  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4080 episode reward:  10.0  Episode finished after 460 timesteps\n",
      "    PARAMS.epsilon:  0.560459800009542  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4081 episode reward:  4.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.5603410000095446  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4082 episode reward:  4.0  Episode finished after 261 timesteps\n",
      "    PARAMS.epsilon:  0.5602103200095474  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4083 episode reward:  6.0  Episode finished after 336 timesteps\n",
      "    PARAMS.epsilon:  0.560044000009551  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4084 episode reward:  8.0  Episode finished after 435 timesteps\n",
      "    PARAMS.epsilon:  0.5598301600095557  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4085 episode reward:  9.0  Episode finished after 435 timesteps\n",
      "    PARAMS.epsilon:  0.5596143400095603  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4086 episode reward:  4.0  Episode finished after 258 timesteps\n",
      "    PARAMS.epsilon:  0.5594856400095631  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4087 episode reward:  4.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.5593490200095661  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4088 episode reward:  7.0  Episode finished after 373 timesteps\n",
      "    PARAMS.epsilon:  0.5591629000095701  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4089 episode reward:  12.0  Episode finished after 557 timesteps\n",
      "    PARAMS.epsilon:  0.5588876800095761  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4090 episode reward:  20.0  Episode finished after 527 timesteps\n",
      "    PARAMS.epsilon:  0.5586263200095818  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  20.0  agent.save() Done!\n",
      "PARAMS.episode_i:  4091 episode reward:  6.0  Episode finished after 318 timesteps\n",
      "    PARAMS.epsilon:  0.5584699000095852  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4092 episode reward:  7.0  Episode finished after 367 timesteps\n",
      "    PARAMS.epsilon:  0.5582877400095891  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4093 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.5582105200095908  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4094 episode reward:  7.0  Episode finished after 425 timesteps\n",
      "    PARAMS.epsilon:  0.5580006400095954  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4095 episode reward:  6.0  Episode finished after 391 timesteps\n",
      "    PARAMS.epsilon:  0.5578066000095996  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4096 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.5577313600096012  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4097 episode reward:  3.0  Episode finished after 266 timesteps\n",
      "    PARAMS.epsilon:  0.5575987000096041  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4098 episode reward:  9.0  Episode finished after 436 timesteps\n",
      "    PARAMS.epsilon:  0.5573828800096088  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4099 episode reward:  9.0  Episode finished after 470 timesteps\n",
      "    PARAMS.epsilon:  0.5571512200096138  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4100 episode reward:  7.0  Episode finished after 378 timesteps\n",
      "    PARAMS.epsilon:  0.5569631200096179  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4101 episode reward:  6.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.5567987800096215  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4102 episode reward:  4.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.556679980009624  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4103 episode reward:  6.0  Episode finished after 341 timesteps\n",
      "    PARAMS.epsilon:  0.5565116800096277  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4104 episode reward:  11.0  Episode finished after 568 timesteps\n",
      "    PARAMS.epsilon:  0.5562305200096338  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4105 episode reward:  6.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.5560661800096374  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4106 episode reward:  4.0  Episode finished after 292 timesteps\n",
      "    PARAMS.epsilon:  0.5559216400096405  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4107 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.555804820009643  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4108 episode reward:  5.0  Episode finished after 312 timesteps\n",
      "    PARAMS.epsilon:  0.5556503800096464  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4109 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.5555256400096491  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4110 episode reward:  6.0  Episode finished after 358 timesteps\n",
      "    PARAMS.epsilon:  0.5553494200096529  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4111 episode reward:  5.0  Episode finished after 292 timesteps\n",
      "    PARAMS.epsilon:  0.5552048800096561  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4112 episode reward:  20.0  Episode finished after 656 timesteps\n",
      "    PARAMS.epsilon:  0.5548801600096631  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4113 episode reward:  0.0  Episode finished after 122 timesteps\n",
      "    PARAMS.epsilon:  0.5548187800096644  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4114 episode reward:  6.0  Episode finished after 342 timesteps\n",
      "    PARAMS.epsilon:  0.5546504800096681  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4115 episode reward:  1.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.5545594000096701  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4116 episode reward:  2.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.5544425800096726  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4117 episode reward:  11.0  Episode finished after 521 timesteps\n",
      "    PARAMS.epsilon:  0.5541851800096782  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4118 episode reward:  2.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.5540782600096805  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4119 episode reward:  5.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.5539139200096841  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4120 episode reward:  3.0  Episode finished after 266 timesteps\n",
      "    PARAMS.epsilon:  0.553781260009687  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4121 episode reward:  8.0  Episode finished after 438 timesteps\n",
      "    PARAMS.epsilon:  0.5535654400096917  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4122 episode reward:  5.0  Episode finished after 333 timesteps\n",
      "    PARAMS.epsilon:  0.5534011000096952  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4123 episode reward:  9.0  Episode finished after 442 timesteps\n",
      "    PARAMS.epsilon:  0.5531813200097  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4124 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.5531199400097013  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4125 episode reward:  9.0  Episode finished after 369 timesteps\n",
      "    PARAMS.epsilon:  0.5529377800097053  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4126 episode reward:  5.0  Episode finished after 294 timesteps\n",
      "    PARAMS.epsilon:  0.5527932400097084  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4127 episode reward:  4.0  Episode finished after 269 timesteps\n",
      "    PARAMS.epsilon:  0.5526586000097113  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4128 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.5525318800097141  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4129 episode reward:  5.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.5523695200097176  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4130 episode reward:  2.0  Episode finished after 204 timesteps\n",
      "    PARAMS.epsilon:  0.5522685400097198  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4131 episode reward:  6.0  Episode finished after 364 timesteps\n",
      "    PARAMS.epsilon:  0.5520883600097237  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4132 episode reward:  4.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.5519497600097267  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4133 episode reward:  4.0  Episode finished after 286 timesteps\n",
      "    PARAMS.epsilon:  0.5518072000097298  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4134 episode reward:  4.0  Episode finished after 284 timesteps\n",
      "    PARAMS.epsilon:  0.5516666200097329  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4135 episode reward:  4.0  Episode finished after 282 timesteps\n",
      "    PARAMS.epsilon:  0.5515280200097359  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4136 episode reward:  7.0  Episode finished after 414 timesteps\n",
      "    PARAMS.epsilon:  0.5513221000097404  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4137 episode reward:  5.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.5511577600097439  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4138 episode reward:  7.0  Episode finished after 348 timesteps\n",
      "    PARAMS.epsilon:  0.5509855000097477  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4139 episode reward:  16.0  Episode finished after 631 timesteps\n",
      "    PARAMS.epsilon:  0.5506746400097544  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4140 episode reward:  6.0  Episode finished after 364 timesteps\n",
      "    PARAMS.epsilon:  0.5504944600097583  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4141 episode reward:  5.0  Episode finished after 291 timesteps\n",
      "    PARAMS.epsilon:  0.5503499200097615  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4142 episode reward:  4.0  Episode finished after 264 timesteps\n",
      "    PARAMS.epsilon:  0.5502192400097643  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4143 episode reward:  7.0  Episode finished after 397 timesteps\n",
      "    PARAMS.epsilon:  0.5500232200097686  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4144 episode reward:  5.0  Episode finished after 326 timesteps\n",
      "    PARAMS.epsilon:  0.5498608600097721  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4145 episode reward:  4.0  Episode finished after 277 timesteps\n",
      "    PARAMS.epsilon:  0.549724240009775  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4146 episode reward:  4.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.5495955400097778  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4147 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.5495183200097795  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4148 episode reward:  12.0  Episode finished after 448 timesteps\n",
      "    PARAMS.epsilon:  0.5492965600097843  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4149 episode reward:  4.0  Episode finished after 239 timesteps\n",
      "    PARAMS.epsilon:  0.5491777600097869  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4150 episode reward:  11.0  Episode finished after 568 timesteps\n",
      "    PARAMS.epsilon:  0.548896600009793  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4151 episode reward:  25.0  Episode finished after 748 timesteps\n",
      "    PARAMS.epsilon:  0.548526340009801  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  25.0  agent.save() Done!\n",
      "PARAMS.episode_i:  4152 episode reward:  9.0  Episode finished after 428 timesteps\n",
      "    PARAMS.epsilon:  0.5483144800098056  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4153 episode reward:  10.0  Episode finished after 509 timesteps\n",
      "    PARAMS.epsilon:  0.5480630200098111  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4154 episode reward:  3.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.5479580800098134  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4155 episode reward:  1.0  Episode finished after 153 timesteps\n",
      "    PARAMS.epsilon:  0.5478808600098151  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4156 episode reward:  4.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.5477620600098176  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4157 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.5476630600098198  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4158 episode reward:  7.0  Episode finished after 396 timesteps\n",
      "    PARAMS.epsilon:  0.547467040009824  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4159 episode reward:  12.0  Episode finished after 452 timesteps\n",
      "    PARAMS.epsilon:  0.5472433000098289  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4160 episode reward:  1.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.5471641000098306  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4161 episode reward:  4.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.5470354000098334  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4162 episode reward:  2.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.5469245200098358  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4163 episode reward:  3.0  Episode finished after 230 timesteps\n",
      "    PARAMS.epsilon:  0.5468116600098383  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4164 episode reward:  9.0  Episode finished after 498 timesteps\n",
      "    PARAMS.epsilon:  0.5465641600098436  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4165 episode reward:  8.0  Episode finished after 447 timesteps\n",
      "    PARAMS.epsilon:  0.5463424000098485  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4166 episode reward:  3.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.546227560009851  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4167 episode reward:  6.0  Episode finished after 341 timesteps\n",
      "    PARAMS.epsilon:  0.5460592600098546  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4168 episode reward:  5.0  Episode finished after 311 timesteps\n",
      "    PARAMS.epsilon:  0.545904820009858  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4169 episode reward:  5.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.5457404800098615  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4170 episode reward:  5.0  Episode finished after 315 timesteps\n",
      "    PARAMS.epsilon:  0.5455840600098649  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4171 episode reward:  13.0  Episode finished after 544 timesteps\n",
      "    PARAMS.epsilon:  0.5453147800098708  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4172 episode reward:  3.0  Episode finished after 269 timesteps\n",
      "    PARAMS.epsilon:  0.5451821200098736  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4173 episode reward:  6.0  Episode finished after 325 timesteps\n",
      "    PARAMS.epsilon:  0.5450217400098771  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4174 episode reward:  8.0  Episode finished after 402 timesteps\n",
      "    PARAMS.epsilon:  0.5448217600098815  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4175 episode reward:  5.0  Episode finished after 355 timesteps\n",
      "    PARAMS.epsilon:  0.5446475200098853  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4176 episode reward:  4.0  Episode finished after 298 timesteps\n",
      "    PARAMS.epsilon:  0.5444990200098885  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4177 episode reward:  6.0  Episode finished after 354 timesteps\n",
      "    PARAMS.epsilon:  0.5443247800098923  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4178 episode reward:  4.0  Episode finished after 272 timesteps\n",
      "    PARAMS.epsilon:  0.5441901400098952  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4179 episode reward:  9.0  Episode finished after 500 timesteps\n",
      "    PARAMS.epsilon:  0.5439426400099006  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4180 episode reward:  9.0  Episode finished after 384 timesteps\n",
      "    PARAMS.epsilon:  0.5437525600099047  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4181 episode reward:  3.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.5436397000099071  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4182 episode reward:  5.0  Episode finished after 311 timesteps\n",
      "    PARAMS.epsilon:  0.5434872400099104  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4183 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.5433961600099124  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4184 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.5432852800099148  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4185 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.5431605400099175  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4186 episode reward:  3.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.54304570000992  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4187 episode reward:  3.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.5429328400099225  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4188 episode reward:  3.0  Episode finished after 255 timesteps\n",
      "    PARAMS.epsilon:  0.5428081000099252  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4189 episode reward:  4.0  Episode finished after 241 timesteps\n",
      "    PARAMS.epsilon:  0.5426873200099278  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4190 episode reward:  4.0  Episode finished after 286 timesteps\n",
      "    PARAMS.epsilon:  0.5425467400099309  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4191 episode reward:  0.0  Episode finished after 122 timesteps\n",
      "    PARAMS.epsilon:  0.5424853600099322  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4192 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.5423705200099347  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4193 episode reward:  5.0  Episode finished after 319 timesteps\n",
      "    PARAMS.epsilon:  0.5422121200099381  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4194 episode reward:  6.0  Episode finished after 337 timesteps\n",
      "    PARAMS.epsilon:  0.5420458000099417  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4195 episode reward:  6.0  Episode finished after 327 timesteps\n",
      "    PARAMS.epsilon:  0.5418834400099453  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4196 episode reward:  3.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.5417686000099478  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4197 episode reward:  12.0  Episode finished after 455 timesteps\n",
      "    PARAMS.epsilon:  0.5415428800099527  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4198 episode reward:  6.0  Episode finished after 316 timesteps\n",
      "    PARAMS.epsilon:  0.541386460009956  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4199 episode reward:  5.0  Episode finished after 302 timesteps\n",
      "    PARAMS.epsilon:  0.5412379600099593  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4200 episode reward:  3.0  Episode finished after 271 timesteps\n",
      "    PARAMS.epsilon:  0.5411033200099622  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4201 episode reward:  3.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.5409964000099645  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4202 episode reward:  3.0  Episode finished after 244 timesteps\n",
      "    PARAMS.epsilon:  0.5408756200099671  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4203 episode reward:  3.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.5407607800099696  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4204 episode reward:  6.0  Episode finished after 308 timesteps\n",
      "    PARAMS.epsilon:  0.5406083200099729  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4205 episode reward:  5.0  Episode finished after 297 timesteps\n",
      "    PARAMS.epsilon:  0.5404618000099761  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4206 episode reward:  8.0  Episode finished after 431 timesteps\n",
      "    PARAMS.epsilon:  0.5402479600099808  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4207 episode reward:  6.0  Episode finished after 330 timesteps\n",
      "    PARAMS.epsilon:  0.5400836200099843  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4208 episode reward:  2.0  Episode finished after 219 timesteps\n",
      "    PARAMS.epsilon:  0.5399767000099867  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4209 episode reward:  3.0  Episode finished after 237 timesteps\n",
      "    PARAMS.epsilon:  0.5398579000099892  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4210 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.5397826600099909  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4211 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.5396816800099931  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4212 episode reward:  7.0  Episode finished after 398 timesteps\n",
      "    PARAMS.epsilon:  0.5394856600099973  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4213 episode reward:  4.0  Episode finished after 261 timesteps\n",
      "    PARAMS.epsilon:  0.5393569600100001  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4214 episode reward:  6.0  Episode finished after 327 timesteps\n",
      "    PARAMS.epsilon:  0.5391946000100036  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4215 episode reward:  10.0  Episode finished after 513 timesteps\n",
      "    PARAMS.epsilon:  0.5389411600100091  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4216 episode reward:  8.0  Episode finished after 351 timesteps\n",
      "    PARAMS.epsilon:  0.5387669200100129  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4217 episode reward:  4.0  Episode finished after 282 timesteps\n",
      "    PARAMS.epsilon:  0.538626340010016  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4218 episode reward:  3.0  Episode finished after 270 timesteps\n",
      "    PARAMS.epsilon:  0.5384936800100188  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4219 episode reward:  11.0  Episode finished after 447 timesteps\n",
      "    PARAMS.epsilon:  0.5382719200100237  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4220 episode reward:  2.0  Episode finished after 215 timesteps\n",
      "    PARAMS.epsilon:  0.538165000010026  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4221 episode reward:  6.0  Episode finished after 390 timesteps\n",
      "    PARAMS.epsilon:  0.5379729400100302  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4222 episode reward:  9.0  Episode finished after 428 timesteps\n",
      "    PARAMS.epsilon:  0.5377610800100348  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4223 episode reward:  16.0  Episode finished after 432 timesteps\n",
      "    PARAMS.epsilon:  0.5375472400100394  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4224 episode reward:  3.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.5374225000100421  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4225 episode reward:  7.0  Episode finished after 382 timesteps\n",
      "    PARAMS.epsilon:  0.5372324200100462  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4226 episode reward:  3.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.5371294600100485  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4227 episode reward:  11.0  Episode finished after 511 timesteps\n",
      "    PARAMS.epsilon:  0.536876020010054  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4228 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.5367988000100556  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4229 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.5367077200100576  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4230 episode reward:  2.0  Episode finished after 198 timesteps\n",
      "    PARAMS.epsilon:  0.5366107000100597  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4231 episode reward:  12.0  Episode finished after 503 timesteps\n",
      "    PARAMS.epsilon:  0.5363612200100651  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4232 episode reward:  7.0  Episode finished after 383 timesteps\n",
      "    PARAMS.epsilon:  0.5361711400100693  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4233 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.536093920010071  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4234 episode reward:  4.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.5359573000100739  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4235 episode reward:  9.0  Episode finished after 455 timesteps\n",
      "    PARAMS.epsilon:  0.5357315800100788  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4236 episode reward:  8.0  Episode finished after 356 timesteps\n",
      "    PARAMS.epsilon:  0.5355553600100826  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4237 episode reward:  17.0  Episode finished after 621 timesteps\n",
      "    PARAMS.epsilon:  0.5352484600100893  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4238 episode reward:  7.0  Episode finished after 407 timesteps\n",
      "    PARAMS.epsilon:  0.5350465000100937  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4239 episode reward:  3.0  Episode finished after 216 timesteps\n",
      "    PARAMS.epsilon:  0.534939580010096  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4240 episode reward:  8.0  Episode finished after 450 timesteps\n",
      "    PARAMS.epsilon:  0.5347158400101009  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4241 episode reward:  6.0  Episode finished after 355 timesteps\n",
      "    PARAMS.epsilon:  0.5345416000101046  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4242 episode reward:  5.0  Episode finished after 332 timesteps\n",
      "    PARAMS.epsilon:  0.5343772600101082  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4243 episode reward:  8.0  Episode finished after 412 timesteps\n",
      "    PARAMS.epsilon:  0.5341733200101126  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4244 episode reward:  8.0  Episode finished after 347 timesteps\n",
      "    PARAMS.epsilon:  0.5340010600101164  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4245 episode reward:  8.0  Episode finished after 406 timesteps\n",
      "    PARAMS.epsilon:  0.5337991000101208  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4246 episode reward:  7.0  Episode finished after 392 timesteps\n",
      "    PARAMS.epsilon:  0.533605060010125  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4247 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.5335298200101266  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4248 episode reward:  9.0  Episode finished after 436 timesteps\n",
      "    PARAMS.epsilon:  0.5333140000101313  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4249 episode reward:  4.0  Episode finished after 261 timesteps\n",
      "    PARAMS.epsilon:  0.5331833200101341  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4250 episode reward:  4.0  Episode finished after 274 timesteps\n",
      "    PARAMS.epsilon:  0.533048680010137  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4251 episode reward:  3.0  Episode finished after 214 timesteps\n",
      "    PARAMS.epsilon:  0.5329417600101394  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4252 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.5328269200101419  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4253 episode reward:  4.0  Episode finished after 284 timesteps\n",
      "    PARAMS.epsilon:  0.5326863400101449  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4254 episode reward:  6.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.5325220000101485  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4255 episode reward:  5.0  Episode finished after 347 timesteps\n",
      "    PARAMS.epsilon:  0.5323517200101522  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4256 episode reward:  5.0  Episode finished after 332 timesteps\n",
      "    PARAMS.epsilon:  0.5321873800101558  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4257 episode reward:  6.0  Episode finished after 370 timesteps\n",
      "    PARAMS.epsilon:  0.5320032400101598  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4258 episode reward:  8.0  Episode finished after 370 timesteps\n",
      "    PARAMS.epsilon:  0.5318210800101637  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4259 episode reward:  12.0  Episode finished after 479 timesteps\n",
      "    PARAMS.epsilon:  0.5315834800101689  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4260 episode reward:  10.0  Episode finished after 375 timesteps\n",
      "    PARAMS.epsilon:  0.5313973600101729  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4261 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.531256780010176  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4262 episode reward:  7.0  Episode finished after 356 timesteps\n",
      "    PARAMS.epsilon:  0.5310805600101798  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4263 episode reward:  4.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.5309419600101828  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4264 episode reward:  6.0  Episode finished after 323 timesteps\n",
      "    PARAMS.epsilon:  0.5307815800101863  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4265 episode reward:  9.0  Episode finished after 480 timesteps\n",
      "    PARAMS.epsilon:  0.5305439800101914  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4266 episode reward:  5.0  Episode finished after 342 timesteps\n",
      "    PARAMS.epsilon:  0.5303737000101951  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4267 episode reward:  6.0  Episode finished after 348 timesteps\n",
      "    PARAMS.epsilon:  0.5302014400101989  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4268 episode reward:  4.0  Episode finished after 288 timesteps\n",
      "    PARAMS.epsilon:  0.530058880010202  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4269 episode reward:  7.0  Episode finished after 401 timesteps\n",
      "    PARAMS.epsilon:  0.5298608800102063  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4270 episode reward:  5.0  Episode finished after 295 timesteps\n",
      "    PARAMS.epsilon:  0.5297143600102094  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4271 episode reward:  8.0  Episode finished after 454 timesteps\n",
      "    PARAMS.epsilon:  0.5294906200102143  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4272 episode reward:  10.0  Episode finished after 471 timesteps\n",
      "    PARAMS.epsilon:  0.5292569800102194  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4273 episode reward:  9.0  Episode finished after 439 timesteps\n",
      "    PARAMS.epsilon:  0.5290391800102241  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4274 episode reward:  6.0  Episode finished after 341 timesteps\n",
      "    PARAMS.epsilon:  0.5288708800102278  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4275 episode reward:  6.0  Episode finished after 340 timesteps\n",
      "    PARAMS.epsilon:  0.5287025800102314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4276 episode reward:  9.0  Episode finished after 408 timesteps\n",
      "    PARAMS.epsilon:  0.5285006200102358  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4277 episode reward:  5.0  Episode finished after 352 timesteps\n",
      "    PARAMS.epsilon:  0.5283263800102396  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4278 episode reward:  3.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.528213520010242  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4279 episode reward:  7.0  Episode finished after 401 timesteps\n",
      "    PARAMS.epsilon:  0.5280155200102463  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4280 episode reward:  11.0  Episode finished after 549 timesteps\n",
      "    PARAMS.epsilon:  0.5277442600102522  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4281 episode reward:  16.0  Episode finished after 774 timesteps\n",
      "    PARAMS.epsilon:  0.5273601400102605  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4282 episode reward:  12.0  Episode finished after 573 timesteps\n",
      "    PARAMS.epsilon:  0.5270770000102667  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4283 episode reward:  13.0  Episode finished after 478 timesteps\n",
      "    PARAMS.epsilon:  0.5268394000102719  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4284 episode reward:  5.0  Episode finished after 327 timesteps\n",
      "    PARAMS.epsilon:  0.5266790200102753  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4285 episode reward:  5.0  Episode finished after 319 timesteps\n",
      "    PARAMS.epsilon:  0.5265206200102788  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4286 episode reward:  14.0  Episode finished after 580 timesteps\n",
      "    PARAMS.epsilon:  0.526233520010285  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4287 episode reward:  9.0  Episode finished after 307 timesteps\n",
      "    PARAMS.epsilon:  0.5260810600102883  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4288 episode reward:  12.0  Episode finished after 393 timesteps\n",
      "    PARAMS.epsilon:  0.5258870200102925  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4289 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.525772180010295  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4290 episode reward:  9.0  Episode finished after 475 timesteps\n",
      "    PARAMS.epsilon:  0.5255365600103001  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4291 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.5254593400103018  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4292 episode reward:  3.0  Episode finished after 230 timesteps\n",
      "    PARAMS.epsilon:  0.5253464800103043  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4293 episode reward:  2.0  Episode finished after 205 timesteps\n",
      "    PARAMS.epsilon:  0.5252435200103065  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4294 episode reward:  2.0  Episode finished after 202 timesteps\n",
      "    PARAMS.epsilon:  0.5251445200103086  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4295 episode reward:  4.0  Episode finished after 239 timesteps\n",
      "    PARAMS.epsilon:  0.5250257200103112  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4296 episode reward:  6.0  Episode finished after 335 timesteps\n",
      "    PARAMS.epsilon:  0.5248594000103148  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4297 episode reward:  9.0  Episode finished after 429 timesteps\n",
      "    PARAMS.epsilon:  0.5246475400103194  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4298 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.5245327000103219  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4299 episode reward:  3.0  Episode finished after 230 timesteps\n",
      "    PARAMS.epsilon:  0.5244178600103244  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4300 episode reward:  9.0  Episode finished after 498 timesteps\n",
      "    PARAMS.epsilon:  0.5241723400103298  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4301 episode reward:  5.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.524023840010333  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4302 episode reward:  8.0  Episode finished after 414 timesteps\n",
      "    PARAMS.epsilon:  0.5238199000103374  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4303 episode reward:  2.0  Episode finished after 199 timesteps\n",
      "    PARAMS.epsilon:  0.5237209000103396  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4304 episode reward:  2.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.5236298200103415  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4305 episode reward:  2.0  Episode finished after 218 timesteps\n",
      "    PARAMS.epsilon:  0.5235209200103439  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4306 episode reward:  4.0  Episode finished after 274 timesteps\n",
      "    PARAMS.epsilon:  0.5233862800103468  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4307 episode reward:  5.0  Episode finished after 328 timesteps\n",
      "    PARAMS.epsilon:  0.5232239200103503  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4308 episode reward:  2.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.5231328400103523  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4309 episode reward:  6.0  Episode finished after 348 timesteps\n",
      "    PARAMS.epsilon:  0.5229605800103561  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4310 episode reward:  6.0  Episode finished after 357 timesteps\n",
      "    PARAMS.epsilon:  0.5227843600103599  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4311 episode reward:  6.0  Episode finished after 377 timesteps\n",
      "    PARAMS.epsilon:  0.522596260010364  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4312 episode reward:  10.0  Episode finished after 461 timesteps\n",
      "    PARAMS.epsilon:  0.5223685600103689  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4313 episode reward:  4.0  Episode finished after 264 timesteps\n",
      "    PARAMS.epsilon:  0.5222378800103717  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4314 episode reward:  1.0  Episode finished after 157 timesteps\n",
      "    PARAMS.epsilon:  0.5221606600103734  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4315 episode reward:  6.0  Episode finished after 311 timesteps\n",
      "    PARAMS.epsilon:  0.5220062200103768  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4316 episode reward:  9.0  Episode finished after 464 timesteps\n",
      "    PARAMS.epsilon:  0.5217765400103818  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4317 episode reward:  5.0  Episode finished after 313 timesteps\n",
      "    PARAMS.epsilon:  0.5216221000103851  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4318 episode reward:  7.0  Episode finished after 352 timesteps\n",
      "    PARAMS.epsilon:  0.5214478600103889  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4319 episode reward:  3.0  Episode finished after 254 timesteps\n",
      "    PARAMS.epsilon:  0.5213211400103916  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4320 episode reward:  10.0  Episode finished after 499 timesteps\n",
      "    PARAMS.epsilon:  0.521075620010397  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4321 episode reward:  11.0  Episode finished after 542 timesteps\n",
      "    PARAMS.epsilon:  0.5208063400104028  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4322 episode reward:  4.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.5206677400104058  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4323 episode reward:  5.0  Episode finished after 316 timesteps\n",
      "    PARAMS.epsilon:  0.5205113200104092  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4324 episode reward:  1.0  Episode finished after 155 timesteps\n",
      "    PARAMS.epsilon:  0.5204360800104109  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4325 episode reward:  4.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.5202955000104139  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4326 episode reward:  10.0  Episode finished after 556 timesteps\n",
      "    PARAMS.epsilon:  0.5200202800104199  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4327 episode reward:  3.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.5198975200104226  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4328 episode reward:  10.0  Episode finished after 485 timesteps\n",
      "    PARAMS.epsilon:  0.5196579400104278  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4329 episode reward:  6.0  Episode finished after 383 timesteps\n",
      "    PARAMS.epsilon:  0.5194678600104319  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4330 episode reward:  12.0  Episode finished after 499 timesteps\n",
      "    PARAMS.epsilon:  0.5192203600104373  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4331 episode reward:  13.0  Episode finished after 428 timesteps\n",
      "    PARAMS.epsilon:  0.5190085000104419  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4332 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.5189332600104435  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4333 episode reward:  9.0  Episode finished after 315 timesteps\n",
      "    PARAMS.epsilon:  0.5187768400104469  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4334 episode reward:  7.0  Episode finished after 424 timesteps\n",
      "    PARAMS.epsilon:  0.5185669600104514  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4335 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.518450140010454  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4336 episode reward:  2.0  Episode finished after 183 timesteps\n",
      "    PARAMS.epsilon:  0.518359060010456  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4337 episode reward:  9.0  Episode finished after 467 timesteps\n",
      "    PARAMS.epsilon:  0.5181293800104609  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4338 episode reward:  6.0  Episode finished after 360 timesteps\n",
      "    PARAMS.epsilon:  0.5179511800104648  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4339 episode reward:  6.0  Episode finished after 340 timesteps\n",
      "    PARAMS.epsilon:  0.5177828800104685  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4340 episode reward:  10.0  Episode finished after 452 timesteps\n",
      "    PARAMS.epsilon:  0.5175591400104733  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4341 episode reward:  7.0  Episode finished after 412 timesteps\n",
      "    PARAMS.epsilon:  0.5173552000104777  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4342 episode reward:  2.0  Episode finished after 181 timesteps\n",
      "    PARAMS.epsilon:  0.5172641200104797  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4343 episode reward:  7.0  Episode finished after 432 timesteps\n",
      "    PARAMS.epsilon:  0.5170502800104844  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4344 episode reward:  8.0  Episode finished after 439 timesteps\n",
      "    PARAMS.epsilon:  0.516834460010489  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4345 episode reward:  15.0  Episode finished after 625 timesteps\n",
      "    PARAMS.epsilon:  0.5165236000104958  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4346 episode reward:  9.0  Episode finished after 472 timesteps\n",
      "    PARAMS.epsilon:  0.5162899600105009  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4347 episode reward:  10.0  Episode finished after 528 timesteps\n",
      "    PARAMS.epsilon:  0.5160286000105065  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4348 episode reward:  7.0  Episode finished after 365 timesteps\n",
      "    PARAMS.epsilon:  0.5158484200105105  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4349 episode reward:  6.0  Episode finished after 347 timesteps\n",
      "    PARAMS.epsilon:  0.5156761600105142  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4350 episode reward:  8.0  Episode finished after 395 timesteps\n",
      "    PARAMS.epsilon:  0.5154821200105184  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4351 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.5153672800105209  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4352 episode reward:  4.0  Episode finished after 246 timesteps\n",
      "    PARAMS.epsilon:  0.5152445200105236  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4353 episode reward:  3.0  Episode finished after 213 timesteps\n",
      "    PARAMS.epsilon:  0.5151395800105258  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4354 episode reward:  5.0  Episode finished after 292 timesteps\n",
      "    PARAMS.epsilon:  0.514995040010529  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4355 episode reward:  13.0  Episode finished after 466 timesteps\n",
      "    PARAMS.epsilon:  0.514763380010534  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4356 episode reward:  4.0  Episode finished after 257 timesteps\n",
      "    PARAMS.epsilon:  0.5146366600105368  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4357 episode reward:  7.0  Episode finished after 404 timesteps\n",
      "    PARAMS.epsilon:  0.5144366800105411  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4358 episode reward:  5.0  Episode finished after 289 timesteps\n",
      "    PARAMS.epsilon:  0.5142941200105442  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4359 episode reward:  6.0  Episode finished after 421 timesteps\n",
      "    PARAMS.epsilon:  0.5140862200105487  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4360 episode reward:  5.0  Episode finished after 309 timesteps\n",
      "    PARAMS.epsilon:  0.5139317800105521  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4361 episode reward:  9.0  Episode finished after 513 timesteps\n",
      "    PARAMS.epsilon:  0.5136783400105576  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4362 episode reward:  5.0  Episode finished after 286 timesteps\n",
      "    PARAMS.epsilon:  0.5135377600105606  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4363 episode reward:  14.0  Episode finished after 648 timesteps\n",
      "    PARAMS.epsilon:  0.5132170000105676  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4364 episode reward:  8.0  Episode finished after 378 timesteps\n",
      "    PARAMS.epsilon:  0.5130289000105717  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4365 episode reward:  9.0  Episode finished after 460 timesteps\n",
      "    PARAMS.epsilon:  0.5128012000105766  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4366 episode reward:  10.0  Episode finished after 481 timesteps\n",
      "    PARAMS.epsilon:  0.5125636000105818  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4367 episode reward:  8.0  Episode finished after 409 timesteps\n",
      "    PARAMS.epsilon:  0.5123616400105862  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4368 episode reward:  10.0  Episode finished after 511 timesteps\n",
      "    PARAMS.epsilon:  0.5121082000105917  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4369 episode reward:  11.0  Episode finished after 572 timesteps\n",
      "    PARAMS.epsilon:  0.5118250600105978  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4370 episode reward:  7.0  Episode finished after 333 timesteps\n",
      "    PARAMS.epsilon:  0.5116607200106014  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4371 episode reward:  8.0  Episode finished after 458 timesteps\n",
      "    PARAMS.epsilon:  0.5114330200106063  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4372 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.5113340200106085  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4373 episode reward:  6.0  Episode finished after 330 timesteps\n",
      "    PARAMS.epsilon:  0.511171660010612  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4374 episode reward:  7.0  Episode finished after 345 timesteps\n",
      "    PARAMS.epsilon:  0.5109994000106157  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4375 episode reward:  4.0  Episode finished after 276 timesteps\n",
      "    PARAMS.epsilon:  0.5108627800106187  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4376 episode reward:  3.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.5107499200106211  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4377 episode reward:  16.0  Episode finished after 447 timesteps\n",
      "    PARAMS.epsilon:  0.510528160010626  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4378 episode reward:  7.0  Episode finished after 391 timesteps\n",
      "    PARAMS.epsilon:  0.5103341200106302  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4379 episode reward:  6.0  Episode finished after 341 timesteps\n",
      "    PARAMS.epsilon:  0.5101658200106338  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4380 episode reward:  3.0  Episode finished after 231 timesteps\n",
      "    PARAMS.epsilon:  0.5100509800106363  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4381 episode reward:  4.0  Episode finished after 287 timesteps\n",
      "    PARAMS.epsilon:  0.5099084200106394  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4382 episode reward:  10.0  Episode finished after 492 timesteps\n",
      "    PARAMS.epsilon:  0.5096648800106447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4383 episode reward:  3.0  Episode finished after 265 timesteps\n",
      "    PARAMS.epsilon:  0.5095342000106475  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4384 episode reward:  9.0  Episode finished after 444 timesteps\n",
      "    PARAMS.epsilon:  0.5093144200106523  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4385 episode reward:  8.0  Episode finished after 390 timesteps\n",
      "    PARAMS.epsilon:  0.5091223600106565  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4386 episode reward:  9.0  Episode finished after 443 timesteps\n",
      "    PARAMS.epsilon:  0.5089025800106612  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4387 episode reward:  8.0  Episode finished after 388 timesteps\n",
      "    PARAMS.epsilon:  0.5087105200106654  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4388 episode reward:  5.0  Episode finished after 306 timesteps\n",
      "    PARAMS.epsilon:  0.5085580600106687  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4389 episode reward:  8.0  Episode finished after 407 timesteps\n",
      "    PARAMS.epsilon:  0.5083580800106731  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4390 episode reward:  9.0  Episode finished after 438 timesteps\n",
      "    PARAMS.epsilon:  0.5081402800106778  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4391 episode reward:  10.0  Episode finished after 462 timesteps\n",
      "    PARAMS.epsilon:  0.5079125800106827  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4392 episode reward:  12.0  Episode finished after 456 timesteps\n",
      "    PARAMS.epsilon:  0.5076868600106876  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4393 episode reward:  5.0  Episode finished after 325 timesteps\n",
      "    PARAMS.epsilon:  0.5075245000106912  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4394 episode reward:  9.0  Episode finished after 465 timesteps\n",
      "    PARAMS.epsilon:  0.5072948200106961  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4395 episode reward:  9.0  Episode finished after 464 timesteps\n",
      "    PARAMS.epsilon:  0.5070651400107011  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4396 episode reward:  9.0  Episode finished after 488 timesteps\n",
      "    PARAMS.epsilon:  0.5068235800107064  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4397 episode reward:  6.0  Episode finished after 336 timesteps\n",
      "    PARAMS.epsilon:  0.50665726001071  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4398 episode reward:  4.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.5065305400107127  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4399 episode reward:  10.0  Episode finished after 463 timesteps\n",
      "    PARAMS.epsilon:  0.5063008600107177  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4400 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.5062018600107199  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4401 episode reward:  12.0  Episode finished after 497 timesteps\n",
      "    PARAMS.epsilon:  0.5059563400107252  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4402 episode reward:  3.0  Episode finished after 212 timesteps\n",
      "    PARAMS.epsilon:  0.5058514000107275  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4403 episode reward:  5.0  Episode finished after 324 timesteps\n",
      "    PARAMS.epsilon:  0.505691020010731  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4404 episode reward:  5.0  Episode finished after 313 timesteps\n",
      "    PARAMS.epsilon:  0.5055365800107343  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4405 episode reward:  8.0  Episode finished after 467 timesteps\n",
      "    PARAMS.epsilon:  0.5053049200107393  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4406 episode reward:  5.0  Episode finished after 323 timesteps\n",
      "    PARAMS.epsilon:  0.5051445400107428  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4407 episode reward:  8.0  Episode finished after 414 timesteps\n",
      "    PARAMS.epsilon:  0.5049406000107473  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4408 episode reward:  7.0  Episode finished after 388 timesteps\n",
      "    PARAMS.epsilon:  0.5047485400107514  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4409 episode reward:  12.0  Episode finished after 419 timesteps\n",
      "    PARAMS.epsilon:  0.5045406400107559  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4410 episode reward:  4.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.504402040010759  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4411 episode reward:  13.0  Episode finished after 626 timesteps\n",
      "    PARAMS.epsilon:  0.5040911800107657  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4412 episode reward:  5.0  Episode finished after 345 timesteps\n",
      "    PARAMS.epsilon:  0.5039209000107694  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4413 episode reward:  6.0  Episode finished after 344 timesteps\n",
      "    PARAMS.epsilon:  0.5037506200107731  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4414 episode reward:  10.0  Episode finished after 454 timesteps\n",
      "    PARAMS.epsilon:  0.5035268800107779  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4415 episode reward:  8.0  Episode finished after 425 timesteps\n",
      "    PARAMS.epsilon:  0.5033150200107825  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4416 episode reward:  4.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.5031962200107851  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4417 episode reward:  7.0  Episode finished after 354 timesteps\n",
      "    PARAMS.epsilon:  0.503020000010789  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4418 episode reward:  6.0  Episode finished after 362 timesteps\n",
      "    PARAMS.epsilon:  0.5028418000107928  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4419 episode reward:  7.0  Episode finished after 403 timesteps\n",
      "    PARAMS.epsilon:  0.5026418200107972  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4420 episode reward:  7.0  Episode finished after 406 timesteps\n",
      "    PARAMS.epsilon:  0.5024398600108015  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4421 episode reward:  9.0  Episode finished after 504 timesteps\n",
      "    PARAMS.epsilon:  0.502190380010807  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4422 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.5021131600108086  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4423 episode reward:  5.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.5019745600108116  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4424 episode reward:  8.0  Episode finished after 414 timesteps\n",
      "    PARAMS.epsilon:  0.5017686400108161  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4425 episode reward:  14.0  Episode finished after 521 timesteps\n",
      "    PARAMS.epsilon:  0.5015112400108217  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4426 episode reward:  4.0  Episode finished after 302 timesteps\n",
      "    PARAMS.epsilon:  0.501360760010825  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4427 episode reward:  7.0  Episode finished after 375 timesteps\n",
      "    PARAMS.epsilon:  0.501176620010829  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4428 episode reward:  4.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.5010499000108317  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4429 episode reward:  1.0  Episode finished after 156 timesteps\n",
      "    PARAMS.epsilon:  0.5009726800108334  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4430 episode reward:  2.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.500853880010836  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4431 episode reward:  5.0  Episode finished after 348 timesteps\n",
      "    PARAMS.epsilon:  0.5006816200108397  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4432 episode reward:  7.0  Episode finished after 390 timesteps\n",
      "    PARAMS.epsilon:  0.5004875800108439  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4433 episode reward:  17.0  Episode finished after 652 timesteps\n",
      "    PARAMS.epsilon:  0.5001648400108509  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4434 episode reward:  4.0  Episode finished after 262 timesteps\n",
      "    PARAMS.epsilon:  0.5000361400108537  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4435 episode reward:  4.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.49989754001085385  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4436 episode reward:  4.0  Episode finished after 302 timesteps\n",
      "    PARAMS.epsilon:  0.4997470600108529  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4437 episode reward:  9.0  Episode finished after 490 timesteps\n",
      "    PARAMS.epsilon:  0.49950550001085137  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4438 episode reward:  14.0  Episode finished after 514 timesteps\n",
      "    PARAMS.epsilon:  0.49925008001084975  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4439 episode reward:  14.0  Episode finished after 517 timesteps\n",
      "    PARAMS.epsilon:  0.49899466001084813  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4440 episode reward:  6.0  Episode finished after 342 timesteps\n",
      "    PARAMS.epsilon:  0.49882438001084706  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4441 episode reward:  4.0  Episode finished after 265 timesteps\n",
      "    PARAMS.epsilon:  0.49869370001084623  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4442 episode reward:  9.0  Episode finished after 430 timesteps\n",
      "    PARAMS.epsilon:  0.4984818400108449  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4443 episode reward:  4.0  Episode finished after 300 timesteps\n",
      "    PARAMS.epsilon:  0.49833334001084395  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4444 episode reward:  9.0  Episode finished after 469 timesteps\n",
      "    PARAMS.epsilon:  0.49809970001084247  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4445 episode reward:  3.0  Episode finished after 230 timesteps\n",
      "    PARAMS.epsilon:  0.49798684001084176  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4446 episode reward:  11.0  Episode finished after 547 timesteps\n",
      "    PARAMS.epsilon:  0.49771558001084004  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4447 episode reward:  6.0  Episode finished after 357 timesteps\n",
      "    PARAMS.epsilon:  0.4975393600108389  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4448 episode reward:  5.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.497390860010838  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4449 episode reward:  5.0  Episode finished after 342 timesteps\n",
      "    PARAMS.epsilon:  0.4972225600108369  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4450 episode reward:  7.0  Episode finished after 389 timesteps\n",
      "    PARAMS.epsilon:  0.4970285200108357  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4451 episode reward:  12.0  Episode finished after 518 timesteps\n",
      "    PARAMS.epsilon:  0.4967731000108341  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4452 episode reward:  6.0  Episode finished after 312 timesteps\n",
      "    PARAMS.epsilon:  0.4966186600108331  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4453 episode reward:  1.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.4965434200108326  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4454 episode reward:  6.0  Episode finished after 370 timesteps\n",
      "    PARAMS.epsilon:  0.49635928001083146  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4455 episode reward:  10.0  Episode finished after 483 timesteps\n",
      "    PARAMS.epsilon:  0.49612168001082996  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4456 episode reward:  1.0  Episode finished after 158 timesteps\n",
      "    PARAMS.epsilon:  0.49604248001082946  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4457 episode reward:  11.0  Episode finished after 548 timesteps\n",
      "    PARAMS.epsilon:  0.49577122001082774  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4458 episode reward:  6.0  Episode finished after 392 timesteps\n",
      "    PARAMS.epsilon:  0.4955771800108265  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4459 episode reward:  3.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.49545442001082574  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4460 episode reward:  7.0  Episode finished after 401 timesteps\n",
      "    PARAMS.epsilon:  0.4952564200108245  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4461 episode reward:  5.0  Episode finished after 334 timesteps\n",
      "    PARAMS.epsilon:  0.49509010001082343  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4462 episode reward:  0.0  Episode finished after 123 timesteps\n",
      "    PARAMS.epsilon:  0.49502872001082304  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4463 episode reward:  6.0  Episode finished after 341 timesteps\n",
      "    PARAMS.epsilon:  0.494860420010822  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4464 episode reward:  8.0  Episode finished after 424 timesteps\n",
      "    PARAMS.epsilon:  0.49465054001082065  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4465 episode reward:  4.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.49450996001081976  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4466 episode reward:  4.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.4943713600108189  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4467 episode reward:  3.0  Episode finished after 238 timesteps\n",
      "    PARAMS.epsilon:  0.49425454001081814  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4468 episode reward:  6.0  Episode finished after 367 timesteps\n",
      "    PARAMS.epsilon:  0.494072380010817  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4469 episode reward:  5.0  Episode finished after 317 timesteps\n",
      "    PARAMS.epsilon:  0.493915960010816  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4470 episode reward:  6.0  Episode finished after 384 timesteps\n",
      "    PARAMS.epsilon:  0.4937258800108148  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4471 episode reward:  7.0  Episode finished after 374 timesteps\n",
      "    PARAMS.epsilon:  0.4935397600108136  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4472 episode reward:  5.0  Episode finished after 306 timesteps\n",
      "    PARAMS.epsilon:  0.49338928001081267  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4473 episode reward:  14.0  Episode finished after 621 timesteps\n",
      "    PARAMS.epsilon:  0.49308238001081073  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4474 episode reward:  14.0  Episode finished after 485 timesteps\n",
      "    PARAMS.epsilon:  0.4928408200108092  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4475 episode reward:  5.0  Episode finished after 317 timesteps\n",
      "    PARAMS.epsilon:  0.4926844000108082  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4476 episode reward:  11.0  Episode finished after 507 timesteps\n",
      "    PARAMS.epsilon:  0.4924329400108066  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4477 episode reward:  11.0  Episode finished after 536 timesteps\n",
      "    PARAMS.epsilon:  0.49216762001080494  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4478 episode reward:  12.0  Episode finished after 508 timesteps\n",
      "    PARAMS.epsilon:  0.49191616001080335  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4479 episode reward:  4.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.4917775600108025  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4480 episode reward:  8.0  Episode finished after 455 timesteps\n",
      "    PARAMS.epsilon:  0.49155184001080104  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4481 episode reward:  6.0  Episode finished after 329 timesteps\n",
      "    PARAMS.epsilon:  0.4913894800108  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4482 episode reward:  10.0  Episode finished after 503 timesteps\n",
      "    PARAMS.epsilon:  0.49114000001079844  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4483 episode reward:  9.0  Episode finished after 481 timesteps\n",
      "    PARAMS.epsilon:  0.49090240001079694  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4484 episode reward:  9.0  Episode finished after 449 timesteps\n",
      "    PARAMS.epsilon:  0.49068064001079553  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4485 episode reward:  2.0  Episode finished after 217 timesteps\n",
      "    PARAMS.epsilon:  0.49057372001079486  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4486 episode reward:  9.0  Episode finished after 337 timesteps\n",
      "    PARAMS.epsilon:  0.4904054200107938  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4487 episode reward:  6.0  Episode finished after 315 timesteps\n",
      "    PARAMS.epsilon:  0.4902509800107928  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4488 episode reward:  7.0  Episode finished after 386 timesteps\n",
      "    PARAMS.epsilon:  0.4900589200107916  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4489 episode reward:  9.0  Episode finished after 478 timesteps\n",
      "    PARAMS.epsilon:  0.4898233000107901  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4490 episode reward:  3.0  Episode finished after 249 timesteps\n",
      "    PARAMS.epsilon:  0.4896985600107893  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4491 episode reward:  6.0  Episode finished after 323 timesteps\n",
      "    PARAMS.epsilon:  0.4895401600107883  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4492 episode reward:  3.0  Episode finished after 242 timesteps\n",
      "    PARAMS.epsilon:  0.48941938001078755  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4493 episode reward:  8.0  Episode finished after 449 timesteps\n",
      "    PARAMS.epsilon:  0.48919762001078615  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4494 episode reward:  5.0  Episode finished after 297 timesteps\n",
      "    PARAMS.epsilon:  0.4890511000107852  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4495 episode reward:  2.0  Episode finished after 200 timesteps\n",
      "    PARAMS.epsilon:  0.4889521000107846  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4496 episode reward:  9.0  Episode finished after 419 timesteps\n",
      "    PARAMS.epsilon:  0.4887442000107833  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4497 episode reward:  7.0  Episode finished after 392 timesteps\n",
      "    PARAMS.epsilon:  0.48855016001078205  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4498 episode reward:  10.0  Episode finished after 449 timesteps\n",
      "    PARAMS.epsilon:  0.48832840001078065  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4499 episode reward:  3.0  Episode finished after 256 timesteps\n",
      "    PARAMS.epsilon:  0.48820168001077985  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4500 episode reward:  5.0  Episode finished after 300 timesteps\n",
      "    PARAMS.epsilon:  0.4880531800107789  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4501 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.48796210001077833  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4502 episode reward:  10.0  Episode finished after 467 timesteps\n",
      "    PARAMS.epsilon:  0.48773044001077687  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4503 episode reward:  5.0  Episode finished after 359 timesteps\n",
      "    PARAMS.epsilon:  0.48755224001077574  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4504 episode reward:  7.0  Episode finished after 462 timesteps\n",
      "    PARAMS.epsilon:  0.4873245400107743  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4505 episode reward:  9.0  Episode finished after 471 timesteps\n",
      "    PARAMS.epsilon:  0.4870909000107728  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4506 episode reward:  2.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.48699982001077224  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4507 episode reward:  7.0  Episode finished after 357 timesteps\n",
      "    PARAMS.epsilon:  0.4868216200107711  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4508 episode reward:  4.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.48669886001077034  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4509 episode reward:  5.0  Episode finished after 300 timesteps\n",
      "    PARAMS.epsilon:  0.4865503600107694  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4510 episode reward:  4.0  Episode finished after 243 timesteps\n",
      "    PARAMS.epsilon:  0.48643156001076865  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4511 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.486328600010768  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4512 episode reward:  13.0  Episode finished after 495 timesteps\n",
      "    PARAMS.epsilon:  0.48608308001076644  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4513 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.4859682400107657  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4514 episode reward:  3.0  Episode finished after 234 timesteps\n",
      "    PARAMS.epsilon:  0.485851420010765  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4515 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.48575242001076435  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4516 episode reward:  5.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.4856138200107635  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4517 episode reward:  11.0  Episode finished after 511 timesteps\n",
      "    PARAMS.epsilon:  0.48536038001076187  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4518 episode reward:  5.0  Episode finished after 375 timesteps\n",
      "    PARAMS.epsilon:  0.4851742600107607  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4519 episode reward:  5.0  Episode finished after 333 timesteps\n",
      "    PARAMS.epsilon:  0.48500992001075965  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4520 episode reward:  9.0  Episode finished after 523 timesteps\n",
      "    PARAMS.epsilon:  0.484750540010758  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4521 episode reward:  1.0  Episode finished after 164 timesteps\n",
      "    PARAMS.epsilon:  0.4846693600107575  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4522 episode reward:  8.0  Episode finished after 446 timesteps\n",
      "    PARAMS.epsilon:  0.4844495800107561  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4523 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.48436444001075557  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4524 episode reward:  3.0  Episode finished after 235 timesteps\n",
      "    PARAMS.epsilon:  0.48424762001075483  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4525 episode reward:  10.0  Episode finished after 512 timesteps\n",
      "    PARAMS.epsilon:  0.4839941800107532  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4526 episode reward:  16.0  Episode finished after 421 timesteps\n",
      "    PARAMS.epsilon:  0.4837862800107519  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4527 episode reward:  14.0  Episode finished after 559 timesteps\n",
      "    PARAMS.epsilon:  0.48350908001075016  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4528 episode reward:  7.0  Episode finished after 383 timesteps\n",
      "    PARAMS.epsilon:  0.48332098001074897  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4529 episode reward:  10.0  Episode finished after 365 timesteps\n",
      "    PARAMS.epsilon:  0.4831388200107478  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4530 episode reward:  2.0  Episode finished after 189 timesteps\n",
      "    PARAMS.epsilon:  0.4830457600107472  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4531 episode reward:  8.0  Episode finished after 448 timesteps\n",
      "    PARAMS.epsilon:  0.4828240000107458  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4532 episode reward:  6.0  Episode finished after 362 timesteps\n",
      "    PARAMS.epsilon:  0.4826458000107447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4533 episode reward:  3.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.482532940010744  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4534 episode reward:  6.0  Episode finished after 439 timesteps\n",
      "    PARAMS.epsilon:  0.4823151400107426  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4535 episode reward:  6.0  Episode finished after 381 timesteps\n",
      "    PARAMS.epsilon:  0.4821270400107414  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4536 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.4820260600107408  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4537 episode reward:  4.0  Episode finished after 286 timesteps\n",
      "    PARAMS.epsilon:  0.4818835000107399  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4538 episode reward:  6.0  Episode finished after 366 timesteps\n",
      "    PARAMS.epsilon:  0.48170332001073873  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4539 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.48162610001073825  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4540 episode reward:  10.0  Episode finished after 500 timesteps\n",
      "    PARAMS.epsilon:  0.4813786000107367  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4541 episode reward:  4.0  Episode finished after 244 timesteps\n",
      "    PARAMS.epsilon:  0.4812578200107359  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4542 episode reward:  5.0  Episode finished after 310 timesteps\n",
      "    PARAMS.epsilon:  0.48110536001073495  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4543 episode reward:  6.0  Episode finished after 342 timesteps\n",
      "    PARAMS.epsilon:  0.4809350800107339  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4544 episode reward:  3.0  Episode finished after 233 timesteps\n",
      "    PARAMS.epsilon:  0.48082024001073315  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4545 episode reward:  4.0  Episode finished after 319 timesteps\n",
      "    PARAMS.epsilon:  0.48066184001073214  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4546 episode reward:  8.0  Episode finished after 397 timesteps\n",
      "    PARAMS.epsilon:  0.4804658200107309  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4547 episode reward:  4.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.48032722001073  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4548 episode reward:  3.0  Episode finished after 244 timesteps\n",
      "    PARAMS.epsilon:  0.48020644001072926  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4549 episode reward:  11.0  Episode finished after 512 timesteps\n",
      "    PARAMS.epsilon:  0.47995300001072766  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4550 episode reward:  8.0  Episode finished after 429 timesteps\n",
      "    PARAMS.epsilon:  0.4797411400107263  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4551 episode reward:  5.0  Episode finished after 293 timesteps\n",
      "    PARAMS.epsilon:  0.4795966000107254  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4552 episode reward:  1.0  Episode finished after 171 timesteps\n",
      "    PARAMS.epsilon:  0.47951146001072487  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4553 episode reward:  6.0  Episode finished after 357 timesteps\n",
      "    PARAMS.epsilon:  0.47933524001072375  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4554 episode reward:  5.0  Episode finished after 278 timesteps\n",
      "    PARAMS.epsilon:  0.4791966400107229  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4555 episode reward:  5.0  Episode finished after 323 timesteps\n",
      "    PARAMS.epsilon:  0.47903824001072187  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4556 episode reward:  7.0  Episode finished after 376 timesteps\n",
      "    PARAMS.epsilon:  0.4788521200107207  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4557 episode reward:  9.0  Episode finished after 472 timesteps\n",
      "    PARAMS.epsilon:  0.4786184800107192  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4558 episode reward:  7.0  Episode finished after 385 timesteps\n",
      "    PARAMS.epsilon:  0.478426420010718  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4559 episode reward:  6.0  Episode finished after 318 timesteps\n",
      "    PARAMS.epsilon:  0.478270000010717  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4560 episode reward:  8.0  Episode finished after 384 timesteps\n",
      "    PARAMS.epsilon:  0.4780799200107158  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4561 episode reward:  0.0  Episode finished after 126 timesteps\n",
      "    PARAMS.epsilon:  0.4780165600107154  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4562 episode reward:  6.0  Episode finished after 337 timesteps\n",
      "    PARAMS.epsilon:  0.47785024001071436  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4563 episode reward:  3.0  Episode finished after 254 timesteps\n",
      "    PARAMS.epsilon:  0.47772550001071357  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4564 episode reward:  7.0  Episode finished after 338 timesteps\n",
      "    PARAMS.epsilon:  0.4775572000107125  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4565 episode reward:  10.0  Episode finished after 377 timesteps\n",
      "    PARAMS.epsilon:  0.4773710800107113  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4566 episode reward:  2.0  Episode finished after 203 timesteps\n",
      "    PARAMS.epsilon:  0.4772701000107107  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4567 episode reward:  5.0  Episode finished after 320 timesteps\n",
      "    PARAMS.epsilon:  0.4771117000107097  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4568 episode reward:  5.0  Episode finished after 348 timesteps\n",
      "    PARAMS.epsilon:  0.4769394400107086  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4569 episode reward:  2.0  Episode finished after 201 timesteps\n",
      "    PARAMS.epsilon:  0.47684044001070797  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4570 episode reward:  9.0  Episode finished after 465 timesteps\n",
      "    PARAMS.epsilon:  0.4766107600107065  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4571 episode reward:  10.0  Episode finished after 510 timesteps\n",
      "    PARAMS.epsilon:  0.4763573200107049  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4572 episode reward:  0.0  Episode finished after 128 timesteps\n",
      "    PARAMS.epsilon:  0.4762939600107045  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4573 episode reward:  5.0  Episode finished after 306 timesteps\n",
      "    PARAMS.epsilon:  0.47614348001070356  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4574 episode reward:  3.0  Episode finished after 265 timesteps\n",
      "    PARAMS.epsilon:  0.4760108200107027  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4575 episode reward:  11.0  Episode finished after 566 timesteps\n",
      "    PARAMS.epsilon:  0.47573164001070095  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4576 episode reward:  7.0  Episode finished after 397 timesteps\n",
      "    PARAMS.epsilon:  0.4755356200106997  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4577 episode reward:  6.0  Episode finished after 355 timesteps\n",
      "    PARAMS.epsilon:  0.4753594000106986  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4578 episode reward:  3.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.47525446001069793  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4579 episode reward:  11.0  Episode finished after 396 timesteps\n",
      "    PARAMS.epsilon:  0.4750584400106967  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4580 episode reward:  6.0  Episode finished after 311 timesteps\n",
      "    PARAMS.epsilon:  0.4749040000106957  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4581 episode reward:  5.0  Episode finished after 308 timesteps\n",
      "    PARAMS.epsilon:  0.47475154001069475  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4582 episode reward:  4.0  Episode finished after 269 timesteps\n",
      "    PARAMS.epsilon:  0.4746188800106939  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4583 episode reward:  5.0  Episode finished after 296 timesteps\n",
      "    PARAMS.epsilon:  0.474472360010693  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4584 episode reward:  3.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.4743496000106922  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4585 episode reward:  6.0  Episode finished after 349 timesteps\n",
      "    PARAMS.epsilon:  0.4741773400106911  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4586 episode reward:  2.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.47408428001069053  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4587 episode reward:  4.0  Episode finished after 260 timesteps\n",
      "    PARAMS.epsilon:  0.4739555800106897  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4588 episode reward:  11.0  Episode finished after 418 timesteps\n",
      "    PARAMS.epsilon:  0.4737496600106884  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4589 episode reward:  6.0  Episode finished after 321 timesteps\n",
      "    PARAMS.epsilon:  0.4735892800106874  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4590 episode reward:  7.0  Episode finished after 389 timesteps\n",
      "    PARAMS.epsilon:  0.4733972200106862  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4591 episode reward:  1.0  Episode finished after 167 timesteps\n",
      "    PARAMS.epsilon:  0.47331406001068566  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4592 episode reward:  6.0  Episode finished after 314 timesteps\n",
      "    PARAMS.epsilon:  0.4731596200106847  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4593 episode reward:  6.0  Episode finished after 344 timesteps\n",
      "    PARAMS.epsilon:  0.4729893400106836  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4594 episode reward:  6.0  Episode finished after 344 timesteps\n",
      "    PARAMS.epsilon:  0.4728190600106825  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4595 episode reward:  6.0  Episode finished after 366 timesteps\n",
      "    PARAMS.epsilon:  0.47263690001068137  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4596 episode reward:  6.0  Episode finished after 366 timesteps\n",
      "    PARAMS.epsilon:  0.47245672001068023  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4597 episode reward:  6.0  Episode finished after 353 timesteps\n",
      "    PARAMS.epsilon:  0.47228248001067913  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4598 episode reward:  13.0  Episode finished after 434 timesteps\n",
      "    PARAMS.epsilon:  0.47206666001067776  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4599 episode reward:  2.0  Episode finished after 208 timesteps\n",
      "    PARAMS.epsilon:  0.4719637000106771  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4600 episode reward:  4.0  Episode finished after 264 timesteps\n",
      "    PARAMS.epsilon:  0.4718330200106763  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4601 episode reward:  5.0  Episode finished after 294 timesteps\n",
      "    PARAMS.epsilon:  0.47168848001067537  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4602 episode reward:  16.0  Episode finished after 668 timesteps\n",
      "    PARAMS.epsilon:  0.4713578200106733  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4603 episode reward:  3.0  Episode finished after 211 timesteps\n",
      "    PARAMS.epsilon:  0.4712528800106726  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4604 episode reward:  4.0  Episode finished after 290 timesteps\n",
      "    PARAMS.epsilon:  0.4711083400106717  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4605 episode reward:  5.0  Episode finished after 310 timesteps\n",
      "    PARAMS.epsilon:  0.47095588001067074  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4606 episode reward:  17.0  Episode finished after 647 timesteps\n",
      "    PARAMS.epsilon:  0.4706351200106687  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4607 episode reward:  9.0  Episode finished after 427 timesteps\n",
      "    PARAMS.epsilon:  0.47042326001066737  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4608 episode reward:  5.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.47027674001066644  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4609 episode reward:  8.0  Episode finished after 422 timesteps\n",
      "    PARAMS.epsilon:  0.4700668600106651  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4610 episode reward:  8.0  Episode finished after 410 timesteps\n",
      "    PARAMS.epsilon:  0.46986490001066383  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4611 episode reward:  6.0  Episode finished after 386 timesteps\n",
      "    PARAMS.epsilon:  0.4696728400106626  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4612 episode reward:  13.0  Episode finished after 605 timesteps\n",
      "    PARAMS.epsilon:  0.4693738600106607  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4613 episode reward:  9.0  Episode finished after 436 timesteps\n",
      "    PARAMS.epsilon:  0.46915804001065936  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4614 episode reward:  10.0  Episode finished after 471 timesteps\n",
      "    PARAMS.epsilon:  0.4689244000106579  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4615 episode reward:  0.0  Episode finished after 127 timesteps\n",
      "    PARAMS.epsilon:  0.4688610400106575  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4616 episode reward:  4.0  Episode finished after 278 timesteps\n",
      "    PARAMS.epsilon:  0.4687244200106566  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4617 episode reward:  4.0  Episode finished after 303 timesteps\n",
      "    PARAMS.epsilon:  0.46857394001065567  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4618 episode reward:  8.0  Episode finished after 418 timesteps\n",
      "    PARAMS.epsilon:  0.46836802001065436  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4619 episode reward:  11.0  Episode finished after 384 timesteps\n",
      "    PARAMS.epsilon:  0.46817794001065316  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4620 episode reward:  8.0  Episode finished after 441 timesteps\n",
      "    PARAMS.epsilon:  0.46795816001065177  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4621 episode reward:  7.0  Episode finished after 377 timesteps\n",
      "    PARAMS.epsilon:  0.4677720400106506  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4622 episode reward:  19.0  Episode finished after 591 timesteps\n",
      "    PARAMS.epsilon:  0.46747900001064874  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4623 episode reward:  7.0  Episode finished after 373 timesteps\n",
      "    PARAMS.epsilon:  0.4672948600106476  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4624 episode reward:  5.0  Episode finished after 344 timesteps\n",
      "    PARAMS.epsilon:  0.4671245800106465  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4625 episode reward:  9.0  Episode finished after 411 timesteps\n",
      "    PARAMS.epsilon:  0.4669206400106452  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4626 episode reward:  8.0  Episode finished after 437 timesteps\n",
      "    PARAMS.epsilon:  0.46670482001064384  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4627 episode reward:  7.0  Episode finished after 357 timesteps\n",
      "    PARAMS.epsilon:  0.4665286000106427  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4628 episode reward:  6.0  Episode finished after 320 timesteps\n",
      "    PARAMS.epsilon:  0.4663702000106417  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4629 episode reward:  8.0  Episode finished after 419 timesteps\n",
      "    PARAMS.epsilon:  0.4661623000106404  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4630 episode reward:  11.0  Episode finished after 549 timesteps\n",
      "    PARAMS.epsilon:  0.4658910400106387  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4631 episode reward:  4.0  Episode finished after 277 timesteps\n",
      "    PARAMS.epsilon:  0.4657544200106378  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4632 episode reward:  2.0  Episode finished after 197 timesteps\n",
      "    PARAMS.epsilon:  0.4656554200106372  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4633 episode reward:  6.0  Episode finished after 362 timesteps\n",
      "    PARAMS.epsilon:  0.4654772200106361  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4634 episode reward:  8.0  Episode finished after 370 timesteps\n",
      "    PARAMS.epsilon:  0.4652930800106349  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4635 episode reward:  16.0  Episode finished after 456 timesteps\n",
      "    PARAMS.epsilon:  0.4650673600106335  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4636 episode reward:  12.0  Episode finished after 612 timesteps\n",
      "    PARAMS.epsilon:  0.46476442001063156  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4637 episode reward:  5.0  Episode finished after 323 timesteps\n",
      "    PARAMS.epsilon:  0.46460602001063056  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4638 episode reward:  5.0  Episode finished after 309 timesteps\n",
      "    PARAMS.epsilon:  0.4644515800106296  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4639 episode reward:  11.0  Episode finished after 542 timesteps\n",
      "    PARAMS.epsilon:  0.4641842800106279  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4640 episode reward:  4.0  Episode finished after 244 timesteps\n",
      "    PARAMS.epsilon:  0.46406350001062713  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4641 episode reward:  7.0  Episode finished after 404 timesteps\n",
      "    PARAMS.epsilon:  0.46386352001062586  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4642 episode reward:  7.0  Episode finished after 382 timesteps\n",
      "    PARAMS.epsilon:  0.46367344001062466  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4643 episode reward:  7.0  Episode finished after 354 timesteps\n",
      "    PARAMS.epsilon:  0.46349920001062356  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4644 episode reward:  5.0  Episode finished after 305 timesteps\n",
      "    PARAMS.epsilon:  0.4633487200106226  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4645 episode reward:  8.0  Episode finished after 414 timesteps\n",
      "    PARAMS.epsilon:  0.4631428000106213  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4646 episode reward:  5.0  Episode finished after 278 timesteps\n",
      "    PARAMS.epsilon:  0.46300618001062044  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4647 episode reward:  3.0  Episode finished after 225 timesteps\n",
      "    PARAMS.epsilon:  0.4628933200106197  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4648 episode reward:  10.0  Episode finished after 481 timesteps\n",
      "    PARAMS.epsilon:  0.4626557200106182  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4649 episode reward:  8.0  Episode finished after 455 timesteps\n",
      "    PARAMS.epsilon:  0.4624300000106168  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4650 episode reward:  7.0  Episode finished after 399 timesteps\n",
      "    PARAMS.epsilon:  0.46223398001061555  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4651 episode reward:  3.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.46212112001061484  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4652 episode reward:  8.0  Episode finished after 406 timesteps\n",
      "    PARAMS.epsilon:  0.46191916001061356  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4653 episode reward:  14.0  Episode finished after 701 timesteps\n",
      "    PARAMS.epsilon:  0.46157266001061137  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4654 episode reward:  6.0  Episode finished after 326 timesteps\n",
      "    PARAMS.epsilon:  0.46141030001061034  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4655 episode reward:  7.0  Episode finished after 402 timesteps\n",
      "    PARAMS.epsilon:  0.4612123000106091  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4656 episode reward:  6.0  Episode finished after 325 timesteps\n",
      "    PARAMS.epsilon:  0.4610519200106081  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4657 episode reward:  14.0  Episode finished after 561 timesteps\n",
      "    PARAMS.epsilon:  0.4607727400106063  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4658 episode reward:  9.0  Episode finished after 446 timesteps\n",
      "    PARAMS.epsilon:  0.4605529600106049  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4659 episode reward:  4.0  Episode finished after 288 timesteps\n",
      "    PARAMS.epsilon:  0.460410400010604  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4660 episode reward:  9.0  Episode finished after 439 timesteps\n",
      "    PARAMS.epsilon:  0.46019260001060264  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4661 episode reward:  7.0  Episode finished after 405 timesteps\n",
      "    PARAMS.epsilon:  0.45999262001060137  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4662 episode reward:  4.0  Episode finished after 306 timesteps\n",
      "    PARAMS.epsilon:  0.4598401600106004  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4663 episode reward:  4.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.45970156001059953  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4664 episode reward:  14.0  Episode finished after 513 timesteps\n",
      "    PARAMS.epsilon:  0.4594481200105979  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4665 episode reward:  9.0  Episode finished after 355 timesteps\n",
      "    PARAMS.epsilon:  0.4592719000105968  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4666 episode reward:  8.0  Episode finished after 438 timesteps\n",
      "    PARAMS.epsilon:  0.45905608001059545  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4667 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.45896500001059487  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4668 episode reward:  3.0  Episode finished after 235 timesteps\n",
      "    PARAMS.epsilon:  0.45884818001059413  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4669 episode reward:  12.0  Episode finished after 597 timesteps\n",
      "    PARAMS.epsilon:  0.45855316001059226  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4670 episode reward:  15.0  Episode finished after 553 timesteps\n",
      "    PARAMS.epsilon:  0.45827992001059054  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4671 episode reward:  10.0  Episode finished after 465 timesteps\n",
      "    PARAMS.epsilon:  0.45804826001058907  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4672 episode reward:  4.0  Episode finished after 273 timesteps\n",
      "    PARAMS.epsilon:  0.4579136200105882  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4673 episode reward:  8.0  Episode finished after 439 timesteps\n",
      "    PARAMS.epsilon:  0.45769582001058684  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4674 episode reward:  2.0  Episode finished after 195 timesteps\n",
      "    PARAMS.epsilon:  0.45760078001058624  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4675 episode reward:  16.0  Episode finished after 657 timesteps\n",
      "    PARAMS.epsilon:  0.45727408001058417  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4676 episode reward:  8.0  Episode finished after 390 timesteps\n",
      "    PARAMS.epsilon:  0.45708202001058296  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4677 episode reward:  4.0  Episode finished after 284 timesteps\n",
      "    PARAMS.epsilon:  0.45694144001058207  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4678 episode reward:  5.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.4568028400105812  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4679 episode reward:  4.0  Episode finished after 253 timesteps\n",
      "    PARAMS.epsilon:  0.4566781000105804  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4680 episode reward:  7.0  Episode finished after 373 timesteps\n",
      "    PARAMS.epsilon:  0.4564919800105792  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4681 episode reward:  4.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.4563454600105783  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4682 episode reward:  8.0  Episode finished after 439 timesteps\n",
      "    PARAMS.epsilon:  0.4561276600105769  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4683 episode reward:  11.0  Episode finished after 518 timesteps\n",
      "    PARAMS.epsilon:  0.4558702600105753  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4684 episode reward:  6.0  Episode finished after 313 timesteps\n",
      "    PARAMS.epsilon:  0.4557158200105743  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4685 episode reward:  12.0  Episode finished after 609 timesteps\n",
      "    PARAMS.epsilon:  0.4554148600105724  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4686 episode reward:  8.0  Episode finished after 288 timesteps\n",
      "    PARAMS.epsilon:  0.4552723000105715  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4687 episode reward:  6.0  Episode finished after 348 timesteps\n",
      "    PARAMS.epsilon:  0.4551000400105704  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4688 episode reward:  7.0  Episode finished after 411 timesteps\n",
      "    PARAMS.epsilon:  0.4548961000105691  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4689 episode reward:  14.0  Episode finished after 493 timesteps\n",
      "    PARAMS.epsilon:  0.4546525600105676  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4690 episode reward:  7.0  Episode finished after 374 timesteps\n",
      "    PARAMS.epsilon:  0.4544664400105664  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4691 episode reward:  7.0  Episode finished after 363 timesteps\n",
      "    PARAMS.epsilon:  0.4542882400105653  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4692 episode reward:  3.0  Episode finished after 250 timesteps\n",
      "    PARAMS.epsilon:  0.4541635000105645  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4693 episode reward:  13.0  Episode finished after 624 timesteps\n",
      "    PARAMS.epsilon:  0.45385462001056254  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4694 episode reward:  6.0  Episode finished after 354 timesteps\n",
      "    PARAMS.epsilon:  0.45368038001056143  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4695 episode reward:  12.0  Episode finished after 595 timesteps\n",
      "    PARAMS.epsilon:  0.45338536001055957  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4696 episode reward:  5.0  Episode finished after 299 timesteps\n",
      "    PARAMS.epsilon:  0.45323686001055863  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4697 episode reward:  8.0  Episode finished after 432 timesteps\n",
      "    PARAMS.epsilon:  0.4530230200105573  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4698 episode reward:  11.0  Episode finished after 562 timesteps\n",
      "    PARAMS.epsilon:  0.4527458200105555  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4699 episode reward:  14.0  Episode finished after 496 timesteps\n",
      "    PARAMS.epsilon:  0.45250030001055397  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4700 episode reward:  6.0  Episode finished after 395 timesteps\n",
      "    PARAMS.epsilon:  0.45230428001055273  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4701 episode reward:  3.0  Episode finished after 229 timesteps\n",
      "    PARAMS.epsilon:  0.452191420010552  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4702 episode reward:  6.0  Episode finished after 341 timesteps\n",
      "    PARAMS.epsilon:  0.45202114001055094  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4703 episode reward:  9.0  Episode finished after 448 timesteps\n",
      "    PARAMS.epsilon:  0.45179938001054953  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4704 episode reward:  6.0  Episode finished after 375 timesteps\n",
      "    PARAMS.epsilon:  0.45161524001054837  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4705 episode reward:  5.0  Episode finished after 327 timesteps\n",
      "    PARAMS.epsilon:  0.45145288001054734  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4706 episode reward:  7.0  Episode finished after 417 timesteps\n",
      "    PARAMS.epsilon:  0.45124696001054604  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4707 episode reward:  7.0  Episode finished after 410 timesteps\n",
      "    PARAMS.epsilon:  0.45104302001054475  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4708 episode reward:  7.0  Episode finished after 394 timesteps\n",
      "    PARAMS.epsilon:  0.4508489800105435  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4709 episode reward:  13.0  Episode finished after 464 timesteps\n",
      "    PARAMS.epsilon:  0.45061930001054207  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4710 episode reward:  9.0  Episode finished after 524 timesteps\n",
      "    PARAMS.epsilon:  0.4503599200105404  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4711 episode reward:  14.0  Episode finished after 617 timesteps\n",
      "    PARAMS.epsilon:  0.4500530200105385  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4712 episode reward:  8.0  Episode finished after 396 timesteps\n",
      "    PARAMS.epsilon:  0.44985700001053724  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4713 episode reward:  6.0  Episode finished after 321 timesteps\n",
      "    PARAMS.epsilon:  0.44969860001053624  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4714 episode reward:  4.0  Episode finished after 307 timesteps\n",
      "    PARAMS.epsilon:  0.4495461400105353  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4715 episode reward:  12.0  Episode finished after 441 timesteps\n",
      "    PARAMS.epsilon:  0.4493283400105339  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4716 episode reward:  6.0  Episode finished after 387 timesteps\n",
      "    PARAMS.epsilon:  0.4491362800105327  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4717 episode reward:  10.0  Episode finished after 528 timesteps\n",
      "    PARAMS.epsilon:  0.44887492001053103  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4718 episode reward:  13.0  Episode finished after 595 timesteps\n",
      "    PARAMS.epsilon:  0.4485818800105292  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4719 episode reward:  11.0  Episode finished after 545 timesteps\n",
      "    PARAMS.epsilon:  0.44831062001052746  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4720 episode reward:  7.0  Episode finished after 412 timesteps\n",
      "    PARAMS.epsilon:  0.44810668001052617  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4721 episode reward:  7.0  Episode finished after 363 timesteps\n",
      "    PARAMS.epsilon:  0.44792848001052504  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4722 episode reward:  7.0  Episode finished after 378 timesteps\n",
      "    PARAMS.epsilon:  0.44774038001052385  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4723 episode reward:  6.0  Episode finished after 364 timesteps\n",
      "    PARAMS.epsilon:  0.4475602000105227  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4724 episode reward:  8.0  Episode finished after 426 timesteps\n",
      "    PARAMS.epsilon:  0.4473503200105214  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4725 episode reward:  12.0  Episode finished after 474 timesteps\n",
      "    PARAMS.epsilon:  0.4471147000105199  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4726 episode reward:  4.0  Episode finished after 301 timesteps\n",
      "    PARAMS.epsilon:  0.44696620001051895  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4727 episode reward:  4.0  Episode finished after 282 timesteps\n",
      "    PARAMS.epsilon:  0.44682562001051807  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4728 episode reward:  21.0  Episode finished after 634 timesteps\n",
      "    PARAMS.epsilon:  0.4465127800105161  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4729 episode reward:  10.0  Episode finished after 515 timesteps\n",
      "    PARAMS.epsilon:  0.44625736001051447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4730 episode reward:  7.0  Episode finished after 446 timesteps\n",
      "    PARAMS.epsilon:  0.4460375800105131  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4731 episode reward:  11.0  Episode finished after 536 timesteps\n",
      "    PARAMS.epsilon:  0.4457722600105114  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4732 episode reward:  18.0  Episode finished after 505 timesteps\n",
      "    PARAMS.epsilon:  0.4455208000105098  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4733 episode reward:  11.0  Episode finished after 515 timesteps\n",
      "    PARAMS.epsilon:  0.4452673600105082  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4734 episode reward:  10.0  Episode finished after 532 timesteps\n",
      "    PARAMS.epsilon:  0.44500402001050654  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4735 episode reward:  8.0  Episode finished after 436 timesteps\n",
      "    PARAMS.epsilon:  0.4447882000105052  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4736 episode reward:  6.0  Episode finished after 316 timesteps\n",
      "    PARAMS.epsilon:  0.4446317800105042  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4737 episode reward:  9.0  Episode finished after 485 timesteps\n",
      "    PARAMS.epsilon:  0.44439022001050266  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4738 episode reward:  8.0  Episode finished after 411 timesteps\n",
      "    PARAMS.epsilon:  0.4441882600105014  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4739 episode reward:  5.0  Episode finished after 311 timesteps\n",
      "    PARAMS.epsilon:  0.4440338200105004  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4740 episode reward:  6.0  Episode finished after 375 timesteps\n",
      "    PARAMS.epsilon:  0.4438477000104992  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4741 episode reward:  7.0  Episode finished after 339 timesteps\n",
      "    PARAMS.epsilon:  0.44367940001049816  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4742 episode reward:  6.0  Episode finished after 338 timesteps\n",
      "    PARAMS.epsilon:  0.4435130800104971  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4743 episode reward:  12.0  Episode finished after 565 timesteps\n",
      "    PARAMS.epsilon:  0.44323390001049534  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4744 episode reward:  11.0  Episode finished after 557 timesteps\n",
      "    PARAMS.epsilon:  0.4429567000104936  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4745 episode reward:  16.0  Episode finished after 579 timesteps\n",
      "    PARAMS.epsilon:  0.4426715800104918  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4746 episode reward:  7.0  Episode finished after 392 timesteps\n",
      "    PARAMS.epsilon:  0.44247754001049056  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4747 episode reward:  8.0  Episode finished after 422 timesteps\n",
      "    PARAMS.epsilon:  0.4422676600104892  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4748 episode reward:  5.0  Episode finished after 309 timesteps\n",
      "    PARAMS.epsilon:  0.44211520001048826  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4749 episode reward:  7.0  Episode finished after 387 timesteps\n",
      "    PARAMS.epsilon:  0.44192314001048705  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4750 episode reward:  14.0  Episode finished after 620 timesteps\n",
      "    PARAMS.epsilon:  0.4416162400104851  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4751 episode reward:  6.0  Episode finished after 344 timesteps\n",
      "    PARAMS.epsilon:  0.44144596001048403  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4752 episode reward:  9.0  Episode finished after 442 timesteps\n",
      "    PARAMS.epsilon:  0.44122816001048265  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4753 episode reward:  7.0  Episode finished after 454 timesteps\n",
      "    PARAMS.epsilon:  0.4410024400104812  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4754 episode reward:  7.0  Episode finished after 396 timesteps\n",
      "    PARAMS.epsilon:  0.44080642001048  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4755 episode reward:  11.0  Episode finished after 427 timesteps\n",
      "    PARAMS.epsilon:  0.44059456001047864  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4756 episode reward:  4.0  Episode finished after 262 timesteps\n",
      "    PARAMS.epsilon:  0.4404658600104778  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4757 episode reward:  6.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.4403015200104768  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4758 episode reward:  10.0  Episode finished after 475 timesteps\n",
      "    PARAMS.epsilon:  0.4400659000104753  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4759 episode reward:  11.0  Episode finished after 536 timesteps\n",
      "    PARAMS.epsilon:  0.4398005800104736  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4760 episode reward:  11.0  Episode finished after 381 timesteps\n",
      "    PARAMS.epsilon:  0.43961248001047243  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4761 episode reward:  7.0  Episode finished after 416 timesteps\n",
      "    PARAMS.epsilon:  0.4394065600104711  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4762 episode reward:  5.0  Episode finished after 338 timesteps\n",
      "    PARAMS.epsilon:  0.4392402400104701  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4763 episode reward:  14.0  Episode finished after 603 timesteps\n",
      "    PARAMS.epsilon:  0.4389412600104682  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4764 episode reward:  10.0  Episode finished after 492 timesteps\n",
      "    PARAMS.epsilon:  0.43869772001046664  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4765 episode reward:  5.0  Episode finished after 295 timesteps\n",
      "    PARAMS.epsilon:  0.4385512000104657  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4766 episode reward:  4.0  Episode finished after 291 timesteps\n",
      "    PARAMS.epsilon:  0.4384066600104648  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4767 episode reward:  11.0  Episode finished after 539 timesteps\n",
      "    PARAMS.epsilon:  0.4381413400104631  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4768 episode reward:  13.0  Episode finished after 643 timesteps\n",
      "    PARAMS.epsilon:  0.4378225600104611  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4769 episode reward:  13.0  Episode finished after 605 timesteps\n",
      "    PARAMS.epsilon:  0.4375235800104592  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4770 episode reward:  6.0  Episode finished after 326 timesteps\n",
      "    PARAMS.epsilon:  0.4373612200104582  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4771 episode reward:  9.0  Episode finished after 482 timesteps\n",
      "    PARAMS.epsilon:  0.4371236200104567  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4772 episode reward:  6.0  Episode finished after 346 timesteps\n",
      "    PARAMS.epsilon:  0.4369513600104556  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4773 episode reward:  9.0  Episode finished after 445 timesteps\n",
      "    PARAMS.epsilon:  0.4367315800104542  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4774 episode reward:  14.0  Episode finished after 469 timesteps\n",
      "    PARAMS.epsilon:  0.43649992001045274  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4775 episode reward:  9.0  Episode finished after 456 timesteps\n",
      "    PARAMS.epsilon:  0.4362742000104513  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4776 episode reward:  15.0  Episode finished after 590 timesteps\n",
      "    PARAMS.epsilon:  0.43598116001044945  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4777 episode reward:  11.0  Episode finished after 519 timesteps\n",
      "    PARAMS.epsilon:  0.4357237600104478  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4778 episode reward:  10.0  Episode finished after 508 timesteps\n",
      "    PARAMS.epsilon:  0.43547230001044623  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4779 episode reward:  9.0  Episode finished after 334 timesteps\n",
      "    PARAMS.epsilon:  0.4353079600104452  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4780 episode reward:  1.0  Episode finished after 154 timesteps\n",
      "    PARAMS.epsilon:  0.4352307400104447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4781 episode reward:  12.0  Episode finished after 463 timesteps\n",
      "    PARAMS.epsilon:  0.43500304001044326  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4782 episode reward:  12.0  Episode finished after 438 timesteps\n",
      "    PARAMS.epsilon:  0.4347852400104419  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4783 episode reward:  5.0  Episode finished after 371 timesteps\n",
      "    PARAMS.epsilon:  0.4346011000104407  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4784 episode reward:  9.0  Episode finished after 473 timesteps\n",
      "    PARAMS.epsilon:  0.43436746001043924  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4785 episode reward:  6.0  Episode finished after 334 timesteps\n",
      "    PARAMS.epsilon:  0.4342031200104382  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4786 episode reward:  8.0  Episode finished after 386 timesteps\n",
      "    PARAMS.epsilon:  0.434011060010437  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4787 episode reward:  9.0  Episode finished after 453 timesteps\n",
      "    PARAMS.epsilon:  0.4337873200104356  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4788 episode reward:  7.0  Episode finished after 376 timesteps\n",
      "    PARAMS.epsilon:  0.4336012000104344  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4789 episode reward:  12.0  Episode finished after 563 timesteps\n",
      "    PARAMS.epsilon:  0.43332202001043263  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4790 episode reward:  10.0  Episode finished after 479 timesteps\n",
      "    PARAMS.epsilon:  0.4330844200104311  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4791 episode reward:  8.0  Episode finished after 415 timesteps\n",
      "    PARAMS.epsilon:  0.43288048001042984  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4792 episode reward:  3.0  Episode finished after 228 timesteps\n",
      "    PARAMS.epsilon:  0.4327676200104291  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4793 episode reward:  8.0  Episode finished after 441 timesteps\n",
      "    PARAMS.epsilon:  0.43254784001042773  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4794 episode reward:  10.0  Episode finished after 488 timesteps\n",
      "    PARAMS.epsilon:  0.4323062800104262  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4795 episode reward:  13.0  Episode finished after 497 timesteps\n",
      "    PARAMS.epsilon:  0.43206076001042465  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4796 episode reward:  12.0  Episode finished after 440 timesteps\n",
      "    PARAMS.epsilon:  0.43184296001042327  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4797 episode reward:  5.0  Episode finished after 277 timesteps\n",
      "    PARAMS.epsilon:  0.4317063400104224  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4798 episode reward:  14.0  Episode finished after 658 timesteps\n",
      "    PARAMS.epsilon:  0.43137964001042034  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4799 episode reward:  10.0  Episode finished after 500 timesteps\n",
      "    PARAMS.epsilon:  0.4311321400104188  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4800 episode reward:  16.0  Episode finished after 614 timesteps\n",
      "    PARAMS.epsilon:  0.43082920001041686  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4801 episode reward:  13.0  Episode finished after 612 timesteps\n",
      "    PARAMS.epsilon:  0.43052626001041494  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4802 episode reward:  10.0  Episode finished after 497 timesteps\n",
      "    PARAMS.epsilon:  0.4302807400104134  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4803 episode reward:  8.0  Episode finished after 302 timesteps\n",
      "    PARAMS.epsilon:  0.43013026001041244  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4804 episode reward:  11.0  Episode finished after 505 timesteps\n",
      "    PARAMS.epsilon:  0.42988078001041086  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4805 episode reward:  6.0  Episode finished after 347 timesteps\n",
      "    PARAMS.epsilon:  0.42970852001040977  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4806 episode reward:  13.0  Episode finished after 446 timesteps\n",
      "    PARAMS.epsilon:  0.4294887400104084  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4807 episode reward:  18.0  Episode finished after 586 timesteps\n",
      "    PARAMS.epsilon:  0.42919768001040653  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4808 episode reward:  9.0  Episode finished after 473 timesteps\n",
      "    PARAMS.epsilon:  0.42896404001040506  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4809 episode reward:  10.0  Episode finished after 461 timesteps\n",
      "    PARAMS.epsilon:  0.4287363400104036  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4810 episode reward:  10.0  Episode finished after 477 timesteps\n",
      "    PARAMS.epsilon:  0.4284987400104021  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4811 episode reward:  12.0  Episode finished after 633 timesteps\n",
      "    PARAMS.epsilon:  0.42818590001040013  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4812 episode reward:  10.0  Episode finished after 504 timesteps\n",
      "    PARAMS.epsilon:  0.42793642001039855  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4813 episode reward:  4.0  Episode finished after 281 timesteps\n",
      "    PARAMS.epsilon:  0.4277978200103977  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4814 episode reward:  4.0  Episode finished after 298 timesteps\n",
      "    PARAMS.epsilon:  0.42764932001039674  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4815 episode reward:  3.0  Episode finished after 246 timesteps\n",
      "    PARAMS.epsilon:  0.427528540010396  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4816 episode reward:  9.0  Episode finished after 446 timesteps\n",
      "    PARAMS.epsilon:  0.42730678001039457  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4817 episode reward:  9.0  Episode finished after 457 timesteps\n",
      "    PARAMS.epsilon:  0.42708106001039314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4818 episode reward:  13.0  Episode finished after 605 timesteps\n",
      "    PARAMS.epsilon:  0.42678208001039125  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4819 episode reward:  15.0  Episode finished after 536 timesteps\n",
      "    PARAMS.epsilon:  0.4265167600103896  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4820 episode reward:  9.0  Episode finished after 468 timesteps\n",
      "    PARAMS.epsilon:  0.4262851000103881  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4821 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.4261445200103872  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4822 episode reward:  7.0  Episode finished after 381 timesteps\n",
      "    PARAMS.epsilon:  0.425954440010386  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4823 episode reward:  9.0  Episode finished after 491 timesteps\n",
      "    PARAMS.epsilon:  0.4257128800103845  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4824 episode reward:  12.0  Episode finished after 556 timesteps\n",
      "    PARAMS.epsilon:  0.42543766001038275  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4825 episode reward:  13.0  Episode finished after 574 timesteps\n",
      "    PARAMS.epsilon:  0.42515254001038094  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4826 episode reward:  15.0  Episode finished after 632 timesteps\n",
      "    PARAMS.epsilon:  0.42483970001037896  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4827 episode reward:  3.0  Episode finished after 236 timesteps\n",
      "    PARAMS.epsilon:  0.4247228800103782  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4828 episode reward:  7.0  Episode finished after 405 timesteps\n",
      "    PARAMS.epsilon:  0.42452290001037696  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4829 episode reward:  8.0  Episode finished after 431 timesteps\n",
      "    PARAMS.epsilon:  0.4243090600103756  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4830 episode reward:  9.0  Episode finished after 440 timesteps\n",
      "    PARAMS.epsilon:  0.4240912600103742  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4831 episode reward:  12.0  Episode finished after 442 timesteps\n",
      "    PARAMS.epsilon:  0.42387346001037285  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4832 episode reward:  13.0  Episode finished after 588 timesteps\n",
      "    PARAMS.epsilon:  0.423582400010371  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4833 episode reward:  6.0  Episode finished after 365 timesteps\n",
      "    PARAMS.epsilon:  0.42340024001036985  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4834 episode reward:  10.0  Episode finished after 486 timesteps\n",
      "    PARAMS.epsilon:  0.42316066001036834  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4835 episode reward:  9.0  Episode finished after 446 timesteps\n",
      "    PARAMS.epsilon:  0.42293890001036694  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4836 episode reward:  10.0  Episode finished after 373 timesteps\n",
      "    PARAMS.epsilon:  0.42275476001036577  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4837 episode reward:  13.0  Episode finished after 579 timesteps\n",
      "    PARAMS.epsilon:  0.42246766001036395  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4838 episode reward:  4.0  Episode finished after 262 timesteps\n",
      "    PARAMS.epsilon:  0.42233896001036314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4839 episode reward:  1.0  Episode finished after 152 timesteps\n",
      "    PARAMS.epsilon:  0.42226372001036266  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4840 episode reward:  12.0  Episode finished after 442 timesteps\n",
      "    PARAMS.epsilon:  0.4220439400103613  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4841 episode reward:  6.0  Episode finished after 377 timesteps\n",
      "    PARAMS.epsilon:  0.4218578200103601  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4842 episode reward:  9.0  Episode finished after 467 timesteps\n",
      "    PARAMS.epsilon:  0.42162616001035863  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4843 episode reward:  7.0  Episode finished after 371 timesteps\n",
      "    PARAMS.epsilon:  0.4214440000103575  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4844 episode reward:  15.0  Episode finished after 547 timesteps\n",
      "    PARAMS.epsilon:  0.42117274001035576  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4845 episode reward:  13.0  Episode finished after 550 timesteps\n",
      "    PARAMS.epsilon:  0.42089950001035403  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4846 episode reward:  14.0  Episode finished after 545 timesteps\n",
      "    PARAMS.epsilon:  0.42063022001035233  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4847 episode reward:  4.0  Episode finished after 279 timesteps\n",
      "    PARAMS.epsilon:  0.42049162001035145  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4848 episode reward:  8.0  Episode finished after 452 timesteps\n",
      "    PARAMS.epsilon:  0.42026788001035004  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4849 episode reward:  10.0  Episode finished after 503 timesteps\n",
      "    PARAMS.epsilon:  0.42002038001034847  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4850 episode reward:  13.0  Episode finished after 590 timesteps\n",
      "    PARAMS.epsilon:  0.4197273400103466  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4851 episode reward:  7.0  Episode finished after 376 timesteps\n",
      "    PARAMS.epsilon:  0.41954122001034544  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4852 episode reward:  2.0  Episode finished after 210 timesteps\n",
      "    PARAMS.epsilon:  0.4194382600103448  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4853 episode reward:  7.0  Episode finished after 416 timesteps\n",
      "    PARAMS.epsilon:  0.4192323400103435  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4854 episode reward:  9.0  Episode finished after 485 timesteps\n",
      "    PARAMS.epsilon:  0.41899078001034196  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4855 episode reward:  8.0  Episode finished after 373 timesteps\n",
      "    PARAMS.epsilon:  0.4188066400103408  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4856 episode reward:  15.0  Episode finished after 580 timesteps\n",
      "    PARAMS.epsilon:  0.418519540010339  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4857 episode reward:  7.0  Episode finished after 351 timesteps\n",
      "    PARAMS.epsilon:  0.4183453000103379  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4858 episode reward:  4.0  Episode finished after 275 timesteps\n",
      "    PARAMS.epsilon:  0.418210660010337  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4859 episode reward:  4.0  Episode finished after 278 timesteps\n",
      "    PARAMS.epsilon:  0.41807206001033614  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4860 episode reward:  17.0  Episode finished after 678 timesteps\n",
      "    PARAMS.epsilon:  0.417737440010334  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4861 episode reward:  9.0  Episode finished after 411 timesteps\n",
      "    PARAMS.epsilon:  0.41753350001033274  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4862 episode reward:  8.0  Episode finished after 391 timesteps\n",
      "    PARAMS.epsilon:  0.4173394600103315  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4863 episode reward:  21.0  Episode finished after 543 timesteps\n",
      "    PARAMS.epsilon:  0.4170701800103298  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4864 episode reward:  11.0  Episode finished after 408 timesteps\n",
      "    PARAMS.epsilon:  0.4168682200103285  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4865 episode reward:  4.0  Episode finished after 288 timesteps\n",
      "    PARAMS.epsilon:  0.4167256600103276  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4866 episode reward:  4.0  Episode finished after 271 timesteps\n",
      "    PARAMS.epsilon:  0.4165930000103268  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4867 episode reward:  6.0  Episode finished after 336 timesteps\n",
      "    PARAMS.epsilon:  0.41642668001032573  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4868 episode reward:  6.0  Episode finished after 315 timesteps\n",
      "    PARAMS.epsilon:  0.41627026001032474  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4869 episode reward:  7.0  Episode finished after 334 timesteps\n",
      "    PARAMS.epsilon:  0.4161039400103237  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4870 episode reward:  9.0  Episode finished after 430 timesteps\n",
      "    PARAMS.epsilon:  0.41589208001032235  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4871 episode reward:  17.0  Episode finished after 491 timesteps\n",
      "    PARAMS.epsilon:  0.4156485400103208  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4872 episode reward:  29.0  Episode finished after 824 timesteps\n",
      "    PARAMS.epsilon:  0.41524066001031823  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  29.0  agent.save() Done!\n",
      "PARAMS.episode_i:  4873 episode reward:  14.0  Episode finished after 633 timesteps\n",
      "    PARAMS.epsilon:  0.41492782001031625  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4874 episode reward:  17.0  Episode finished after 760 timesteps\n",
      "    PARAMS.epsilon:  0.41455162001031387  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4875 episode reward:  9.0  Episode finished after 474 timesteps\n",
      "    PARAMS.epsilon:  0.4143160000103124  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4876 episode reward:  4.0  Episode finished after 278 timesteps\n",
      "    PARAMS.epsilon:  0.4141793800103115  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4877 episode reward:  9.0  Episode finished after 457 timesteps\n",
      "    PARAMS.epsilon:  0.4139536600103101  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4878 episode reward:  7.0  Episode finished after 394 timesteps\n",
      "    PARAMS.epsilon:  0.41375764001030885  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4879 episode reward:  6.0  Episode finished after 358 timesteps\n",
      "    PARAMS.epsilon:  0.41358142001030773  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4880 episode reward:  8.0  Episode finished after 426 timesteps\n",
      "    PARAMS.epsilon:  0.4133695600103064  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4881 episode reward:  5.0  Episode finished after 320 timesteps\n",
      "    PARAMS.epsilon:  0.4132111600103054  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4882 episode reward:  12.0  Episode finished after 558 timesteps\n",
      "    PARAMS.epsilon:  0.41293594001030365  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4883 episode reward:  7.0  Episode finished after 343 timesteps\n",
      "    PARAMS.epsilon:  0.41276566001030257  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4884 episode reward:  6.0  Episode finished after 347 timesteps\n",
      "    PARAMS.epsilon:  0.4125934000103015  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4885 episode reward:  14.0  Episode finished after 588 timesteps\n",
      "    PARAMS.epsilon:  0.41230234001029964  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4886 episode reward:  14.0  Episode finished after 662 timesteps\n",
      "    PARAMS.epsilon:  0.4119756400102976  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4887 episode reward:  6.0  Episode finished after 343 timesteps\n",
      "    PARAMS.epsilon:  0.4118053600102965  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4888 episode reward:  11.0  Episode finished after 575 timesteps\n",
      "    PARAMS.epsilon:  0.4115202400102947  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4889 episode reward:  3.0  Episode finished after 232 timesteps\n",
      "    PARAMS.epsilon:  0.41140540001029396  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4890 episode reward:  13.0  Episode finished after 678 timesteps\n",
      "    PARAMS.epsilon:  0.41107078001029185  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4891 episode reward:  7.0  Episode finished after 408 timesteps\n",
      "    PARAMS.epsilon:  0.41086882001029057  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4892 episode reward:  12.0  Episode finished after 544 timesteps\n",
      "    PARAMS.epsilon:  0.41059954001028887  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4893 episode reward:  5.0  Episode finished after 309 timesteps\n",
      "    PARAMS.epsilon:  0.4104451000102879  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4894 episode reward:  10.0  Episode finished after 400 timesteps\n",
      "    PARAMS.epsilon:  0.41024710001028664  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4895 episode reward:  2.0  Episode finished after 184 timesteps\n",
      "    PARAMS.epsilon:  0.41015602001028606  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4896 episode reward:  14.0  Episode finished after 519 timesteps\n",
      "    PARAMS.epsilon:  0.40990060001028444  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4897 episode reward:  7.0  Episode finished after 390 timesteps\n",
      "    PARAMS.epsilon:  0.4097065600102832  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4898 episode reward:  8.0  Episode finished after 410 timesteps\n",
      "    PARAMS.epsilon:  0.40950460001028194  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4899 episode reward:  2.0  Episode finished after 187 timesteps\n",
      "    PARAMS.epsilon:  0.40941154001028135  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4900 episode reward:  13.0  Episode finished after 638 timesteps\n",
      "    PARAMS.epsilon:  0.40909474001027935  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4901 episode reward:  14.0  Episode finished after 502 timesteps\n",
      "    PARAMS.epsilon:  0.4088472400102778  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4902 episode reward:  6.0  Episode finished after 383 timesteps\n",
      "    PARAMS.epsilon:  0.4086571600102766  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4903 episode reward:  8.0  Episode finished after 395 timesteps\n",
      "    PARAMS.epsilon:  0.40846114001027534  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4904 episode reward:  7.0  Episode finished after 432 timesteps\n",
      "    PARAMS.epsilon:  0.408247300010274  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4905 episode reward:  6.0  Episode finished after 344 timesteps\n",
      "    PARAMS.epsilon:  0.4080770200102729  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4906 episode reward:  3.0  Episode finished after 221 timesteps\n",
      "    PARAMS.epsilon:  0.4079681200102722  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4907 episode reward:  9.0  Episode finished after 478 timesteps\n",
      "    PARAMS.epsilon:  0.4077325000102707  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4908 episode reward:  6.0  Episode finished after 367 timesteps\n",
      "    PARAMS.epsilon:  0.4075503400102696  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4909 episode reward:  10.0  Episode finished after 513 timesteps\n",
      "    PARAMS.epsilon:  0.40729690001026797  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4910 episode reward:  10.0  Episode finished after 447 timesteps\n",
      "    PARAMS.epsilon:  0.40707514001026657  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4911 episode reward:  13.0  Episode finished after 458 timesteps\n",
      "    PARAMS.epsilon:  0.4068474400102651  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4912 episode reward:  12.0  Episode finished after 579 timesteps\n",
      "    PARAMS.epsilon:  0.4065623200102633  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4913 episode reward:  5.0  Episode finished after 316 timesteps\n",
      "    PARAMS.epsilon:  0.40640590001026233  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4914 episode reward:  7.0  Episode finished after 411 timesteps\n",
      "    PARAMS.epsilon:  0.40620196001026104  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4915 episode reward:  9.0  Episode finished after 459 timesteps\n",
      "    PARAMS.epsilon:  0.4059742600102596  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4916 episode reward:  5.0  Episode finished after 343 timesteps\n",
      "    PARAMS.epsilon:  0.4058039800102585  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4917 episode reward:  16.0  Episode finished after 625 timesteps\n",
      "    PARAMS.epsilon:  0.40549510001025657  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4918 episode reward:  8.0  Episode finished after 457 timesteps\n",
      "    PARAMS.epsilon:  0.40526938001025514  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4919 episode reward:  12.0  Episode finished after 478 timesteps\n",
      "    PARAMS.epsilon:  0.40503178001025364  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4920 episode reward:  12.0  Episode finished after 644 timesteps\n",
      "    PARAMS.epsilon:  0.4047130000102516  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4921 episode reward:  8.0  Episode finished after 430 timesteps\n",
      "    PARAMS.epsilon:  0.4045011400102503  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4922 episode reward:  6.0  Episode finished after 317 timesteps\n",
      "    PARAMS.epsilon:  0.4043447200102493  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4923 episode reward:  8.0  Episode finished after 411 timesteps\n",
      "    PARAMS.epsilon:  0.404140780010248  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4924 episode reward:  15.0  Episode finished after 454 timesteps\n",
      "    PARAMS.epsilon:  0.4039150600102466  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4925 episode reward:  8.0  Episode finished after 420 timesteps\n",
      "    PARAMS.epsilon:  0.40370716001024526  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4926 episode reward:  11.0  Episode finished after 295 timesteps\n",
      "    PARAMS.epsilon:  0.40356262001024434  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4927 episode reward:  11.0  Episode finished after 513 timesteps\n",
      "    PARAMS.epsilon:  0.40330720001024273  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4928 episode reward:  4.0  Episode finished after 273 timesteps\n",
      "    PARAMS.epsilon:  0.4031725600102419  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4929 episode reward:  9.0  Episode finished after 454 timesteps\n",
      "    PARAMS.epsilon:  0.40294882001024046  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4930 episode reward:  8.0  Episode finished after 384 timesteps\n",
      "    PARAMS.epsilon:  0.40275874001023926  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4931 episode reward:  6.0  Episode finished after 383 timesteps\n",
      "    PARAMS.epsilon:  0.40256866001023806  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4932 episode reward:  10.0  Episode finished after 500 timesteps\n",
      "    PARAMS.epsilon:  0.4023211600102365  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4933 episode reward:  9.0  Episode finished after 460 timesteps\n",
      "    PARAMS.epsilon:  0.40209346001023505  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4934 episode reward:  8.0  Episode finished after 405 timesteps\n",
      "    PARAMS.epsilon:  0.4018934800102338  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4935 episode reward:  17.0  Episode finished after 610 timesteps\n",
      "    PARAMS.epsilon:  0.40159054001023187  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4936 episode reward:  27.0  Episode finished after 898 timesteps\n",
      "    PARAMS.epsilon:  0.40114702001022906  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4937 episode reward:  7.0  Episode finished after 374 timesteps\n",
      "    PARAMS.epsilon:  0.4009609000102279  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4938 episode reward:  6.0  Episode finished after 323 timesteps\n",
      "    PARAMS.epsilon:  0.40080052001022687  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4939 episode reward:  13.0  Episode finished after 599 timesteps\n",
      "    PARAMS.epsilon:  0.400505500010225  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4940 episode reward:  13.0  Episode finished after 625 timesteps\n",
      "    PARAMS.epsilon:  0.40019464001022304  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4941 episode reward:  4.0  Episode finished after 252 timesteps\n",
      "    PARAMS.epsilon:  0.40006990001022225  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4942 episode reward:  15.0  Episode finished after 522 timesteps\n",
      "    PARAMS.epsilon:  0.3998125000102206  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4943 episode reward:  8.0  Episode finished after 441 timesteps\n",
      "    PARAMS.epsilon:  0.39959470001021924  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4944 episode reward:  14.0  Episode finished after 580 timesteps\n",
      "    PARAMS.epsilon:  0.3993076000102174  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4945 episode reward:  8.0  Episode finished after 425 timesteps\n",
      "    PARAMS.epsilon:  0.3990957400102161  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4946 episode reward:  12.0  Episode finished after 618 timesteps\n",
      "    PARAMS.epsilon:  0.39879082001021415  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4947 episode reward:  8.0  Episode finished after 429 timesteps\n",
      "    PARAMS.epsilon:  0.3985789600102128  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4948 episode reward:  16.0  Episode finished after 647 timesteps\n",
      "    PARAMS.epsilon:  0.3982582000102108  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4949 episode reward:  11.0  Episode finished after 534 timesteps\n",
      "    PARAMS.epsilon:  0.3979928800102091  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4950 episode reward:  11.0  Episode finished after 539 timesteps\n",
      "    PARAMS.epsilon:  0.3977275600102074  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4951 episode reward:  7.0  Episode finished after 370 timesteps\n",
      "    PARAMS.epsilon:  0.39754342001020626  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4952 episode reward:  10.0  Episode finished after 426 timesteps\n",
      "    PARAMS.epsilon:  0.39733354001020493  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4953 episode reward:  7.0  Episode finished after 380 timesteps\n",
      "    PARAMS.epsilon:  0.39714544001020374  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4954 episode reward:  8.0  Episode finished after 481 timesteps\n",
      "    PARAMS.epsilon:  0.3969058600102022  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4955 episode reward:  11.0  Episode finished after 526 timesteps\n",
      "    PARAMS.epsilon:  0.3966464800102006  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4956 episode reward:  15.0  Episode finished after 511 timesteps\n",
      "    PARAMS.epsilon:  0.396393040010199  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4957 episode reward:  11.0  Episode finished after 563 timesteps\n",
      "    PARAMS.epsilon:  0.3961138600101972  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4958 episode reward:  21.0  Episode finished after 549 timesteps\n",
      "    PARAMS.epsilon:  0.3958426000101955  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4959 episode reward:  16.0  Episode finished after 570 timesteps\n",
      "    PARAMS.epsilon:  0.3955614400101937  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4960 episode reward:  7.0  Episode finished after 374 timesteps\n",
      "    PARAMS.epsilon:  0.39537532001019254  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4961 episode reward:  11.0  Episode finished after 556 timesteps\n",
      "    PARAMS.epsilon:  0.3951001000101908  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4962 episode reward:  8.0  Episode finished after 429 timesteps\n",
      "    PARAMS.epsilon:  0.39488824001018946  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4963 episode reward:  17.0  Episode finished after 627 timesteps\n",
      "    PARAMS.epsilon:  0.3945773800101875  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4964 episode reward:  13.0  Episode finished after 598 timesteps\n",
      "    PARAMS.epsilon:  0.39428236001018563  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4965 episode reward:  9.0  Episode finished after 433 timesteps\n",
      "    PARAMS.epsilon:  0.39406654001018426  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4966 episode reward:  4.0  Episode finished after 290 timesteps\n",
      "    PARAMS.epsilon:  0.39392398001018336  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4967 episode reward:  11.0  Episode finished after 438 timesteps\n",
      "    PARAMS.epsilon:  0.393706180010182  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4968 episode reward:  7.0  Episode finished after 403 timesteps\n",
      "    PARAMS.epsilon:  0.39350818001018073  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4969 episode reward:  8.0  Episode finished after 470 timesteps\n",
      "    PARAMS.epsilon:  0.39327454001017925  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4970 episode reward:  8.0  Episode finished after 444 timesteps\n",
      "    PARAMS.epsilon:  0.39305476001017786  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4971 episode reward:  15.0  Episode finished after 596 timesteps\n",
      "    PARAMS.epsilon:  0.392759740010176  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4972 episode reward:  8.0  Episode finished after 392 timesteps\n",
      "    PARAMS.epsilon:  0.39256570001017477  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4973 episode reward:  10.0  Episode finished after 533 timesteps\n",
      "    PARAMS.epsilon:  0.3923023600101731  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4974 episode reward:  15.0  Episode finished after 723 timesteps\n",
      "    PARAMS.epsilon:  0.39194398001017083  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4975 episode reward:  3.0  Episode finished after 251 timesteps\n",
      "    PARAMS.epsilon:  0.39181924001017004  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4976 episode reward:  8.0  Episode finished after 463 timesteps\n",
      "    PARAMS.epsilon:  0.3915915400101686  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4977 episode reward:  10.0  Episode finished after 356 timesteps\n",
      "    PARAMS.epsilon:  0.3914153200101675  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4978 episode reward:  12.0  Episode finished after 459 timesteps\n",
      "    PARAMS.epsilon:  0.39118762001016605  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4979 episode reward:  6.0  Episode finished after 372 timesteps\n",
      "    PARAMS.epsilon:  0.3910034800101649  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4980 episode reward:  4.0  Episode finished after 246 timesteps\n",
      "    PARAMS.epsilon:  0.3908807200101641  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4981 episode reward:  5.0  Episode finished after 325 timesteps\n",
      "    PARAMS.epsilon:  0.3907203400101631  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4982 episode reward:  8.0  Episode finished after 423 timesteps\n",
      "    PARAMS.epsilon:  0.39051046001016176  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4983 episode reward:  17.0  Episode finished after 611 timesteps\n",
      "    PARAMS.epsilon:  0.39020950001015986  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4984 episode reward:  26.0  Episode finished after 752 timesteps\n",
      "    PARAMS.epsilon:  0.3898372600101575  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4985 episode reward:  6.0  Episode finished after 360 timesteps\n",
      "    PARAMS.epsilon:  0.3896590600101564  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4986 episode reward:  14.0  Episode finished after 564 timesteps\n",
      "    PARAMS.epsilon:  0.3893798800101546  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4987 episode reward:  12.0  Episode finished after 524 timesteps\n",
      "    PARAMS.epsilon:  0.38912050001015297  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4988 episode reward:  12.0  Episode finished after 603 timesteps\n",
      "    PARAMS.epsilon:  0.3888215200101511  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4989 episode reward:  10.0  Episode finished after 387 timesteps\n",
      "    PARAMS.epsilon:  0.38862946001014986  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4990 episode reward:  9.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.3884651200101488  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4991 episode reward:  17.0  Episode finished after 611 timesteps\n",
      "    PARAMS.epsilon:  0.3881641600101469  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4992 episode reward:  7.0  Episode finished after 366 timesteps\n",
      "    PARAMS.epsilon:  0.38798200001014577  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4993 episode reward:  8.0  Episode finished after 436 timesteps\n",
      "    PARAMS.epsilon:  0.3877661800101444  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4994 episode reward:  2.0  Episode finished after 198 timesteps\n",
      "    PARAMS.epsilon:  0.3876691600101438  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4995 episode reward:  9.0  Episode finished after 454 timesteps\n",
      "    PARAMS.epsilon:  0.38744344001014236  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4996 episode reward:  6.0  Episode finished after 383 timesteps\n",
      "    PARAMS.epsilon:  0.38725336001014116  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4997 episode reward:  4.0  Episode finished after 280 timesteps\n",
      "    PARAMS.epsilon:  0.3871147600101403  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4998 episode reward:  12.0  Episode finished after 465 timesteps\n",
      "    PARAMS.epsilon:  0.3868850800101388  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  4999 episode reward:  16.0  Episode finished after 500 timesteps\n",
      "    PARAMS.epsilon:  0.38663758001013726  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5000 episode reward:  6.0  Episode finished after 364 timesteps\n",
      "    PARAMS.epsilon:  0.3864574000101361  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5001 episode reward:  9.0  Episode finished after 473 timesteps\n",
      "    PARAMS.epsilon:  0.38622376001013464  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5002 episode reward:  12.0  Episode finished after 581 timesteps\n",
      "    PARAMS.epsilon:  0.3859366600101328  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5003 episode reward:  13.0  Episode finished after 522 timesteps\n",
      "    PARAMS.epsilon:  0.3856772800101312  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5004 episode reward:  10.0  Episode finished after 560 timesteps\n",
      "    PARAMS.epsilon:  0.38540008001012943  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5005 episode reward:  8.0  Episode finished after 442 timesteps\n",
      "    PARAMS.epsilon:  0.38518228001012805  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5006 episode reward:  11.0  Episode finished after 553 timesteps\n",
      "    PARAMS.epsilon:  0.3849070600101263  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5007 episode reward:  8.0  Episode finished after 401 timesteps\n",
      "    PARAMS.epsilon:  0.38470906001012506  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5008 episode reward:  11.0  Episode finished after 443 timesteps\n",
      "    PARAMS.epsilon:  0.38448928001012367  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5009 episode reward:  4.0  Episode finished after 294 timesteps\n",
      "    PARAMS.epsilon:  0.38434474001012275  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5010 episode reward:  13.0  Episode finished after 525 timesteps\n",
      "    PARAMS.epsilon:  0.3840853600101211  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5011 episode reward:  19.0  Episode finished after 738 timesteps\n",
      "    PARAMS.epsilon:  0.3837190600101188  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5012 episode reward:  7.0  Episode finished after 353 timesteps\n",
      "    PARAMS.epsilon:  0.3835448200101177  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5013 episode reward:  18.0  Episode finished after 624 timesteps\n",
      "    PARAMS.epsilon:  0.38323594001011574  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5014 episode reward:  7.0  Episode finished after 393 timesteps\n",
      "    PARAMS.epsilon:  0.3830419000101145  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5015 episode reward:  17.0  Episode finished after 678 timesteps\n",
      "    PARAMS.epsilon:  0.3827053000101124  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5016 episode reward:  9.0  Episode finished after 469 timesteps\n",
      "    PARAMS.epsilon:  0.3824736400101109  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5017 episode reward:  11.0  Episode finished after 519 timesteps\n",
      "    PARAMS.epsilon:  0.3822162400101093  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5018 episode reward:  10.0  Episode finished after 545 timesteps\n",
      "    PARAMS.epsilon:  0.3819469600101076  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5019 episode reward:  13.0  Episode finished after 549 timesteps\n",
      "    PARAMS.epsilon:  0.38167570001010587  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5020 episode reward:  12.0  Episode finished after 586 timesteps\n",
      "    PARAMS.epsilon:  0.381384640010104  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5021 episode reward:  12.0  Episode finished after 578 timesteps\n",
      "    PARAMS.epsilon:  0.3810995200101022  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5022 episode reward:  8.0  Episode finished after 294 timesteps\n",
      "    PARAMS.epsilon:  0.3809530000101013  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5023 episode reward:  5.0  Episode finished after 286 timesteps\n",
      "    PARAMS.epsilon:  0.3808124200101004  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5024 episode reward:  13.0  Episode finished after 528 timesteps\n",
      "    PARAMS.epsilon:  0.38055106001009875  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5025 episode reward:  8.0  Episode finished after 452 timesteps\n",
      "    PARAMS.epsilon:  0.38032732001009734  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5026 episode reward:  5.0  Episode finished after 340 timesteps\n",
      "    PARAMS.epsilon:  0.38015902001009627  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5027 episode reward:  15.0  Episode finished after 575 timesteps\n",
      "    PARAMS.epsilon:  0.37987390001009447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5028 episode reward:  12.0  Episode finished after 516 timesteps\n",
      "    PARAMS.epsilon:  0.37961848001009285  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5029 episode reward:  9.0  Episode finished after 467 timesteps\n",
      "    PARAMS.epsilon:  0.3793868200100914  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5030 episode reward:  7.0  Episode finished after 406 timesteps\n",
      "    PARAMS.epsilon:  0.3791868400100901  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5031 episode reward:  12.0  Episode finished after 503 timesteps\n",
      "    PARAMS.epsilon:  0.37893736001008854  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5032 episode reward:  8.0  Episode finished after 382 timesteps\n",
      "    PARAMS.epsilon:  0.37874728001008734  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5033 episode reward:  17.0  Episode finished after 502 timesteps\n",
      "    PARAMS.epsilon:  0.3784997800100858  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5034 episode reward:  6.0  Episode finished after 326 timesteps\n",
      "    PARAMS.epsilon:  0.37833742001008475  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5035 episode reward:  6.0  Episode finished after 400 timesteps\n",
      "    PARAMS.epsilon:  0.3781394200100835  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5036 episode reward:  10.0  Episode finished after 504 timesteps\n",
      "    PARAMS.epsilon:  0.3778899400100819  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5037 episode reward:  13.0  Episode finished after 523 timesteps\n",
      "    PARAMS.epsilon:  0.3776325400100803  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5038 episode reward:  9.0  Episode finished after 467 timesteps\n",
      "    PARAMS.epsilon:  0.3774008800100788  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5039 episode reward:  11.0  Episode finished after 552 timesteps\n",
      "    PARAMS.epsilon:  0.3771276400100771  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5040 episode reward:  16.0  Episode finished after 466 timesteps\n",
      "    PARAMS.epsilon:  0.3768959800100756  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5041 episode reward:  13.0  Episode finished after 521 timesteps\n",
      "    PARAMS.epsilon:  0.376638580010074  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5042 episode reward:  5.0  Episode finished after 361 timesteps\n",
      "    PARAMS.epsilon:  0.37646038001007287  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5043 episode reward:  8.0  Episode finished after 332 timesteps\n",
      "    PARAMS.epsilon:  0.37629604001007183  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5044 episode reward:  7.0  Episode finished after 353 timesteps\n",
      "    PARAMS.epsilon:  0.37612180001007073  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5045 episode reward:  10.0  Episode finished after 466 timesteps\n",
      "    PARAMS.epsilon:  0.37589014001006926  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5046 episode reward:  9.0  Episode finished after 518 timesteps\n",
      "    PARAMS.epsilon:  0.37563472001006765  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5047 episode reward:  15.0  Episode finished after 456 timesteps\n",
      "    PARAMS.epsilon:  0.3754090000100662  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5048 episode reward:  10.0  Episode finished after 495 timesteps\n",
      "    PARAMS.epsilon:  0.37516348001006466  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5049 episode reward:  21.0  Episode finished after 488 timesteps\n",
      "    PARAMS.epsilon:  0.37492192001006314  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5050 episode reward:  8.0  Episode finished after 447 timesteps\n",
      "    PARAMS.epsilon:  0.37470016001006173  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5051 episode reward:  10.0  Episode finished after 535 timesteps\n",
      "    PARAMS.epsilon:  0.37443484001006005  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5052 episode reward:  6.0  Episode finished after 381 timesteps\n",
      "    PARAMS.epsilon:  0.37424674001005886  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5053 episode reward:  10.0  Episode finished after 529 timesteps\n",
      "    PARAMS.epsilon:  0.3739853800100572  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5054 episode reward:  12.0  Episode finished after 569 timesteps\n",
      "    PARAMS.epsilon:  0.37370422001005543  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5055 episode reward:  10.0  Episode finished after 443 timesteps\n",
      "    PARAMS.epsilon:  0.37348444001005404  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5056 episode reward:  22.0  Episode finished after 573 timesteps\n",
      "    PARAMS.epsilon:  0.37320130001005225  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5057 episode reward:  9.0  Episode finished after 462 timesteps\n",
      "    PARAMS.epsilon:  0.3729716200100508  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5058 episode reward:  6.0  Episode finished after 333 timesteps\n",
      "    PARAMS.epsilon:  0.37280728001004976  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5059 episode reward:  8.0  Episode finished after 424 timesteps\n",
      "    PARAMS.epsilon:  0.37259740001004843  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5060 episode reward:  11.0  Episode finished after 457 timesteps\n",
      "    PARAMS.epsilon:  0.372371680010047  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5061 episode reward:  2.0  Episode finished after 224 timesteps\n",
      "    PARAMS.epsilon:  0.3722608000100463  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5062 episode reward:  18.0  Episode finished after 661 timesteps\n",
      "    PARAMS.epsilon:  0.3719321200100442  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5063 episode reward:  11.0  Episode finished after 548 timesteps\n",
      "    PARAMS.epsilon:  0.3716608600100425  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5064 episode reward:  11.0  Episode finished after 581 timesteps\n",
      "    PARAMS.epsilon:  0.3713737600100407  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5065 episode reward:  11.0  Episode finished after 424 timesteps\n",
      "    PARAMS.epsilon:  0.37116388001003936  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5066 episode reward:  16.0  Episode finished after 582 timesteps\n",
      "    PARAMS.epsilon:  0.37087678001003754  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5067 episode reward:  17.0  Episode finished after 682 timesteps\n",
      "    PARAMS.epsilon:  0.3705382000100354  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5068 episode reward:  6.0  Episode finished after 361 timesteps\n",
      "    PARAMS.epsilon:  0.3703600000100343  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5069 episode reward:  11.0  Episode finished after 563 timesteps\n",
      "    PARAMS.epsilon:  0.3700808200100325  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5070 episode reward:  10.0  Episode finished after 388 timesteps\n",
      "    PARAMS.epsilon:  0.3698887600100313  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5071 episode reward:  11.0  Episode finished after 612 timesteps\n",
      "    PARAMS.epsilon:  0.3695858200100294  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5072 episode reward:  9.0  Episode finished after 439 timesteps\n",
      "    PARAMS.epsilon:  0.369368020010028  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5073 episode reward:  5.0  Episode finished after 309 timesteps\n",
      "    PARAMS.epsilon:  0.36921556001002703  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5074 episode reward:  9.0  Episode finished after 472 timesteps\n",
      "    PARAMS.epsilon:  0.36898192001002555  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5075 episode reward:  8.0  Episode finished after 385 timesteps\n",
      "    PARAMS.epsilon:  0.36879184001002435  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5076 episode reward:  6.0  Episode finished after 325 timesteps\n",
      "    PARAMS.epsilon:  0.36863146001002334  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5077 episode reward:  9.0  Episode finished after 467 timesteps\n",
      "    PARAMS.epsilon:  0.36839980001002187  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5078 episode reward:  21.0  Episode finished after 687 timesteps\n",
      "    PARAMS.epsilon:  0.3680592400100197  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5079 episode reward:  11.0  Episode finished after 455 timesteps\n",
      "    PARAMS.epsilon:  0.3678335200100183  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5080 episode reward:  14.0  Episode finished after 402 timesteps\n",
      "    PARAMS.epsilon:  0.36763552001001704  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5081 episode reward:  21.0  Episode finished after 669 timesteps\n",
      "    PARAMS.epsilon:  0.36730486001001494  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5082 episode reward:  9.0  Episode finished after 483 timesteps\n",
      "    PARAMS.epsilon:  0.36706528001001343  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5083 episode reward:  5.0  Episode finished after 334 timesteps\n",
      "    PARAMS.epsilon:  0.3668989600100124  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5084 episode reward:  14.0  Episode finished after 538 timesteps\n",
      "    PARAMS.epsilon:  0.3666336400100107  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5085 episode reward:  16.0  Episode finished after 457 timesteps\n",
      "    PARAMS.epsilon:  0.36640792001000927  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5086 episode reward:  9.0  Episode finished after 498 timesteps\n",
      "    PARAMS.epsilon:  0.3661604200100077  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5087 episode reward:  2.0  Episode finished after 223 timesteps\n",
      "    PARAMS.epsilon:  0.366049540010007  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5088 episode reward:  7.0  Episode finished after 421 timesteps\n",
      "    PARAMS.epsilon:  0.3658416400100057  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5089 episode reward:  14.0  Episode finished after 623 timesteps\n",
      "    PARAMS.epsilon:  0.36553276001000373  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5090 episode reward:  10.0  Episode finished after 550 timesteps\n",
      "    PARAMS.epsilon:  0.365261500010002  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5091 episode reward:  10.0  Episode finished after 422 timesteps\n",
      "    PARAMS.epsilon:  0.3650516200100007  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5092 episode reward:  5.0  Episode finished after 383 timesteps\n",
      "    PARAMS.epsilon:  0.3648635200099995  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5093 episode reward:  6.0  Episode finished after 390 timesteps\n",
      "    PARAMS.epsilon:  0.36466948000999827  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5094 episode reward:  6.0  Episode finished after 348 timesteps\n",
      "    PARAMS.epsilon:  0.3644972200099972  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5095 episode reward:  19.0  Episode finished after 627 timesteps\n",
      "    PARAMS.epsilon:  0.3641863600099952  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5096 episode reward:  17.0  Episode finished after 359 timesteps\n",
      "    PARAMS.epsilon:  0.3640101400099941  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5097 episode reward:  7.0  Episode finished after 431 timesteps\n",
      "    PARAMS.epsilon:  0.36379630000999275  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5098 episode reward:  0.0  Episode finished after 159 timesteps\n",
      "    PARAMS.epsilon:  0.36371710000999224  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5099 episode reward:  20.0  Episode finished after 676 timesteps\n",
      "    PARAMS.epsilon:  0.3633824800099901  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5100 episode reward:  4.0  Episode finished after 301 timesteps\n",
      "    PARAMS.epsilon:  0.3632339800099892  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5101 episode reward:  19.0  Episode finished after 624 timesteps\n",
      "    PARAMS.epsilon:  0.36292510000998723  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5102 episode reward:  17.0  Episode finished after 674 timesteps\n",
      "    PARAMS.epsilon:  0.3625904800099851  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5103 episode reward:  4.0  Episode finished after 335 timesteps\n",
      "    PARAMS.epsilon:  0.3624261400099841  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5104 episode reward:  17.0  Episode finished after 519 timesteps\n",
      "    PARAMS.epsilon:  0.36216874000998245  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5105 episode reward:  16.0  Episode finished after 603 timesteps\n",
      "    PARAMS.epsilon:  0.36186976000998056  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5106 episode reward:  6.0  Episode finished after 354 timesteps\n",
      "    PARAMS.epsilon:  0.36169552000997945  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5107 episode reward:  11.0  Episode finished after 445 timesteps\n",
      "    PARAMS.epsilon:  0.36147376000997805  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5108 episode reward:  15.0  Episode finished after 558 timesteps\n",
      "    PARAMS.epsilon:  0.3611985400099763  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5109 episode reward:  13.0  Episode finished after 621 timesteps\n",
      "    PARAMS.epsilon:  0.36089164000997437  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5110 episode reward:  10.0  Episode finished after 519 timesteps\n",
      "    PARAMS.epsilon:  0.36063424000997274  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5111 episode reward:  13.0  Episode finished after 511 timesteps\n",
      "    PARAMS.epsilon:  0.36038080000997114  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5112 episode reward:  8.0  Episode finished after 490 timesteps\n",
      "    PARAMS.epsilon:  0.3601392400099696  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5113 episode reward:  7.0  Episode finished after 404 timesteps\n",
      "    PARAMS.epsilon:  0.35993926000996834  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5114 episode reward:  4.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.35979670000996744  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5115 episode reward:  11.0  Episode finished after 537 timesteps\n",
      "    PARAMS.epsilon:  0.35953138000996576  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5116 episode reward:  12.0  Episode finished after 421 timesteps\n",
      "    PARAMS.epsilon:  0.35932348000996445  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5117 episode reward:  14.0  Episode finished after 518 timesteps\n",
      "    PARAMS.epsilon:  0.3590660800099628  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5118 episode reward:  13.0  Episode finished after 570 timesteps\n",
      "    PARAMS.epsilon:  0.35878492000996104  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5119 episode reward:  18.0  Episode finished after 552 timesteps\n",
      "    PARAMS.epsilon:  0.3585116800099593  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5120 episode reward:  9.0  Episode finished after 523 timesteps\n",
      "    PARAMS.epsilon:  0.35825230000995767  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5121 episode reward:  15.0  Episode finished after 459 timesteps\n",
      "    PARAMS.epsilon:  0.35802460000995623  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5122 episode reward:  10.0  Episode finished after 499 timesteps\n",
      "    PARAMS.epsilon:  0.3577790800099547  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5123 episode reward:  5.0  Episode finished after 341 timesteps\n",
      "    PARAMS.epsilon:  0.3576088000099536  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5124 episode reward:  8.0  Episode finished after 422 timesteps\n",
      "    PARAMS.epsilon:  0.3574009000099523  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5125 episode reward:  14.0  Episode finished after 401 timesteps\n",
      "    PARAMS.epsilon:  0.35720290000995103  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5126 episode reward:  13.0  Episode finished after 394 timesteps\n",
      "    PARAMS.epsilon:  0.3570068800099498  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5127 episode reward:  11.0  Episode finished after 530 timesteps\n",
      "    PARAMS.epsilon:  0.35674552000994814  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5128 episode reward:  8.0  Episode finished after 445 timesteps\n",
      "    PARAMS.epsilon:  0.35652376000994673  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5129 episode reward:  8.0  Episode finished after 448 timesteps\n",
      "    PARAMS.epsilon:  0.35630200000994533  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5130 episode reward:  12.0  Episode finished after 531 timesteps\n",
      "    PARAMS.epsilon:  0.3560406400099437  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5131 episode reward:  11.0  Episode finished after 601 timesteps\n",
      "    PARAMS.epsilon:  0.3557416600099418  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5132 episode reward:  6.0  Episode finished after 385 timesteps\n",
      "    PARAMS.epsilon:  0.3555515800099406  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5133 episode reward:  3.0  Episode finished after 254 timesteps\n",
      "    PARAMS.epsilon:  0.3554268400099398  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5134 episode reward:  10.0  Episode finished after 496 timesteps\n",
      "    PARAMS.epsilon:  0.35518132000993824  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5135 episode reward:  9.0  Episode finished after 473 timesteps\n",
      "    PARAMS.epsilon:  0.35494570000993675  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5136 episode reward:  18.0  Episode finished after 562 timesteps\n",
      "    PARAMS.epsilon:  0.354668500009935  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5137 episode reward:  6.0  Episode finished after 376 timesteps\n",
      "    PARAMS.epsilon:  0.3544823800099338  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5138 episode reward:  21.0  Episode finished after 707 timesteps\n",
      "    PARAMS.epsilon:  0.3541319200099316  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5139 episode reward:  11.0  Episode finished after 463 timesteps\n",
      "    PARAMS.epsilon:  0.35390224000993015  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5140 episode reward:  2.0  Episode finished after 226 timesteps\n",
      "    PARAMS.epsilon:  0.35379136000992945  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5141 episode reward:  15.0  Episode finished after 549 timesteps\n",
      "    PARAMS.epsilon:  0.35352010000992773  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5142 episode reward:  9.0  Episode finished after 359 timesteps\n",
      "    PARAMS.epsilon:  0.3533419000099266  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5143 episode reward:  16.0  Episode finished after 495 timesteps\n",
      "    PARAMS.epsilon:  0.35309638000992505  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5144 episode reward:  6.0  Episode finished after 354 timesteps\n",
      "    PARAMS.epsilon:  0.35292214000992395  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5145 episode reward:  14.0  Episode finished after 559 timesteps\n",
      "    PARAMS.epsilon:  0.3526449400099222  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5146 episode reward:  13.0  Episode finished after 523 timesteps\n",
      "    PARAMS.epsilon:  0.35238556000992055  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5147 episode reward:  13.0  Episode finished after 508 timesteps\n",
      "    PARAMS.epsilon:  0.35213410000991896  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5148 episode reward:  12.0  Episode finished after 413 timesteps\n",
      "    PARAMS.epsilon:  0.35193016000991767  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5149 episode reward:  5.0  Episode finished after 344 timesteps\n",
      "    PARAMS.epsilon:  0.3517598800099166  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5150 episode reward:  11.0  Episode finished after 548 timesteps\n",
      "    PARAMS.epsilon:  0.3514886200099149  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5151 episode reward:  7.0  Episode finished after 377 timesteps\n",
      "    PARAMS.epsilon:  0.3513025000099137  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5152 episode reward:  11.0  Episode finished after 564 timesteps\n",
      "    PARAMS.epsilon:  0.35102332000991193  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5153 episode reward:  4.0  Episode finished after 309 timesteps\n",
      "    PARAMS.epsilon:  0.35086888000991096  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5154 episode reward:  13.0  Episode finished after 427 timesteps\n",
      "    PARAMS.epsilon:  0.3506590000099096  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5155 episode reward:  8.0  Episode finished after 397 timesteps\n",
      "    PARAMS.epsilon:  0.3504610000099084  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5156 episode reward:  11.0  Episode finished after 480 timesteps\n",
      "    PARAMS.epsilon:  0.35022340000990687  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5157 episode reward:  6.0  Episode finished after 360 timesteps\n",
      "    PARAMS.epsilon:  0.35004520000990574  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5158 episode reward:  12.0  Episode finished after 484 timesteps\n",
      "    PARAMS.epsilon:  0.34980562000990423  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5159 episode reward:  9.0  Episode finished after 453 timesteps\n",
      "    PARAMS.epsilon:  0.3495818800099028  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5160 episode reward:  14.0  Episode finished after 421 timesteps\n",
      "    PARAMS.epsilon:  0.3493739800099015  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5161 episode reward:  15.0  Episode finished after 601 timesteps\n",
      "    PARAMS.epsilon:  0.3490769800098996  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5162 episode reward:  6.0  Episode finished after 390 timesteps\n",
      "    PARAMS.epsilon:  0.3488829400098984  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5163 episode reward:  25.0  Episode finished after 797 timesteps\n",
      "    PARAMS.epsilon:  0.3484889200098959  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5164 episode reward:  10.0  Episode finished after 464 timesteps\n",
      "    PARAMS.epsilon:  0.34825924000989444  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5165 episode reward:  12.0  Episode finished after 534 timesteps\n",
      "    PARAMS.epsilon:  0.34799392000989277  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5166 episode reward:  4.0  Episode finished after 303 timesteps\n",
      "    PARAMS.epsilon:  0.3478454200098918  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5167 episode reward:  11.0  Episode finished after 449 timesteps\n",
      "    PARAMS.epsilon:  0.3476216800098904  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5168 episode reward:  5.0  Episode finished after 340 timesteps\n",
      "    PARAMS.epsilon:  0.34745338000988935  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5169 episode reward:  6.0  Episode finished after 366 timesteps\n",
      "    PARAMS.epsilon:  0.3472732000098882  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5170 episode reward:  9.0  Episode finished after 455 timesteps\n",
      "    PARAMS.epsilon:  0.3470474800098868  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5171 episode reward:  12.0  Episode finished after 487 timesteps\n",
      "    PARAMS.epsilon:  0.34680592000988525  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5172 episode reward:  13.0  Episode finished after 481 timesteps\n",
      "    PARAMS.epsilon:  0.34656832000988375  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5173 episode reward:  10.0  Episode finished after 383 timesteps\n",
      "    PARAMS.epsilon:  0.34637824000988254  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5174 episode reward:  6.0  Episode finished after 352 timesteps\n",
      "    PARAMS.epsilon:  0.34620400000988144  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5175 episode reward:  7.0  Episode finished after 375 timesteps\n",
      "    PARAMS.epsilon:  0.3460198600098803  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5176 episode reward:  14.0  Episode finished after 596 timesteps\n",
      "    PARAMS.epsilon:  0.3457248400098784  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5177 episode reward:  11.0  Episode finished after 538 timesteps\n",
      "    PARAMS.epsilon:  0.3454575400098767  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5178 episode reward:  11.0  Episode finished after 534 timesteps\n",
      "    PARAMS.epsilon:  0.34519420000987505  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5179 episode reward:  6.0  Episode finished after 382 timesteps\n",
      "    PARAMS.epsilon:  0.34500412000987385  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5180 episode reward:  5.0  Episode finished after 322 timesteps\n",
      "    PARAMS.epsilon:  0.34484572000987285  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5181 episode reward:  9.0  Episode finished after 411 timesteps\n",
      "    PARAMS.epsilon:  0.34464178000987156  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5182 episode reward:  10.0  Episode finished after 490 timesteps\n",
      "    PARAMS.epsilon:  0.34439824000987  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5183 episode reward:  7.0  Episode finished after 408 timesteps\n",
      "    PARAMS.epsilon:  0.34419628000986874  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5184 episode reward:  6.0  Episode finished after 371 timesteps\n",
      "    PARAMS.epsilon:  0.3440141200098676  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5185 episode reward:  12.0  Episode finished after 425 timesteps\n",
      "    PARAMS.epsilon:  0.34380226000986625  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5186 episode reward:  14.0  Episode finished after 636 timesteps\n",
      "    PARAMS.epsilon:  0.34348744000986425  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5187 episode reward:  12.0  Episode finished after 638 timesteps\n",
      "    PARAMS.epsilon:  0.34317262000986226  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5188 episode reward:  4.0  Episode finished after 271 timesteps\n",
      "    PARAMS.epsilon:  0.3430379800098614  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5189 episode reward:  16.0  Episode finished after 571 timesteps\n",
      "    PARAMS.epsilon:  0.3427548400098596  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5190 episode reward:  13.0  Episode finished after 537 timesteps\n",
      "    PARAMS.epsilon:  0.34248952000985794  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5191 episode reward:  14.0  Episode finished after 413 timesteps\n",
      "    PARAMS.epsilon:  0.34228558000985665  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5192 episode reward:  11.0  Episode finished after 572 timesteps\n",
      "    PARAMS.epsilon:  0.34200244000985486  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5193 episode reward:  12.0  Episode finished after 600 timesteps\n",
      "    PARAMS.epsilon:  0.341705440009853  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5194 episode reward:  7.0  Episode finished after 411 timesteps\n",
      "    PARAMS.epsilon:  0.3415015000098517  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5195 episode reward:  13.0  Episode finished after 455 timesteps\n",
      "    PARAMS.epsilon:  0.34127578000985026  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5196 episode reward:  13.0  Episode finished after 678 timesteps\n",
      "    PARAMS.epsilon:  0.34094116000984814  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5197 episode reward:  13.0  Episode finished after 508 timesteps\n",
      "    PARAMS.epsilon:  0.34068970000984655  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5198 episode reward:  9.0  Episode finished after 471 timesteps\n",
      "    PARAMS.epsilon:  0.3404560600098451  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5199 episode reward:  13.0  Episode finished after 531 timesteps\n",
      "    PARAMS.epsilon:  0.3401927200098434  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5200 episode reward:  14.0  Episode finished after 589 timesteps\n",
      "    PARAMS.epsilon:  0.33990166000984157  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5201 episode reward:  5.0  Episode finished after 356 timesteps\n",
      "    PARAMS.epsilon:  0.33972544000984045  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5202 episode reward:  5.0  Episode finished after 331 timesteps\n",
      "    PARAMS.epsilon:  0.3395611000098394  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5203 episode reward:  11.0  Episode finished after 531 timesteps\n",
      "    PARAMS.epsilon:  0.33929974000983776  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5204 episode reward:  22.0  Episode finished after 617 timesteps\n",
      "    PARAMS.epsilon:  0.3389928400098358  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5205 episode reward:  18.0  Episode finished after 654 timesteps\n",
      "    PARAMS.epsilon:  0.3386701000098338  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5206 episode reward:  6.0  Episode finished after 451 timesteps\n",
      "    PARAMS.epsilon:  0.33844636000983236  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5207 episode reward:  15.0  Episode finished after 427 timesteps\n",
      "    PARAMS.epsilon:  0.338234500009831  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5208 episode reward:  4.0  Episode finished after 283 timesteps\n",
      "    PARAMS.epsilon:  0.33809590000983014  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5209 episode reward:  5.0  Episode finished after 352 timesteps\n",
      "    PARAMS.epsilon:  0.33792166000982904  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5210 episode reward:  7.0  Episode finished after 386 timesteps\n",
      "    PARAMS.epsilon:  0.3377296000098278  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5211 episode reward:  7.0  Episode finished after 396 timesteps\n",
      "    PARAMS.epsilon:  0.3375335800098266  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5212 episode reward:  5.0  Episode finished after 339 timesteps\n",
      "    PARAMS.epsilon:  0.3373652800098255  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5213 episode reward:  2.0  Episode finished after 248 timesteps\n",
      "    PARAMS.epsilon:  0.33724252000982474  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5214 episode reward:  10.0  Episode finished after 546 timesteps\n",
      "    PARAMS.epsilon:  0.33697324000982304  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5215 episode reward:  8.0  Episode finished after 469 timesteps\n",
      "    PARAMS.epsilon:  0.3367415800098216  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5216 episode reward:  13.0  Episode finished after 609 timesteps\n",
      "    PARAMS.epsilon:  0.33643864000981966  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5217 episode reward:  14.0  Episode finished after 532 timesteps\n",
      "    PARAMS.epsilon:  0.336175300009818  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5218 episode reward:  5.0  Episode finished after 310 timesteps\n",
      "    PARAMS.epsilon:  0.336022840009817  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5219 episode reward:  12.0  Episode finished after 584 timesteps\n",
      "    PARAMS.epsilon:  0.3357337600098152  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5220 episode reward:  12.0  Episode finished after 448 timesteps\n",
      "    PARAMS.epsilon:  0.3355120000098138  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5221 episode reward:  9.0  Episode finished after 444 timesteps\n",
      "    PARAMS.epsilon:  0.3352922200098124  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5222 episode reward:  7.0  Episode finished after 426 timesteps\n",
      "    PARAMS.epsilon:  0.33508036000981106  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5223 episode reward:  6.0  Episode finished after 389 timesteps\n",
      "    PARAMS.epsilon:  0.33488830000980985  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5224 episode reward:  11.0  Episode finished after 516 timesteps\n",
      "    PARAMS.epsilon:  0.33463288000980823  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5225 episode reward:  7.0  Episode finished after 400 timesteps\n",
      "    PARAMS.epsilon:  0.334434880009807  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5226 episode reward:  17.0  Episode finished after 663 timesteps\n",
      "    PARAMS.epsilon:  0.3341062000098049  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5227 episode reward:  10.0  Episode finished after 541 timesteps\n",
      "    PARAMS.epsilon:  0.3338389000098032  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5228 episode reward:  9.0  Episode finished after 528 timesteps\n",
      "    PARAMS.epsilon:  0.33357754000980155  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5229 episode reward:  15.0  Episode finished after 568 timesteps\n",
      "    PARAMS.epsilon:  0.3332963800097998  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5230 episode reward:  10.0  Episode finished after 500 timesteps\n",
      "    PARAMS.epsilon:  0.3330488800097982  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5231 episode reward:  16.0  Episode finished after 630 timesteps\n",
      "    PARAMS.epsilon:  0.33273802000979624  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5232 episode reward:  19.0  Episode finished after 494 timesteps\n",
      "    PARAMS.epsilon:  0.3324925000097947  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5233 episode reward:  16.0  Episode finished after 622 timesteps\n",
      "    PARAMS.epsilon:  0.33218560000979275  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5234 episode reward:  12.0  Episode finished after 552 timesteps\n",
      "    PARAMS.epsilon:  0.331912360009791  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5235 episode reward:  5.0  Episode finished after 304 timesteps\n",
      "    PARAMS.epsilon:  0.33176188000979007  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5236 episode reward:  7.0  Episode finished after 404 timesteps\n",
      "    PARAMS.epsilon:  0.3315619000097888  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5237 episode reward:  11.0  Episode finished after 563 timesteps\n",
      "    PARAMS.epsilon:  0.33128272000978704  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5238 episode reward:  11.0  Episode finished after 546 timesteps\n",
      "    PARAMS.epsilon:  0.3310114600097853  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5239 episode reward:  5.0  Episode finished after 342 timesteps\n",
      "    PARAMS.epsilon:  0.33084316000978425  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5240 episode reward:  14.0  Episode finished after 526 timesteps\n",
      "    PARAMS.epsilon:  0.3305818000097826  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5241 episode reward:  8.0  Episode finished after 433 timesteps\n",
      "    PARAMS.epsilon:  0.33036796000978125  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5242 episode reward:  14.0  Episode finished after 590 timesteps\n",
      "    PARAMS.epsilon:  0.3300769000097794  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5243 episode reward:  8.0  Episode finished after 420 timesteps\n",
      "    PARAMS.epsilon:  0.3298690000097781  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5244 episode reward:  10.0  Episode finished after 473 timesteps\n",
      "    PARAMS.epsilon:  0.3296333800097766  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5245 episode reward:  10.0  Episode finished after 462 timesteps\n",
      "    PARAMS.epsilon:  0.32940568000977516  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5246 episode reward:  14.0  Episode finished after 539 timesteps\n",
      "    PARAMS.epsilon:  0.32913838000977347  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5247 episode reward:  9.0  Episode finished after 473 timesteps\n",
      "    PARAMS.epsilon:  0.328904740009772  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5248 episode reward:  14.0  Episode finished after 503 timesteps\n",
      "    PARAMS.epsilon:  0.3286552600097704  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5249 episode reward:  23.0  Episode finished after 755 timesteps\n",
      "    PARAMS.epsilon:  0.32828104000976804  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5250 episode reward:  9.0  Episode finished after 480 timesteps\n",
      "    PARAMS.epsilon:  0.32804344000976654  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5251 episode reward:  14.0  Episode finished after 646 timesteps\n",
      "    PARAMS.epsilon:  0.3277246600097645  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5252 episode reward:  7.0  Episode finished after 430 timesteps\n",
      "    PARAMS.epsilon:  0.32751082000976317  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5253 episode reward:  15.0  Episode finished after 597 timesteps\n",
      "    PARAMS.epsilon:  0.3272158000097613  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5254 episode reward:  6.0  Episode finished after 365 timesteps\n",
      "    PARAMS.epsilon:  0.32703562000976016  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5255 episode reward:  7.0  Episode finished after 439 timesteps\n",
      "    PARAMS.epsilon:  0.3268178200097588  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5256 episode reward:  6.0  Episode finished after 323 timesteps\n",
      "    PARAMS.epsilon:  0.32665744000975777  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5257 episode reward:  24.0  Episode finished after 641 timesteps\n",
      "    PARAMS.epsilon:  0.32634064000975577  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5258 episode reward:  10.0  Episode finished after 596 timesteps\n",
      "    PARAMS.epsilon:  0.3260456200097539  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5259 episode reward:  12.0  Episode finished after 455 timesteps\n",
      "    PARAMS.epsilon:  0.32581990000975247  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5260 episode reward:  10.0  Episode finished after 513 timesteps\n",
      "    PARAMS.epsilon:  0.32556646000975087  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5261 episode reward:  10.0  Episode finished after 451 timesteps\n",
      "    PARAMS.epsilon:  0.32534272000974945  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5262 episode reward:  12.0  Episode finished after 521 timesteps\n",
      "    PARAMS.epsilon:  0.3250853200097478  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5263 episode reward:  7.0  Episode finished after 391 timesteps\n",
      "    PARAMS.epsilon:  0.3248912800097466  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5264 episode reward:  12.0  Episode finished after 607 timesteps\n",
      "    PARAMS.epsilon:  0.3245923000097447  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5265 episode reward:  15.0  Episode finished after 617 timesteps\n",
      "    PARAMS.epsilon:  0.32428540000974276  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5266 episode reward:  14.0  Episode finished after 565 timesteps\n",
      "    PARAMS.epsilon:  0.324006220009741  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5267 episode reward:  15.0  Episode finished after 573 timesteps\n",
      "    PARAMS.epsilon:  0.3237230800097392  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5268 episode reward:  3.0  Episode finished after 262 timesteps\n",
      "    PARAMS.epsilon:  0.3235924000097384  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5269 episode reward:  15.0  Episode finished after 436 timesteps\n",
      "    PARAMS.epsilon:  0.323376580009737  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5270 episode reward:  9.0  Episode finished after 443 timesteps\n",
      "    PARAMS.epsilon:  0.32315878000973564  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5271 episode reward:  25.0  Episode finished after 798 timesteps\n",
      "    PARAMS.epsilon:  0.32276278000973313  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5272 episode reward:  14.0  Episode finished after 495 timesteps\n",
      "    PARAMS.epsilon:  0.3225172600097316  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5273 episode reward:  15.0  Episode finished after 591 timesteps\n",
      "    PARAMS.epsilon:  0.32222620000972974  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5274 episode reward:  13.0  Episode finished after 471 timesteps\n",
      "    PARAMS.epsilon:  0.32199256000972826  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5275 episode reward:  13.0  Episode finished after 390 timesteps\n",
      "    PARAMS.epsilon:  0.32179852000972703  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5276 episode reward:  7.0  Episode finished after 344 timesteps\n",
      "    PARAMS.epsilon:  0.32162824000972595  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5277 episode reward:  8.0  Episode finished after 483 timesteps\n",
      "    PARAMS.epsilon:  0.32139064000972445  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5278 episode reward:  6.0  Episode finished after 376 timesteps\n",
      "    PARAMS.epsilon:  0.32120452000972327  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5279 episode reward:  18.0  Episode finished after 659 timesteps\n",
      "    PARAMS.epsilon:  0.3208778200097212  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5280 episode reward:  7.0  Episode finished after 367 timesteps\n",
      "    PARAMS.epsilon:  0.32069566000972005  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5281 episode reward:  6.0  Episode finished after 342 timesteps\n",
      "    PARAMS.epsilon:  0.320527360009719  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5282 episode reward:  25.0  Episode finished after 986 timesteps\n",
      "    PARAMS.epsilon:  0.3200383000097159  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5283 episode reward:  10.0  Episode finished after 458 timesteps\n",
      "    PARAMS.epsilon:  0.31981258000971446  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5284 episode reward:  13.0  Episode finished after 551 timesteps\n",
      "    PARAMS.epsilon:  0.31953934000971274  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5285 episode reward:  22.0  Episode finished after 682 timesteps\n",
      "    PARAMS.epsilon:  0.3192007600097106  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5286 episode reward:  10.0  Episode finished after 507 timesteps\n",
      "    PARAMS.epsilon:  0.318951280009709  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5287 episode reward:  10.0  Episode finished after 485 timesteps\n",
      "    PARAMS.epsilon:  0.3187097200097075  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5288 episode reward:  13.0  Episode finished after 458 timesteps\n",
      "    PARAMS.epsilon:  0.31848400000970606  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5289 episode reward:  5.0  Episode finished after 347 timesteps\n",
      "    PARAMS.epsilon:  0.31831174000970497  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5290 episode reward:  13.0  Episode finished after 485 timesteps\n",
      "    PARAMS.epsilon:  0.31807216000970345  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5291 episode reward:  12.0  Episode finished after 633 timesteps\n",
      "    PARAMS.epsilon:  0.3177593200097015  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5292 episode reward:  10.0  Episode finished after 434 timesteps\n",
      "    PARAMS.epsilon:  0.3175435000097001  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5293 episode reward:  13.0  Episode finished after 378 timesteps\n",
      "    PARAMS.epsilon:  0.31735738000969893  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5294 episode reward:  18.0  Episode finished after 525 timesteps\n",
      "    PARAMS.epsilon:  0.3170960200096973  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5295 episode reward:  15.0  Episode finished after 519 timesteps\n",
      "    PARAMS.epsilon:  0.31684060000969566  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5296 episode reward:  12.0  Episode finished after 541 timesteps\n",
      "    PARAMS.epsilon:  0.31657132000969396  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5297 episode reward:  10.0  Episode finished after 474 timesteps\n",
      "    PARAMS.epsilon:  0.3163376800096925  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5298 episode reward:  15.0  Episode finished after 553 timesteps\n",
      "    PARAMS.epsilon:  0.31606444000969075  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5299 episode reward:  5.0  Episode finished after 317 timesteps\n",
      "    PARAMS.epsilon:  0.31590604000968975  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5300 episode reward:  9.0  Episode finished after 430 timesteps\n",
      "    PARAMS.epsilon:  0.3156941800096884  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5301 episode reward:  18.0  Episode finished after 514 timesteps\n",
      "    PARAMS.epsilon:  0.3154387600096868  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5302 episode reward:  11.0  Episode finished after 482 timesteps\n",
      "    PARAMS.epsilon:  0.3152011600096853  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5303 episode reward:  11.0  Episode finished after 563 timesteps\n",
      "    PARAMS.epsilon:  0.3149219800096835  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5304 episode reward:  10.0  Episode finished after 510 timesteps\n",
      "    PARAMS.epsilon:  0.31467052000968193  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5305 episode reward:  7.0  Episode finished after 336 timesteps\n",
      "    PARAMS.epsilon:  0.3145042000096809  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5306 episode reward:  10.0  Episode finished after 492 timesteps\n",
      "    PARAMS.epsilon:  0.31426066000967934  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5307 episode reward:  20.0  Episode finished after 757 timesteps\n",
      "    PARAMS.epsilon:  0.31388446000967696  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5308 episode reward:  11.0  Episode finished after 523 timesteps\n",
      "    PARAMS.epsilon:  0.31362706000967533  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5309 episode reward:  7.0  Episode finished after 412 timesteps\n",
      "    PARAMS.epsilon:  0.31342312000967404  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5310 episode reward:  12.0  Episode finished after 337 timesteps\n",
      "    PARAMS.epsilon:  0.313254820009673  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5311 episode reward:  16.0  Episode finished after 571 timesteps\n",
      "    PARAMS.epsilon:  0.3129736600096712  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5312 episode reward:  10.0  Episode finished after 493 timesteps\n",
      "    PARAMS.epsilon:  0.31272814000966964  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5313 episode reward:  18.0  Episode finished after 585 timesteps\n",
      "    PARAMS.epsilon:  0.3124390600096678  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5314 episode reward:  12.0  Episode finished after 441 timesteps\n",
      "    PARAMS.epsilon:  0.31222126000966643  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5315 episode reward:  9.0  Episode finished after 483 timesteps\n",
      "    PARAMS.epsilon:  0.3119816800096649  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5316 episode reward:  9.0  Episode finished after 431 timesteps\n",
      "    PARAMS.epsilon:  0.31176784000966357  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5317 episode reward:  12.0  Episode finished after 551 timesteps\n",
      "    PARAMS.epsilon:  0.31149658000966185  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5318 episode reward:  11.0  Episode finished after 507 timesteps\n",
      "    PARAMS.epsilon:  0.31124512000966026  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5319 episode reward:  15.0  Episode finished after 645 timesteps\n",
      "    PARAMS.epsilon:  0.31092634000965824  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5320 episode reward:  20.0  Episode finished after 636 timesteps\n",
      "    PARAMS.epsilon:  0.31061152000965625  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5321 episode reward:  11.0  Episode finished after 564 timesteps\n",
      "    PARAMS.epsilon:  0.3103323400096545  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5322 episode reward:  8.0  Episode finished after 413 timesteps\n",
      "    PARAMS.epsilon:  0.3101264200096532  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5323 episode reward:  12.0  Episode finished after 579 timesteps\n",
      "    PARAMS.epsilon:  0.3098413000096514  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5324 episode reward:  19.0  Episode finished after 782 timesteps\n",
      "    PARAMS.epsilon:  0.3094532200096489  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5325 episode reward:  18.0  Episode finished after 619 timesteps\n",
      "    PARAMS.epsilon:  0.309146320009647  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5326 episode reward:  11.0  Episode finished after 494 timesteps\n",
      "    PARAMS.epsilon:  0.30890278000964544  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5327 episode reward:  21.0  Episode finished after 504 timesteps\n",
      "    PARAMS.epsilon:  0.30865330000964386  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5328 episode reward:  14.0  Episode finished after 615 timesteps\n",
      "    PARAMS.epsilon:  0.30834838000964193  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5329 episode reward:  13.0  Episode finished after 601 timesteps\n",
      "    PARAMS.epsilon:  0.30805138000964005  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5330 episode reward:  31.0  Episode finished after 768 timesteps\n",
      "    PARAMS.epsilon:  0.30767122000963765  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  31.0  agent.save() Done!\n",
      "PARAMS.episode_i:  5331 episode reward:  23.0  Episode finished after 666 timesteps\n",
      "    PARAMS.epsilon:  0.30734056000963555  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5332 episode reward:  12.0  Episode finished after 502 timesteps\n",
      "    PARAMS.epsilon:  0.307093060009634  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5333 episode reward:  10.0  Episode finished after 508 timesteps\n",
      "    PARAMS.epsilon:  0.3068416000096324  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5334 episode reward:  11.0  Episode finished after 406 timesteps\n",
      "    PARAMS.epsilon:  0.3066396400096311  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5335 episode reward:  9.0  Episode finished after 497 timesteps\n",
      "    PARAMS.epsilon:  0.30639412000962957  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5336 episode reward:  19.0  Episode finished after 781 timesteps\n",
      "    PARAMS.epsilon:  0.3060080200096271  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5337 episode reward:  8.0  Episode finished after 495 timesteps\n",
      "    PARAMS.epsilon:  0.30576250000962557  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5338 episode reward:  12.0  Episode finished after 368 timesteps\n",
      "    PARAMS.epsilon:  0.3055803400096244  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5339 episode reward:  18.0  Episode finished after 633 timesteps\n",
      "    PARAMS.epsilon:  0.30526750000962244  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5340 episode reward:  18.0  Episode finished after 585 timesteps\n",
      "    PARAMS.epsilon:  0.3049784200096206  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5341 episode reward:  17.0  Episode finished after 660 timesteps\n",
      "    PARAMS.epsilon:  0.30465172000961854  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5342 episode reward:  12.0  Episode finished after 512 timesteps\n",
      "    PARAMS.epsilon:  0.30439828000961694  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5343 episode reward:  15.0  Episode finished after 592 timesteps\n",
      "    PARAMS.epsilon:  0.3041052400096151  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5344 episode reward:  22.0  Episode finished after 843 timesteps\n",
      "    PARAMS.epsilon:  0.30368746000961244  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5345 episode reward:  10.0  Episode finished after 479 timesteps\n",
      "    PARAMS.epsilon:  0.30344986000961094  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5346 episode reward:  15.0  Episode finished after 587 timesteps\n",
      "    PARAMS.epsilon:  0.3031588000096091  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5347 episode reward:  11.0  Episode finished after 422 timesteps\n",
      "    PARAMS.epsilon:  0.3029509000096078  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5348 episode reward:  22.0  Episode finished after 675 timesteps\n",
      "    PARAMS.epsilon:  0.30261628000960566  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5349 episode reward:  12.0  Episode finished after 511 timesteps\n",
      "    PARAMS.epsilon:  0.30236284000960406  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5350 episode reward:  12.0  Episode finished after 553 timesteps\n",
      "    PARAMS.epsilon:  0.30208960000960233  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5351 episode reward:  5.0  Episode finished after 324 timesteps\n",
      "    PARAMS.epsilon:  0.3019292200096013  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5352 episode reward:  12.0  Episode finished after 538 timesteps\n",
      "    PARAMS.epsilon:  0.30166390000959964  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5353 episode reward:  16.0  Episode finished after 747 timesteps\n",
      "    PARAMS.epsilon:  0.3012936400095973  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5354 episode reward:  6.0  Episode finished after 379 timesteps\n",
      "    PARAMS.epsilon:  0.3011055400095961  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5355 episode reward:  9.0  Episode finished after 485 timesteps\n",
      "    PARAMS.epsilon:  0.3008659600095946  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5356 episode reward:  12.0  Episode finished after 582 timesteps\n",
      "    PARAMS.epsilon:  0.30057688000959276  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5357 episode reward:  9.0  Episode finished after 459 timesteps\n",
      "    PARAMS.epsilon:  0.30035116000959133  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5358 episode reward:  18.0  Episode finished after 782 timesteps\n",
      "    PARAMS.epsilon:  0.2999630800095889  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5359 episode reward:  9.0  Episode finished after 425 timesteps\n",
      "    PARAMS.epsilon:  0.29975320000958755  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5360 episode reward:  5.0  Episode finished after 312 timesteps\n",
      "    PARAMS.epsilon:  0.2995987600095866  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5361 episode reward:  14.0  Episode finished after 547 timesteps\n",
      "    PARAMS.epsilon:  0.29932750000958486  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5362 episode reward:  8.0  Episode finished after 418 timesteps\n",
      "    PARAMS.epsilon:  0.29912158000958355  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5363 episode reward:  13.0  Episode finished after 606 timesteps\n",
      "    PARAMS.epsilon:  0.29882062000958165  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5364 episode reward:  2.0  Episode finished after 180 timesteps\n",
      "    PARAMS.epsilon:  0.2987315200095811  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5365 episode reward:  7.0  Episode finished after 385 timesteps\n",
      "    PARAMS.epsilon:  0.2985414400095799  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5366 episode reward:  8.0  Episode finished after 399 timesteps\n",
      "    PARAMS.epsilon:  0.29834344000957863  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5367 episode reward:  22.0  Episode finished after 753 timesteps\n",
      "    PARAMS.epsilon:  0.2979712000095763  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5368 episode reward:  11.0  Episode finished after 410 timesteps\n",
      "    PARAMS.epsilon:  0.297767260009575  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5369 episode reward:  14.0  Episode finished after 489 timesteps\n",
      "    PARAMS.epsilon:  0.29752570000957346  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5370 episode reward:  19.0  Episode finished after 605 timesteps\n",
      "    PARAMS.epsilon:  0.29722672000957157  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5371 episode reward:  14.0  Episode finished after 662 timesteps\n",
      "    PARAMS.epsilon:  0.2968980400095695  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5372 episode reward:  8.0  Episode finished after 381 timesteps\n",
      "    PARAMS.epsilon:  0.2967099400095683  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5373 episode reward:  3.0  Episode finished after 285 timesteps\n",
      "    PARAMS.epsilon:  0.2965693600095674  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5374 episode reward:  15.0  Episode finished after 570 timesteps\n",
      "    PARAMS.epsilon:  0.2962862200095656  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5375 episode reward:  18.0  Episode finished after 483 timesteps\n",
      "    PARAMS.epsilon:  0.2960486200095641  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5376 episode reward:  19.0  Episode finished after 592 timesteps\n",
      "    PARAMS.epsilon:  0.29575558000956226  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5377 episode reward:  9.0  Episode finished after 434 timesteps\n",
      "    PARAMS.epsilon:  0.2955397600095609  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5378 episode reward:  13.0  Episode finished after 377 timesteps\n",
      "    PARAMS.epsilon:  0.2953536400095597  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5379 episode reward:  12.0  Episode finished after 550 timesteps\n",
      "    PARAMS.epsilon:  0.295080400009558  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5380 episode reward:  20.0  Episode finished after 586 timesteps\n",
      "    PARAMS.epsilon:  0.29479132000955616  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5381 episode reward:  7.0  Episode finished after 359 timesteps\n",
      "    PARAMS.epsilon:  0.29461312000955503  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5382 episode reward:  15.0  Episode finished after 562 timesteps\n",
      "    PARAMS.epsilon:  0.2943359200095533  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5383 episode reward:  12.0  Episode finished after 540 timesteps\n",
      "    PARAMS.epsilon:  0.2940686200095516  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5384 episode reward:  8.0  Episode finished after 394 timesteps\n",
      "    PARAMS.epsilon:  0.29387260000955034  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5385 episode reward:  6.0  Episode finished after 380 timesteps\n",
      "    PARAMS.epsilon:  0.29368450000954915  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5386 episode reward:  9.0  Episode finished after 478 timesteps\n",
      "    PARAMS.epsilon:  0.29344888000954766  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5387 episode reward:  10.0  Episode finished after 502 timesteps\n",
      "    PARAMS.epsilon:  0.2931994000095461  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5388 episode reward:  7.0  Episode finished after 364 timesteps\n",
      "    PARAMS.epsilon:  0.29301922000954495  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5389 episode reward:  2.0  Episode finished after 185 timesteps\n",
      "    PARAMS.epsilon:  0.29292814000954437  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5390 episode reward:  11.0  Episode finished after 580 timesteps\n",
      "    PARAMS.epsilon:  0.29264104000954255  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5391 episode reward:  6.0  Episode finished after 340 timesteps\n",
      "    PARAMS.epsilon:  0.2924727400095415  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5392 episode reward:  11.0  Episode finished after 558 timesteps\n",
      "    PARAMS.epsilon:  0.29219554000953973  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5393 episode reward:  17.0  Episode finished after 595 timesteps\n",
      "    PARAMS.epsilon:  0.2919025000095379  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5394 episode reward:  19.0  Episode finished after 657 timesteps\n",
      "    PARAMS.epsilon:  0.2915758000095358  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5395 episode reward:  10.0  Episode finished after 407 timesteps\n",
      "    PARAMS.epsilon:  0.29137582000953455  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5396 episode reward:  10.0  Episode finished after 500 timesteps\n",
      "    PARAMS.epsilon:  0.291128320009533  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5397 episode reward:  15.0  Episode finished after 626 timesteps\n",
      "    PARAMS.epsilon:  0.290817460009531  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5398 episode reward:  15.0  Episode finished after 509 timesteps\n",
      "    PARAMS.epsilon:  0.2905660000095294  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5399 episode reward:  16.0  Episode finished after 526 timesteps\n",
      "    PARAMS.epsilon:  0.29030464000952777  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5400 episode reward:  15.0  Episode finished after 549 timesteps\n",
      "    PARAMS.epsilon:  0.29003338000952605  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5401 episode reward:  13.0  Episode finished after 612 timesteps\n",
      "    PARAMS.epsilon:  0.28973044000952414  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5402 episode reward:  7.0  Episode finished after 372 timesteps\n",
      "    PARAMS.epsilon:  0.28954630000952297  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5403 episode reward:  22.0  Episode finished after 531 timesteps\n",
      "    PARAMS.epsilon:  0.2892829600095213  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5404 episode reward:  6.0  Episode finished after 325 timesteps\n",
      "    PARAMS.epsilon:  0.2891225800095203  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5405 episode reward:  21.0  Episode finished after 654 timesteps\n",
      "    PARAMS.epsilon:  0.28879984000951825  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5406 episode reward:  21.0  Episode finished after 803 timesteps\n",
      "    PARAMS.epsilon:  0.28840186000951573  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5407 episode reward:  13.0  Episode finished after 569 timesteps\n",
      "    PARAMS.epsilon:  0.28812070000951395  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5408 episode reward:  14.0  Episode finished after 655 timesteps\n",
      "    PARAMS.epsilon:  0.2877959800095119  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5409 episode reward:  16.0  Episode finished after 634 timesteps\n",
      "    PARAMS.epsilon:  0.2874811600095099  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5410 episode reward:  20.0  Episode finished after 600 timesteps\n",
      "    PARAMS.epsilon:  0.287184160009508  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5411 episode reward:  5.0  Episode finished after 315 timesteps\n",
      "    PARAMS.epsilon:  0.28702972000950705  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5412 episode reward:  24.0  Episode finished after 933 timesteps\n",
      "    PARAMS.epsilon:  0.2865664000095041  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5413 episode reward:  17.0  Episode finished after 519 timesteps\n",
      "    PARAMS.epsilon:  0.2863109800095025  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5414 episode reward:  21.0  Episode finished after 798 timesteps\n",
      "    PARAMS.epsilon:  0.2859149800095  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5415 episode reward:  12.0  Episode finished after 525 timesteps\n",
      "    PARAMS.epsilon:  0.28565560000949836  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5416 episode reward:  8.0  Episode finished after 452 timesteps\n",
      "    PARAMS.epsilon:  0.28543186000949694  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.episode_i:  5417 episode reward:  37.0  Episode finished after 1000 timesteps\n",
      "    PARAMS.epsilon:  0.2849368600094938  PARAMS.learning_rate:  0.0001\n",
      "PARAMS.max_episode_reward:  37.0  agent.save() Done!\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "Tried to reset environment which is not done. While the monitor is active for BreakoutDeterministic-v4, you cannot call reset() unless the episode is over.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-28d183a0e1ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"====== Start Interacting with Env ======\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mPARAMS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode_i\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mPARAMS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_episodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPARAMS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdown_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb2gray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mframe_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/anaconda3/lib/python3.7/site-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/anaconda3/lib/python3.7/site-packages/gym/wrappers/monitor.py\u001b[0m in \u001b[0;36m_before_reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_before_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_after_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Apps/anaconda3/lib/python3.7/site-packages/gym/wrappers/monitoring/stats_recorder.py\u001b[0m in \u001b[0;36mbefore_reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tried to reset environment which is not done. While the monitor is active for {}, you cannot call reset() unless the episode is over.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mError\u001b[0m: Tried to reset environment which is not done. While the monitor is active for BreakoutDeterministic-v4, you cannot call reset() unless the episode is over."
     ]
    }
   ],
   "source": [
    "################\n",
    "### Training ###\n",
    "################\n",
    "# Let the agent interact with the environment\n",
    "\n",
    "# Create an instance of DQN Agent.\n",
    "agent = Agent()\n",
    "\n",
    "# -------------\n",
    "# Load weights\n",
    "# -------------------------------------------------------\n",
    "# Need to Specify episode_i, best and max_episode_reward.\n",
    "# If you train the agent from stratch, comment the \n",
    "# following lines of code out.\n",
    "# -------------------------------------------------------\n",
    "# episode_i = 700\n",
    "# max_episode_reward = 1 # Any number does not matter if best=False\n",
    "# best = False\n",
    "# agent.restore(episode_i=episode_i, best=best, max_episode_reward=max_episode_reward)\n",
    "\n",
    "# -----------------------------\n",
    "# Iterate through all episodes\n",
    "# -----------------------------\n",
    "print()\n",
    "print(\"====== Start Interacting with Env ======\")\n",
    "while PARAMS.episode_i < PARAMS.max_episodes:\n",
    "    obs = PARAMS.env.reset()\n",
    "    frame = down_sample(rgb2gray(obs))\n",
    "    frame_stack = [frame, frame, frame, frame]\n",
    "    episode_reward = 0\n",
    "    \n",
    "    # Iterate through all steps\n",
    "    for t in range(PARAMS.max_steps):\n",
    "        PARAMS.env.render()\n",
    "        \n",
    "        PARAMS.cnt_frames += 1\n",
    "        # s: current state\n",
    "        s = frame_stack[-PARAMS.s_len:]\n",
    "        # q: current q, a: current action\n",
    "        q, a = agent.predict(\\\n",
    "                    np.expand_dims(np.transpose(\\\n",
    "                    s, [1, 2, 0]), axis=0))\n",
    "        \n",
    "        # epsilon probability to take random actions to explore\n",
    "        if np.random.random() < PARAMS.epsilon:\n",
    "            a = PARAMS.env.action_space.sample()\n",
    "        \n",
    "        # One Step\n",
    "        obs, r, done, info = PARAMS.env.step(a) \n",
    "        # r: immediate reward, done: terminal state indicator\n",
    "        \n",
    "        next_frame = down_sample(rgb2gray(obs))\n",
    "        frame_stack.append(next_frame)\n",
    "        # s_: next state\n",
    "        s_ = frame_stack[-PARAMS.s_len:]\n",
    "        \n",
    "        transition = (q, s, a, s_, r, int(not done))\n",
    "        # Append a transition into replay buffer\n",
    "        agent.remember(transition)\n",
    "        \n",
    "        if len(agent.replay_buffer) >= PARAMS.batch_size and \\\n",
    "            PARAMS.cnt_frames % PARAMS.train_frame_interval == 0:\n",
    "            agent.train()\n",
    "            agent.update_epsilon()\n",
    "        \n",
    "        frame_stack = frame_stack[-PARAMS.s_len:]\n",
    "        \n",
    "        episode_reward += r\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    # -------------------\n",
    "    # End of one episode\n",
    "    # -------------------\n",
    "    \n",
    "    # -------------------\n",
    "    # Log episode reward\n",
    "    # -------------------\n",
    "    PARAMS.log_file.write(str(episode_reward) + '\\n')\n",
    "    PARAMS.log_file.flush()\n",
    "    print(\"PARAMS.episode_i: \", PARAMS.episode_i, \"episode reward: \", episode_reward, \" Episode finished after {} timesteps\".format(t+1) + \"\\n\"\\\n",
    "          \"    PARAMS.epsilon: \", PARAMS.epsilon, \" PARAMS.learning_rate: \", PARAMS.learning_rate)\n",
    "    \n",
    "    # Update PARAMS.learning_rate\n",
    "    if np.abs(PARAMS.epsilon - PARAMS.final_epsilon) < 1e-5 and lr > PARAMS.final_learning_rate:\n",
    "        agent.update_learning_rate()\n",
    "        # print(\"agent.update_learning_rate() Done!\")\n",
    "    # Update target network\n",
    "    if PARAMS.episode_i % PARAMS.update_target_network_episode_interval == 0:\n",
    "        agent.update_target_network()\n",
    "        # print(\"agent.update_target_network() Done!\")\n",
    "        \n",
    "    # ------------------------------\n",
    "    # Save model weights and PARAMS\n",
    "    # ------------------------------\n",
    "    if episode_reward > PARAMS.max_episode_reward:\n",
    "        PARAMS.max_episode_reward = episode_reward\n",
    "        agent.save(best=True)\n",
    "        print(\"PARAMS.max_episode_reward: \", PARAMS.max_episode_reward, \" agent.save() Done!\")\n",
    "    elif PARAMS.episode_i % PARAMS.save_model_episode_interval == 0:\n",
    "        agent.save()\n",
    "        # print(\"agent.save() Done!\")\n",
    "    \n",
    "        \n",
    "    PARAMS.episode_i += 1\n",
    "    \n",
    "PARAMS.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Cao_Bo_112130213_discrete.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
